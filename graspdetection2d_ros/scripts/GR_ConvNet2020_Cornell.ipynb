{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GR-ConvNet2020_Cornell",
      "provenance": [],
      "collapsed_sections": [
        "Bsx4KtUdIbAQ",
        "cWzRBQMTInCC",
        "tMExlRQQJoQG"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0je6Jr82-u0a"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bClqLLWy_U1x",
        "outputId": "756dec52-ecb0-4775-9c58-0688ef31a8d5"
      },
      "source": [
        "! git clone https://github.com/skumra/robotic-grasping.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'robotic-grasping'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 653 (delta 0), reused 1 (delta 0), pack-reused 648\u001b[K\n",
            "Receiving objects: 100% (653/653), 39.10 MiB | 26.10 MiB/s, done.\n",
            "Resolving deltas: 100% (392/392), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78-VRUXgDEmj",
        "outputId": "f8127e5f-fa7b-42c2-a624-373e683b831f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "361vB_YVESVb"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVuQXuTzesdC"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klbR8lPMe3Nx",
        "outputId": "7b31ee99-b43e-4aca-9e45-cd1115a91975"
      },
      "source": [
        "!kaggle datasets download -d oneoneliu/cornell-grasp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading cornell-grasp.zip to /content\n",
            "100% 4.84G/4.85G [01:37<00:00, 43.1MB/s]\n",
            "100% 4.85G/4.85G [01:38<00:00, 53.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKs6ZfQOIVIP"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnkFs7Ojlo3b",
        "outputId": "3b612b59-c8ac-42a7-f004-d65dcd1bb723"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/content/drive/MyDrive/GR_ConvNet_Code')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/GR_ConvNet_Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6l3RPhTrwmn",
        "outputId": "1569499d-6ea1-4e8d-922d-7d304a76b611"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.16.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.10.0+cu102)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.5.1)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 31.7 MB/s \n",
            "\u001b[?25hCollecting pyrealsense2\n",
            "  Downloading pyrealsense2-2.49.0.3474-cp37-cp37m-manylinux1_x86_64.whl (16.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.4 MB 258 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (7.1.2)\n",
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2021.8.26-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.6 MB 115 kB/s \n",
            "\u001b[?25hCollecting gpustat\n",
            "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20210924.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.6.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (3.17.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->-r requirements.txt (line 13)) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->-r requirements.txt (line 13)) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->-r requirements.txt (line 14)) (4.62.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->-r requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->-r requirements.txt (line 14)) (0.8.9)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: gpustat, fvcore\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=a2c2716ccaed638e44b89bff3d4a92daf2f751c46313d5900a187debc1387938\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/67/af/f1ad15974b8fd95f59a63dbf854483ebe5c7a46a93930798b8\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210924-py3-none-any.whl size=60829 sha256=6228b129627a0585ede1d21d54e656d7386b57d0cdce37ff0252e39cbd2e1475\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/c6/de/aa41c65141bdbc9a8aa4b303ce26482aa2f1720ff41b7f17c3\n",
            "Successfully built gpustat fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, blessings, tensorboardX, pyrealsense2, imagecodecs, gpustat, fvcore\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed blessings-1.7 fvcore-0.1.5.post20210924 gpustat-0.6.0 imagecodecs-2021.8.26 iopath-0.1.9 portalocker-2.3.2 pyrealsense2-2.49.0.3474 pyyaml-5.4.1 tensorboardX-2.4 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUrEoBlCdyIe",
        "outputId": "82ece33c-ef16-4323-b072-775c296772d7"
      },
      "source": [
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/cornell-grasp.zip -d /content/cornell_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Grasp_Detection_Workplace/cornell-grasp.zip\n",
            "  inflating: /content/cornell_dataset/01/pcd0100.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0100cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0100cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0100d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0100r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0101.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0101cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0101cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0101d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0101r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0102.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0102cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0102cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0102d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0102r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0103.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0103cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0103cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0103d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0103r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0104.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0104cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0104cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0104d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0104r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0105.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0105cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0105cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0105d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0105r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0106.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0106cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0106cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0106d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0106r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0107.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0107cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0107cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0107d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0107r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0108.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0108cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0108cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0108d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0108r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0109.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0109cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0109cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0109d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0109r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0110.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0110cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0110cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0110d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0110r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0111.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0111cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0111cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0111d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0111r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0112.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0112cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0112cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0112d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0112r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0113.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0113cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0113cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0113d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0113r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0114.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0114cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0114cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0114d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0114r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0115.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0115cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0115cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0115d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0115r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0116.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0116cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0116cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0116d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0116r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0117.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0117cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0117cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0117d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0117r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0118.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0118cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0118cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0118d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0118r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0119.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0119cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0119cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0119d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0119r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0120.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0120cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0120cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0120d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0120r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0121.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0121cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0121cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0121d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0121r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0122.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0122cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0122cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0122d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0122r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0123.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0123cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0123cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0123d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0123r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0124.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0124cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0124cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0124d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0124r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0125.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0125cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0125cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0125d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0125r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0126.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0126cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0126cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0126d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0126r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0127.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0127cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0127cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0127d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0127r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0128.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0128cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0128cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0128d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0128r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0129.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0129cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0129cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0129d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0129r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0130.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0130cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0130cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0130d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0130r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0131.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0131cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0131cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0131d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0131r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0132.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0132cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0132cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0132d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0132r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0133.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0133cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0133cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0133d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0133r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0134.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0134cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0134cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0134d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0134r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0135.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0135cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0135cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0135d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0135r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0136.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0136cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0136cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0136d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0136r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0137.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0137cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0137cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0137d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0137r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0138.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0138cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0138cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0138d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0138r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0139.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0139cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0139cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0139d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0139r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0140.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0140cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0140cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0140d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0140r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0141.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0141cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0141cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0141d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0141r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0142.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0142cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0142cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0142d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0142r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0143.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0143cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0143cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0143d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0143r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0144.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0144cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0144cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0144d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0144r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0145.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0145cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0145cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0145d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0145r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0146.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0146cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0146cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0146d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0146r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0147.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0147cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0147cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0147d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0147r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0148.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0148cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0148cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0148d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0148r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0149.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0149cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0149cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0149d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0149r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0150.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0150cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0150cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0150d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0150r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0151.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0151cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0151cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0151d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0151r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0152.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0152cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0152cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0152d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0152r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0153.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0153cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0153cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0153d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0153r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0154.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0154cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0154cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0154d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0154r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0155.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0155cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0155cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0155d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0155r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0156.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0156cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0156cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0156d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0156r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0157.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0157cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0157cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0157d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0157r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0158.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0158cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0158cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0158d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0158r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0159.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0159cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0159cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0159d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0159r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0160.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0160cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0160cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0160d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0160r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0161.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0161cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0161cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0161d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0161r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0162.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0162cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0162cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0162d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0162r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0163.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0163cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0163cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0163d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0163r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0164.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0164cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0164cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0164d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0164r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0165.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0165cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0165cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0165d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0165r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0166.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0166cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0166cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0166d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0166r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0167.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0167cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0167cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0167d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0167r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0168.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0168cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0168cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0168d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0168r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0169.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0169cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0169cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0169d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0169r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0170.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0170cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0170cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0170d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0170r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0171.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0171cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0171cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0171d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0171r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0172.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0172cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0172cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0172d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0172r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0173.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0173cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0173cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0173d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0173r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0174.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0174cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0174cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0174d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0174r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0175.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0175cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0175cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0175d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0175r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0176.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0176cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0176cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0176d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0176r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0177.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0177cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0177cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0177d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0177r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0178.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0178cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0178cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0178d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0178r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0179.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0179cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0179cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0179d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0179r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0180.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0180cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0180cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0180d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0180r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0181.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0181cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0181cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0181d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0181r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0182.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0182cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0182cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0182d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0182r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0183.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0183cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0183cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0183d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0183r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0184.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0184cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0184cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0184d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0184r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0185.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0185cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0185cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0185d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0187cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0187cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0187d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0187r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0188.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0188cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0188cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0188d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0188r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0189.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0189cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0189cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0189d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0189r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0190.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0190cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0190cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0190d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0190r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0191.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0191cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0191cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0191d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0191r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0192.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0192cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0192cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0192d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0192r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0193.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0193cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0193cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0193d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0193r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0194.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0194cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0194cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0194d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0194r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0195.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0195cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0195cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0195d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0195r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0196.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0196cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0196cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0196d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0196r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0197.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0197cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0197cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0197d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0197r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0198.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0198cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0198cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0198d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0198r.png  \n",
            "  inflating: /content/cornell_dataset/01/pcd0199.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0199cneg.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0199cpos.txt  \n",
            "  inflating: /content/cornell_dataset/01/pcd0199d.tiff  \n",
            "  inflating: /content/cornell_dataset/01/pcd0199r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0200.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0200cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0200cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0200d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0200r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0201.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0201cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0201cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0201d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0201r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0202.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0202cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0202cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0202d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0202r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0203.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0203cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0203cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0203d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0203r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0204.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0204cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0204cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0204d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0204r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0205.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0205cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0205cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0205d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0205r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0206.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0206cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0206cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0206d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0206r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0207.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0207cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0207cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0207d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0207r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0208.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0208cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0208cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0208d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0208r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0209.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0209cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0209cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0209d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0209r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0210.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0210cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0210cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0210d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0210r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0211.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0211cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0211cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0211d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0211r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0212.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0212cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0212cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0212d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0212r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0213.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0213cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0213cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0213d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0213r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0214.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0214cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0214cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0214d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0214r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0215.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0215cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0215cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0215d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0215r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0216.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0216cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0216cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0216d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0216r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0217.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0217cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0217cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0217d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0217r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0218.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0218cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0218cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0218d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0218r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0219.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0219cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0219cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0219d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0219r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0220.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0220cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0220cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0220d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0220r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0221.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0221cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0221cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0221d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0221r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0222.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0222cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0222cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0222d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0222r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0223.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0223cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0223cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0223d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0223r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0224.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0224cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0224cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0224d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0224r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0225.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0225cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0225cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0225d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0225r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0226.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0226cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0226cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0226d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0226r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0227.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0227cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0227cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0227d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0227r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0228.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0228cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0228cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0228d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0228r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0229.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0229cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0229cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0229d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0229r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0230.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0230cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0230cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0230d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0230r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0231.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0231cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0231cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0231d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0231r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0232.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0232cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0232cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0232d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0232r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0233.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0233cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0233cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0233d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0233r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0234.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0234cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0234cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0234d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0234r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0235.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0235cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0235cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0235d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0235r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0236.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0236cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0236cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0236d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0236r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0237.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0237cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0237cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0237d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0237r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0238.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0238cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0238cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0238d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0238r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0239.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0239cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0239cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0239d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0239r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0240.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0240cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0240cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0240d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0240r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0241.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0241cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0241cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0241d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0241r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0242.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0242cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0242cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0242d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0242r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0243.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0243cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0243cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0243d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0243r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0244.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0244cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0244cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0244d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0244r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0245.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0245cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0245cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0245d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0245r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0246.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0246cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0246cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0246d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0246r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0247.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0247cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0247cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0247d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0247r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0248.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0248cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0248cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0248d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0248r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0249.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0249cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0249cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0249d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0249r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0250.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0250cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0250cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0250d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0250r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0251.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0251cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0251cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0251d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0251r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0252.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0252cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0252cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0252d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0252r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0253.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0253cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0253cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0253d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0253r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0254.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0254cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0254cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0254d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0254r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0255.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0255cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0255cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0255d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0255r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0256.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0256cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0256cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0256d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0256r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0257.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0257cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0257cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0257d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0257r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0258.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0258cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0258cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0258d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0258r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0259.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0259cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0259cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0259d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0259r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0260.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0260cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0260cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0260d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0260r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0261.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0261cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0261cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0261d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0261r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0262.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0262cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0262cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0262d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0262r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0263.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0263cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0263cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0263d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0263r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0264.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0264cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0264cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0264d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0264r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0265.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0265cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0265cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0265d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0265r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0266.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0266cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0266cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0266d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0266r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0267.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0267cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0267cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0267d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0267r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0268.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0268cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0268cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0268d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0268r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0269.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0269cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0269cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0269d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0269r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0270.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0270cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0270cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0270d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0270r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0271.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0271cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0271cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0271d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0271r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0272.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0272cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0272cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0272d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0272r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0273.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0273cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0273cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0273d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0273r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0274.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0274cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0274cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0274d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0274r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0275.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0275cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0275cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0275d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0275r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0276.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0276cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0276cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0276d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0276r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0277.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0277cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0277cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0277d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0277r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0278.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0278cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0278cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0278d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0278r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0279.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0279cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0279cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0279d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0279r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0280.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0280cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0280cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0280d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0280r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0281.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0281cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0281cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0281d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0281r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0282.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0282cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0282cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0282d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0282r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0283.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0283cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0283cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0283d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0283r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0284.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0284cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0284cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0284d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0284r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0285.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0285cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0285cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0285d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0285r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0286.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0286cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0286cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0286d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0286r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0287.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0287cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0287cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0287d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0287r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0288.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0288cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0288cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0288d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0288r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0289.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0289cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0289cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0289d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0289r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0290.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0290cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0290cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0290d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0290r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0291.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0291cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0291cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0291d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0291r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0292.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0292cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0292cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0292d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0292r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0293.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0293cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0293cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0293d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0293r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0294.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0294cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0294cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0294d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0294r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0295.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0295cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0295cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0295d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0295r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0296.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0296cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0296cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0296d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0296r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0297.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0297cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0297cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0297d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0297r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0298.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0298cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0298cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0298d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0298r.png  \n",
            "  inflating: /content/cornell_dataset/02/pcd0299.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0299cneg.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0299cpos.txt  \n",
            "  inflating: /content/cornell_dataset/02/pcd0299d.tiff  \n",
            "  inflating: /content/cornell_dataset/02/pcd0299r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0300.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0300cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0300cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0300d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0300r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0301.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0301cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0301cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0301d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0301r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0302.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0302cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0302cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0302d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0302r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0303.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0303cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0303cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0303d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0303r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0304.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0304cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0304cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0304d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0304r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0305.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0305cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0305cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0305d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0305r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0306.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0306cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0306cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0306d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0306r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0307.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0307cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0307cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0307d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0307r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0308.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0308cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0308cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0308d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0308r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0309.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0309cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0309cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0309d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0309r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0310.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0310cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0310cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0310d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0310r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0311.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0311cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0311cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0311d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0311r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0312.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0312cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0312cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0312d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0312r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0313.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0313cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0313cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0313d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0313r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0314.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0314cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0314cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0314d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0314r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0315.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0315cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0315cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0315d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0315r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0316.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0316cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0316cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0316d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0316r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0317.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0317cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0317cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0317d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0317r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0318.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0318cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0318cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0318d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0318r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0319.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0319cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0319cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0319d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0319r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0320.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0320cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0320cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0320d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0320r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0321.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0321cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0321cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0321d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0321r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0322.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0322cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0322cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0322d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0322r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0323.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0323cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0323cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0323d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0323r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0324.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0324cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0324cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0324d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0324r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0325.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0325cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0325cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0325d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0325r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0326.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0326cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0326cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0326d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0326r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0327.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0327cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0327cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0327d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0327r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0328.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0328cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0328cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0328d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0328r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0329.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0329cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0329cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0329d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0329r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0330.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0330cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0330cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0330d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0330r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0331.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0331cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0331cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0331d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0331r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0332.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0332cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0332cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0332d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0332r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0333.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0333cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0333cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0333d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0333r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0334.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0334cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0334cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0334d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0334r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0335.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0335cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0335cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0335d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0335r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0336.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0336cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0336cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0336d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0336r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0337.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0337cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0337cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0337d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0337r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0338.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0338cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0338cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0338d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0338r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0339.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0339cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0339cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0339d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0339r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0340.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0340cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0340cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0340d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0340r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0341.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0341cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0341cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0341d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0341r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0342.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0342cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0342cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0342d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0342r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0343.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0343cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0343cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0343d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0343r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0344.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0344cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0344cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0344d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0344r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0345.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0345cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0345cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0345d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0345r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0346.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0346cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0346cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0346d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0346r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0347.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0347cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0347cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0347d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0347r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0348.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0348cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0348cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0348d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0348r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0349.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0349cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0349cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0349d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0349r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0350.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0350cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0350cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0350d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0350r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0351.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0351cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0351cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0351d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0351r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0352.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0352cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0352cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0352d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0352r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0353.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0353cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0353cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0353d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0353r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0354.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0354cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0354cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0354d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0354r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0355.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0355cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0355cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0355d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0355r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0356.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0356cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0356cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0356d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0356r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0357.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0357cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0357cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0357d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0357r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0358.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0358cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0358cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0358d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0358r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0359.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0359cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0359cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0359d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0359r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0360.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0360cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0360cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0360d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0360r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0361.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0361cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0361cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0361d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0361r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0362.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0362cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0362cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0362d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0362r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0363.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0363cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0363cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0363d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0363r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0364.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0364cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0364cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0364d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0364r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0365.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0365cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0365cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0365d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0365r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0366.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0366cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0366cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0366d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0366r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0367.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0367cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0367cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0367d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0367r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0368.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0368cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0368cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0368d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0368r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0369.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0369cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0369cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0369d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0369r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0370.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0370cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0370cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0370d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0370r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0371.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0371cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0371cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0371d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0371r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0372.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0372cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0372cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0372d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0372r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0373.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0373cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0373cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0373d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0373r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0374.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0374cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0374cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0374d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0374r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0375.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0375cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0375cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0375d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0375r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0376.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0376cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0376cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0376d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0376r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0377.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0377cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0377cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0377d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0377r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0378.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0378cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0378cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0378d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0378r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0379.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0379cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0379cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0379d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0379r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0380.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0380cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0380cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0380d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0380r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0381.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0381cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0381cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0381d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0381r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0382.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0382cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0382cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0382d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0382r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0383.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0383cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0383cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0383d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0383r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0384.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0384cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0384cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0384d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0384r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0385.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0385cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0385cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0385d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0385r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0386.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0386cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0386cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0386d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0386r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0387.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0387cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0387cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0387d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0387r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0388.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0388cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0388cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0388d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0388r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0389.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0389cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0389cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0389d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0389r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0390.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0390cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0390cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0390d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0390r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0391.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0391cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0391cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0391d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0391r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0392.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0392cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0392cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0392d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0392r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0393.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0393cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0393cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0393d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0393r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0394.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0394cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0394cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0394d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0394r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0395.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0395cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0395cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0395d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0395r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0396.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0396cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0396cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0396d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0396r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0397.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0397cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0397cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0397d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0397r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0398.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0398cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0398cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0398d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0398r.png  \n",
            "  inflating: /content/cornell_dataset/03/pcd0399.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0399cneg.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0399cpos.txt  \n",
            "  inflating: /content/cornell_dataset/03/pcd0399d.tiff  \n",
            "  inflating: /content/cornell_dataset/03/pcd0399r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0400.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0400cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0400cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0400d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0400r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0401.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0401cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0401cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0401d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0401r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0402.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0402cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0402cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0402d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0402r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0403.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0403cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0403cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0403d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0403r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0404.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0404cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0404cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0404d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0404r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0405.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0405cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0405cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0405d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0405r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0406.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0406cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0406cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0406d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0406r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0407.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0407cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0407cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0407d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0407r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0408.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0408cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0408cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0408d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0408r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0409.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0409cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0409cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0409d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0409r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0410.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0410cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0410cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0410d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0410r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0411.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0411cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0411cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0411d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0411r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0412.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0412cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0412cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0412d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0412r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0413.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0413cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0413cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0413d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0413r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0414.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0414cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0414cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0414d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0414r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0415.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0415cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0415cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0415d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0415r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0416.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0416cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0416cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0416d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0416r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0417.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0417cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0417cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0417d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0417r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0418.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0418cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0418cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0418d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0418r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0419.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0419cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0419cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0419d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0419r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0420.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0420cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0420cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0420d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0420r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0421.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0421cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0421cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0421d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0421r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0422.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0422cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0422cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0422d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0422r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0423.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0423cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0423cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0423d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0423r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0424.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0424cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0424cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0424d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0424r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0425.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0425cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0425cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0425d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0425r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0426.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0426cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0426cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0426d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0426r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0427.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0427cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0427cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0427d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0427r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0428.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0428cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0428cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0428d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0428r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0429.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0429cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0429cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0429d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0429r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0430.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0430cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0430cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0430d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0430r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0431.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0431cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0431cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0431d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0431r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0432.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0432cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0432cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0432d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0432r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0433.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0433cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0433cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0433d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0433r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0434.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0434cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0434cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0434d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0434r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0435.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0435cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0435cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0435d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0435r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0436.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0436cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0436cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0436d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0436r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0437.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0437cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0437cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0437d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0437r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0438.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0438cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0438cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0438d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0438r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0439.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0439cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0439cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0439d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0439r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0440.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0440cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0440cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0440d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0440r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0441.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0441cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0441cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0441d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0441r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0442.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0442cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0442cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0442d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0442r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0443.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0443cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0443cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0443d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0443r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0444.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0444cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0444cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0444d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0444r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0445.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0445cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0445cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0445d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0445r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0446.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0446cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0446cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0446d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0446r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0447.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0447cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0447cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0447d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0447r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0448.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0448cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0448cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0448d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0448r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0449.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0449cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0449cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0449d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0449r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0450.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0450cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0450cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0450d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0450r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0451.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0451cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0451cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0451d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0451r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0452.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0452cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0452cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0452d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0452r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0453.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0453cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0453cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0453d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0453r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0454.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0454cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0454cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0454d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0454r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0455.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0455cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0455cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0455d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0455r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0456.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0456cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0456cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0456d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0456r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0457.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0457cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0457cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0457d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0457r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0458.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0458cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0458cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0458d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0458r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0459.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0459cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0459cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0459d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0459r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0460.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0460cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0460cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0460d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0460r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0461.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0461cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0461cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0461d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0461r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0462.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0462cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0462cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0462d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0462r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0463.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0463cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0463cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0463d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0463r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0464.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0464cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0464cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0464d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0464r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0465.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0465cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0465cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0465d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0465r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0466.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0466cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0466cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0466d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0466r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0467.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0467cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0467cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0467d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0467r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0468.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0468cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0468cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0468d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0468r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0469.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0469cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0469cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0469d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0469r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0470.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0470cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0470cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0470d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0470r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0471.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0471cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0471cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0471d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0471r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0472.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0472cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0472cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0472d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0472r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0473.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0473cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0473cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0473d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0473r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0474.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0474cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0474cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0474d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0474r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0475.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0475cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0475cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0475d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0475r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0476.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0476cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0476cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0476d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0476r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0477.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0477cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0477cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0477d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0477r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0478.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0478cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0478cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0478d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0478r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0479.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0479cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0479cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0479d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0479r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0480.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0480cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0480cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0480d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0480r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0481.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0481cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0481cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0481d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0481r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0482.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0482cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0482cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0482d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0482r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0483.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0483cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0483cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0483d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0483r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0484.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0484cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0484cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0484d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0484r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0485.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0485cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0485cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0485d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0485r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0486.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0486cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0486cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0486d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0486r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0487.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0487cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0487cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0487d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0487r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0488.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0488cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0488cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0488d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0488r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0489.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0489cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0489cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0489d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0489r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0490.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0490cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0490cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0490d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0490r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0491.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0491cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0491cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0491d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0491r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0492.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0492cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0492cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0492d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0492r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0493.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0493cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0493cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0493d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0493r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0494.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0494cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0494cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0494d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0494r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0495.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0495cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0495cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0495d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0495r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0496.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0496cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0496cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0496d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0496r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0497.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0497cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0497cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0497d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0497r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0498.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0498cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0498cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0498d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0498r.png  \n",
            "  inflating: /content/cornell_dataset/04/pcd0499.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0499cneg.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0499cpos.txt  \n",
            "  inflating: /content/cornell_dataset/04/pcd0499d.tiff  \n",
            "  inflating: /content/cornell_dataset/04/pcd0499r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0500.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0500cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0500cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0500d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0500r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0501.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0501cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0501cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0501d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0501r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0502.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0502cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0502cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0502d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0502r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0503.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0503cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0503cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0503d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0503r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0504.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0504cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0504cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0504d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0504r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0505.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0505cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0505cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0505d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0505r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0506.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0506cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0506cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0506d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0506r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0507.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0507cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0507cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0507d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0507r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0508.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0508cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0508cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0508d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0508r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0509.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0509cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0509cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0509d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0509r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0510.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0510cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0510cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0510d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0510r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0511.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0511cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0511cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0511d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0511r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0512.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0512cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0512cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0512d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0512r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0513.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0513cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0513cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0513d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0513r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0514.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0514cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0514cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0514d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0514r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0515.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0515cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0515cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0515d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0515r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0516.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0516cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0516cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0516d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0516r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0517.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0517cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0517cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0517d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0517r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0518.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0518cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0518cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0518d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0518r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0519.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0519cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0519cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0519d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0519r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0520.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0520cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0520cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0520d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0520r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0521.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0521cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0521cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0521d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0521r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0522.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0522cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0522cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0522d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0522r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0523.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0523cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0523cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0523d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0523r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0524.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0524cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0524cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0524d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0524r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0525.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0525cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0525cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0525d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0525r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0526.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0526cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0526cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0526d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0526r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0527.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0527cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0527cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0527d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0527r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0528.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0528cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0528cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0528d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0528r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0529.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0529cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0529cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0529d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0529r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0530.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0530cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0530cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0530d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0530r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0531.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0531cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0531cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0531d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0531r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0532.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0532cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0532cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0532d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0532r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0533.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0533cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0533cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0533d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0533r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0534.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0534cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0534cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0534d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0534r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0535.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0535cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0535cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0535d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0535r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0536.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0536cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0536cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0536d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0536r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0537.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0537cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0537cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0537d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0537r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0538.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0538cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0538cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0538d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0538r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0539.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0539cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0539cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0539d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0539r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0540.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0540cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0540cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0540d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0540r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0541.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0541cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0541cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0541d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0541r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0542.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0542cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0542cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0542d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0542r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0543.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0543cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0543cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0543d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0543r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0544.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0544cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0544cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0544d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0544r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0545.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0545cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0545cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0545d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0545r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0546.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0546cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0546cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0546d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0546r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0547.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0547cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0547cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0547d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0547r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0548.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0548cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0548cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0548d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0548r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0549.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0549cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0549cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0549d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0549r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0550.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0550cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0550cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0550d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0550r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0551.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0551cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0551cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0551d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0551r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0552.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0552cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0552cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0552d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0552r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0553.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0553cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0553cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0553d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0553r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0554.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0554cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0554cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0554d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0554r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0555.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0555cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0555cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0555d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0555r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0556.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0556cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0556cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0556d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0556r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0557.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0557cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0557cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0557d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0557r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0558.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0558cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0558cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0558d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0558r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0559.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0559cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0559cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0559d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0559r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0560.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0560cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0560cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0560d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0560r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0561.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0561cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0561cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0561d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0561r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0562.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0562cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0562cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0562d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0562r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0563.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0563cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0563cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0563d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0563r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0564.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0564cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0564cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0564d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0564r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0565.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0565cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0565cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0565d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0565r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0566.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0566cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0566cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0566d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0566r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0567.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0567cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0567cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0567d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0567r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0568.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0568cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0568cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0568d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0568r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0569.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0569cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0569cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0569d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0569r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0570.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0570cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0570cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0570d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0570r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0571.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0571cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0571cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0571d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0571r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0572.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0572cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0572cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0572d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0572r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0573.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0573cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0573cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0573d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0573r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0574.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0574cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0574cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0574d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0574r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0575.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0575cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0575cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0575d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0575r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0576.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0576cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0576cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0576d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0576r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0577.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0577cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0577cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0577d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0577r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0578.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0578cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0578cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0578d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0578r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0579.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0579cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0579cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0579d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0579r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0580.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0580cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0580cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0580d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0580r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0581.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0581cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0581cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0581d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0581r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0582.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0582cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0582cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0582d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0582r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0583.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0583cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0583cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0583d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0583r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0584.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0584cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0584cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0584d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0584r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0585.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0585cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0585cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0585d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0585r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0586.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0586cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0586cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0586d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0586r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0587.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0587cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0587cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0587d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0587r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0588.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0588cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0588cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0588d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0588r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0589.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0589cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0589cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0589d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0589r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0590.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0590cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0590cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0590d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0590r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0591.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0591cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0591cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0591d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0591r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0592.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0592cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0592cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0592d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0592r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0593.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0593cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0593cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0593d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0593r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0594.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0594cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0594cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0594d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0594r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0595.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0595cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0595cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0595d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0595r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0596.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0596cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0596cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0596d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0596r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0597.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0597cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0597cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0597d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0597r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0598.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0598cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0598cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0598d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0598r.png  \n",
            "  inflating: /content/cornell_dataset/05/pcd0599.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0599cneg.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0599cpos.txt  \n",
            "  inflating: /content/cornell_dataset/05/pcd0599d.tiff  \n",
            "  inflating: /content/cornell_dataset/05/pcd0599r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0600.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0600cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0600cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0600d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0600r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0601.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0601cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0601cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0601d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0601r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0602.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0602cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0602cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0602d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0602r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0603.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0603cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0603cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0603d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0603r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0604.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0604cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0604cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0604d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0604r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0605.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0605cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0605cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0605d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0605r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0606.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0606cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0606cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0606d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0606r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0607.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0607cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0607cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0607d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0607r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0608.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0608cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0608cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0608d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0608r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0609.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0609cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0609cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0609d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0609r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0610.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0610cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0610cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0610d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0610r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0611.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0611cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0611cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0611d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0611r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0612.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0612cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0612cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0612d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0612r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0613.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0613cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0613cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0613d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0613r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0614.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0614cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0614cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0614d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0614r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0615.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0615cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0615cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0615d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0615r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0616.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0616cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0616cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0616d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0616r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0617.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0617cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0617cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0617d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0617r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0618.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0618cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0618cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0618d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0618r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0619.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0619cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0619cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0619d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0619r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0620.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0620cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0620cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0620d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0620r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0621.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0621cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0621cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0621d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0621r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0622.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0622cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0622cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0622d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0622r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0623.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0623cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0623cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0623d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0623r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0624.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0624cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0624cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0624d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0624r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0625.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0625cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0625cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0625d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0625r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0626.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0626cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0626cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0626d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0626r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0627.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0627cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0627cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0627d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0627r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0628.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0628cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0628cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0628d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0628r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0629.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0629cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0629cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0629d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0629r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0630.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0630cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0630cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0630d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0630r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0631.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0631cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0631cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0631d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0631r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0632.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0632cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0632cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0632d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0632r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0633.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0633cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0633cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0633d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0633r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0634.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0634cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0634cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0634d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0634r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0635.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0635cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0635cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0635d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0635r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0636.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0636cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0636cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0636d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0636r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0637.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0637cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0637cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0637d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0637r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0638.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0638cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0638cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0638d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0638r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0639.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0639cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0639cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0639d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0639r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0640.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0640cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0640cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0640d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0640r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0641.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0641cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0641cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0641d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0641r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0642.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0642cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0642cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0642d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0642r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0643.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0643cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0643cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0643d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0643r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0644.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0644cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0644cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0644d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0644r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0645.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0645cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0645cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0645d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0645r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0646.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0646cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0646cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0646d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0646r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0647.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0647cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0647cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0647d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0647r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0648.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0648cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0648cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0648d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0648r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0649.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0649cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0649cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0649d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0649r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0650.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0650cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0650cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0650d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0650r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0651.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0651cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0651cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0651d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0651r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0652.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0652cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0652cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0652d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0652r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0653.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0653cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0653cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0653d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0653r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0654.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0654cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0654cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0654d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0654r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0655.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0655cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0655cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0655d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0655r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0656.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0656cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0656cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0656d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0656r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0657.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0657cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0657cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0657d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0657r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0658.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0658cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0658cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0658d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0658r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0659.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0659cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0659cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0659d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0659r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0660.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0660cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0660cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0660d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0660r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0661.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0661cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0661cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0661d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0661r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0662.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0662cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0662cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0662d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0662r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0663.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0663cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0663cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0663d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0663r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0664.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0664cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0664cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0664d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0664r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0665.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0665cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0665cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0665d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0665r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0666.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0666cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0666cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0666d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0666r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0667.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0667cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0667cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0667d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0667r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0668.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0668cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0668cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0668d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0668r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0669.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0669cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0669cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0669d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0669r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0670.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0670cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0670cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0670d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0670r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0671.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0671cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0671cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0671d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0671r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0672.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0672cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0672cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0672d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0672r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0673.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0673cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0673cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0673d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0673r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0674.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0674cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0674cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0674d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0674r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0675.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0675cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0675cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0675d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0675r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0676.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0676cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0676cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0676d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0676r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0677.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0677cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0677cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0677d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0677r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0678.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0678cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0678cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0678d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0678r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0679.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0679cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0679cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0679d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0679r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0680.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0680cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0680cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0680d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0680r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0681.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0681cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0681cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0681d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0681r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0682.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0682cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0682cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0682d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0682r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0683.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0683cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0683cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0683d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0683r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0684.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0684cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0684cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0684d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0684r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0685.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0685cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0685cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0685d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0685r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0686.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0686cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0686cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0686d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0686r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0687.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0687cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0687cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0687d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0687r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0688.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0688cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0688cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0688d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0688r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0689.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0689cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0689cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0689d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0689r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0690.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0690cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0690cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0690d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0690r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0691.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0691cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0691cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0691d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0691r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0692.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0692cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0692cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0692d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0692r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0693.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0693cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0693cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0693d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0693r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0694.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0694cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0694cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0694d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0694r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0695.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0695cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0695cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0695d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0695r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0696.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0696cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0696cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0696d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0696r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0697.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0697cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0697cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0697d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0697r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0698.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0698cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0698cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0698d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0698r.png  \n",
            "  inflating: /content/cornell_dataset/06/pcd0699.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0699cneg.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0699cpos.txt  \n",
            "  inflating: /content/cornell_dataset/06/pcd0699d.tiff  \n",
            "  inflating: /content/cornell_dataset/06/pcd0699r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0700.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0700cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0700cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0700d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0700r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0701.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0701cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0701cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0701d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0701r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0702.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0702cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0702cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0702d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0702r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0703.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0703cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0703cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0703d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0703r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0704.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0704cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0704cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0704d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0704r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0705.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0705cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0705cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0705d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0705r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0706.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0706cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0706cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0706d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0706r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0707.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0707cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0707cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0707d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0707r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0708.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0708cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0708cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0708d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0708r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0709.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0709cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0709cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0709d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0709r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0710.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0710cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0710cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0710d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0710r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0711.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0711cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0711cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0711d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0711r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0712.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0712cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0712cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0712d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0712r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0713.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0713cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0713cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0713d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0713r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0714.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0714cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0714cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0714d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0714r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0715.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0715cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0715cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0715d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0715r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0716.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0716cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0716cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0716d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0716r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0717.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0717cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0717cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0717d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0717r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0718.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0718cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0718cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0718d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0718r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0719.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0719cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0719cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0719d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0719r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0720.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0720cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0720cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0720d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0720r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0721.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0721cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0721cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0721d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0721r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0722.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0722cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0722cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0722d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0722r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0723.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0723cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0723cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0723d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0723r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0724.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0724cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0724cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0724d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0724r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0725.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0725cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0725cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0725d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0725r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0726.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0726cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0726cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0726d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0726r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0727.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0727cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0727cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0727d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0727r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0728.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0728cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0728cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0728d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0728r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0729.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0729cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0729cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0729d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0729r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0730.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0730cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0730cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0730d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0730r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0731.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0731cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0731cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0731d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0731r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0732.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0732cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0732cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0732d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0732r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0733.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0733cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0733cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0733d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0733r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0734.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0734cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0734cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0734d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0734r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0735.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0735cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0735cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0735d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0735r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0736.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0736cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0736cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0736d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0736r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0737.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0737cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0737cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0737d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0737r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0738.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0738cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0738cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0738d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0738r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0739.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0739cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0739cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0739d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0739r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0740.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0740cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0740cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0740d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0740r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0741.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0741cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0741cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0741d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0741r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0742.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0742cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0742cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0742d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0742r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0743.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0743cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0743cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0743d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0743r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0744.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0745cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0745cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0745d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0745r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0746.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0746cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0746cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0746d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0746r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0747.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0747cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0747cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0747d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0747r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0748.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0748cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0748cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0748d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0748r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0749.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0749cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0749cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0749d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0749r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0750.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0750cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0750cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0750d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0750r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0751.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0751cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0751cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0751d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0751r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0752.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0752cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0752cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0752d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0752r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0753.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0753cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0753cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0753d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0753r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0754.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0754cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0754cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0754d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0754r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0755.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0755cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0755cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0755d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0755r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0756.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0756cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0756cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0756d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0756r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0757.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0757cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0757cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0757d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0757r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0758.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0758cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0758cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0758d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0758r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0759.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0759cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0759cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0759d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0759r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0760.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0760cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0760cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0760d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0760r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0761.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0761cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0761cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0761d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0761r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0762.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0762cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0762cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0762d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0762r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0763.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0763cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0763cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0763d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0763r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0764.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0764cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0764cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0764d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0764r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0765.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0765cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0765cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0765d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0765r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0766.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0766cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0766cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0766d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0766r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0767.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0767cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0767cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0767d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0767r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0768.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0768cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0768cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0768d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0768r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0769.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0769cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0769cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0769d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0769r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0770.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0770cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0770cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0770d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0770r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0771.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0771cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0771cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0771d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0771r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0772.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0772cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0772cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0772d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0772r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0773.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0773cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0773cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0773d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0773r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0774.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0774cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0774cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0774d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0774r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0775.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0775cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0775cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0775d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0775r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0776.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0776cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0776cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0776d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0776r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0777.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0777cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0777cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0777d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0777r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0778.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0778cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0778cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0778d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0778r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0779.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0779cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0779cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0779d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0779r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0780.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0780cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0780cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0780d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0780r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0781.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0781cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0781cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0781d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0781r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0782.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0782cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0782cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0782d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0782r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0783.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0783cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0783cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0783d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0783r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0784.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0784cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0784cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0784d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0784r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0785.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0785cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0785cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0785d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0785r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0786.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0786cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0786cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0786d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0786r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0787.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0787cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0787cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0787d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0787r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0788.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0788cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0788cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0788d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0788r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0789.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0789cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0789cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0789d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0789r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0790.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0790cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0790cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0790d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0790r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0791.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0791cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0791cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0791d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0791r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0792.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0792cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0792cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0792d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0792r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0793.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0793cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0793cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0793d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0793r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0794.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0794cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0794cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0794d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0794r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0795.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0795cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0795cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0795d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0795r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0796.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0796cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0796cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0796d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0796r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0797.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0797cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0797cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0797d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0797r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0798.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0798cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0798cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0798d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0798r.png  \n",
            "  inflating: /content/cornell_dataset/07/pcd0799.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0799cneg.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0799cpos.txt  \n",
            "  inflating: /content/cornell_dataset/07/pcd0799d.tiff  \n",
            "  inflating: /content/cornell_dataset/07/pcd0799r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0800.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0800cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0800cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0800d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0800r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0801.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0801cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0801cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0801d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0801r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0802.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0802cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0802cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0802d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0802r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0803.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0803cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0803cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0803d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0803r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0804.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0804cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0804cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0804d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0804r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0805.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0805cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0805cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0805d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0805r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0806.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0806cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0806cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0806d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0806r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0807.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0807cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0807cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0807d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0807r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0808.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0808cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0808cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0808d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0808r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0809.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0809cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0809cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0809d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0809r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0810.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0810cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0810cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0810d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0810r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0811.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0811cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0811cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0811d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0811r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0812.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0812cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0812cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0812d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0812r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0813.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0813cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0813cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0813d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0813r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0814.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0814cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0814cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0814d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0814r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0815.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0815cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0815cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0815d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0815r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0816.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0816cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0816cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0816d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0816r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0817.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0817cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0817cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0817d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0817r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0818.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0818cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0818cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0818d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0818r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0819.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0819cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0819cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0819d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0819r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0820.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0820cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0820cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0820d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0820r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0821.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0821cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0821cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0821d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0821r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0822.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0822cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0822cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0822d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0822r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0823.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0823cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0823cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0823d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0823r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0824.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0824cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0824cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0824d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0824r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0825.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0825cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0825cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0825d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0825r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0826.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0826cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0826cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0826d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0826r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0827.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0827cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0827cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0827d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0827r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0828.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0828cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0828cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0828d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0828r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0829.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0829cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0829cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0829d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0829r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0830.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0830cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0830cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0830d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0830r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0831.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0831cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0831cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0831d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0831r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0832.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0832cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0832cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0832d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0832r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0833.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0833cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0833cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0833d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0833r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0834.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0834cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0834cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0834d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0834r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0835.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0835cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0835cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0835d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0835r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0836.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0836cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0836cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0836d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0836r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0837.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0837cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0837cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0837d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0837r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0838.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0838cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0838cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0838d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0838r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0839.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0839cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0839cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0839d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0839r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0840.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0840cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0840cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0840d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0840r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0841.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0841cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0841cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0841d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0841r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0842.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0842cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0842cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0842d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0842r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0843.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0843cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0843cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0843d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0843r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0844.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0844cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0844cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0844d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0844r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0845.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0845cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0845cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0845d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0845r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0846.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0846cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0846cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0846d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0846r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0847.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0847cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0847cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0847d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0847r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0848.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0848cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0848cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0848d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0848r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0849.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0849cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0849cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0849d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0849r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0850.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0850cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0850cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0850d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0850r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0851.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0851cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0851cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0851d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0851r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0852.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0852cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0852cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0852d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0852r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0853.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0853cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0853cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0853d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0853r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0854.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0854cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0854cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0854d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0854r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0855.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0855cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0855cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0855d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0855r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0856.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0856cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0856cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0856d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0856r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0857.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0857cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0857cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0857d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0857r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0858.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0858cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0858cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0858d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0858r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0859.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0859cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0859cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0859d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0859r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0860.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0860cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0860cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0860d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0860r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0861.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0861cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0861cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0861d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0861r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0862.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0862cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0862cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0862d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0862r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0863.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0863cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0863cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0863d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0863r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0864.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0864cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0864cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0864d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0864r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0865.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0865cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0865cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0865d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0865r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0866.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0866cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0866cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0866d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0866r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0867.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0867cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0867cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0867d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0867r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0868.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0868cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0868cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0868d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0868r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0869.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0869cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0869cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0869d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0869r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0870.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0870cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0870cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0870d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0870r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0871.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0871cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0871cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0871d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0871r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0872.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0872cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0872cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0872d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0872r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0873.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0873cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0873cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0873d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0873r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0874.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0874cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0874cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0874d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0874r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0875.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0875cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0875cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0875d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0875r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0876.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0876cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0876cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0876d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0876r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0877.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0877cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0877cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0877d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0877r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0878.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0878cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0878cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0878d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0878r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0879.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0879cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0879cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0879d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0879r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0880.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0880cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0880cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0880d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0880r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0881.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0881cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0881cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0881d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0881r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0882.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0882cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0882cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0882d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0882r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0883.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0883cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0883cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0883d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0883r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0884.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0884cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0884cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0884d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0884r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0885.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0885cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0885cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0885d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0885r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0886.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0886cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0886cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0886d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0886r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0887.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0887cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0887cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0887d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0887r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0888.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0888cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0888cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0888d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0888r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0889.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0889cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0889cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0889d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0889r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0890.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0890cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0890cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0890d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0890r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0891.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0891cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0891cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0891d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0891r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0892.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0892cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0892cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0892d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0892r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0893.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0893cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0893cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0893d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0893r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0894.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0894cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0894cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0894d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0894r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0895.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0895cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0895cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0895d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0895r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0896.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0896cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0896cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0896d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0896r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0897.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0897cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0897cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0897d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0897r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0898.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0898cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0898cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0898d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0898r.png  \n",
            "  inflating: /content/cornell_dataset/08/pcd0899.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0899cneg.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0899cpos.txt  \n",
            "  inflating: /content/cornell_dataset/08/pcd0899d.tiff  \n",
            "  inflating: /content/cornell_dataset/08/pcd0899r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0900.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0900cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0900cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0900d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0900r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0901.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0901cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0901cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0901d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0901r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0902.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0902cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0902cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0902d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0902r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0903.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0903cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0903cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0903d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0903r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0904.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0904cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0904cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0904d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0904r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0905.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0905cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0905cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0905d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0905r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0906.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0906cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0906cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0906d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0906r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0907.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0907cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0907cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0907d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0907r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0908.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0908cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0908cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0908d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0908r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0909.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0909cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0909cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0909d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0909r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0910.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0910cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0910cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0910d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0910r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0911.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0911cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0911cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0911d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0911r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0912.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0912cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0912cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0912d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0912r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0913.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0913cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0913cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0913d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0913r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0914.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0914cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0914cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0914d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0914r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0915.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0915cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0915cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0915d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0915r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0916.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0916cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0916cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0916d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0916r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0917.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0917cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0917cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0917d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0917r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0918.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0918cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0918cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0918d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0918r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0919.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0919cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0919cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0919d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0919r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0920.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0920cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0920cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0920d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0920r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0921.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0921cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0921cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0921d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0921r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0922.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0922cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0922cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0922d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0922r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0923.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0923cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0923cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0923d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0923r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0924.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0924cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0924cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0924d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0924r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0925.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0925cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0925cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0925d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0925r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0926.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0926cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0926cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0926d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0926r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0927.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0927cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0927cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0927d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0927r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0928.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0928cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0928cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0928d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0928r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0929.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0929cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0929cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0929d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0929r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0930.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0930cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0930cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0930d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0930r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0931.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0931cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0931cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0931d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0931r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0932.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0932cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0932cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0932d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0932r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0933.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0933cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0933cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0933d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0933r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0934.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0934cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0934cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0934d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0934r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0935.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0935cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0935cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0935d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0935r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0936.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0936cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0936cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0936d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0936r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0937.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0937cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0937cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0937d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0937r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0938.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0938cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0938cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0938d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0938r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0939.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0939cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0939cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0939d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0939r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0940.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0940cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0940cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0940d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0940r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0941.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0941cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0941cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0941d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0941r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0942.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0942cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0942cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0942d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0942r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0943.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0943cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0943cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0943d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0943r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0944.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0944cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0944cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0944d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0944r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0945.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0945cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0945cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0945d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0945r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0946.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0946cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0946cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0946d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0946r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0947.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0947cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0947cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0947d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0947r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0948.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0948cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0948cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0948d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0948r.png  \n",
            "  inflating: /content/cornell_dataset/09/pcd0949.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0949cneg.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0949cpos.txt  \n",
            "  inflating: /content/cornell_dataset/09/pcd0949d.tiff  \n",
            "  inflating: /content/cornell_dataset/09/pcd0949r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1000.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1000cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1000cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1000d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1000r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1001.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1001cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1001cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1001d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1001r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1002.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1002cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1002cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1002d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1002r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1003.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1003cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1003cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1003d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1003r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1004.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1004cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1004cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1004d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1004r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1005.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1005cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1005cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1005d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1005r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1006.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1006cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1006cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1006d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1006r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1007.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1007cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1007cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1007d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1007r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1008.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1008cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1008cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1008d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1008r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1009.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1009cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1009cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1009d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1009r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1010.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1010cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1010cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1010d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1010r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1011.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1011cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1011cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1011d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1011r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1012.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1012cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1012cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1012d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1012r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1013.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1013cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1013cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1013d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1013r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1014.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1014cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1014cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1014d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1014r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1015.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1015cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1015cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1015d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1015r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1016.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1016cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1016cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1016d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1016r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1017.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1017cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1017cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1017d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1017r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1018.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1018cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1018cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1018d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1018r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1019.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1019cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1019cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1019d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1019r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1020.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1020cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1020cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1020d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1020r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1021.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1021cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1021cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1021d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1021r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1022.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1022cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1022cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1022d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1022r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1023.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1023cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1023cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1023d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1023r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1024.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1024cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1024cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1024d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1024r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1025.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1025cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1025cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1025d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1025r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1026.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1026cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1026cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1026d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1026r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1027.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1027cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1027cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1027d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1027r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1028.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1028cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1028cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1028d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1028r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1029.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1029cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1029cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1029d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1029r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1030.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1030cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1030cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1030d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1030r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1031.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1031cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1031cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1031d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1031r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1032.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1032cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1032cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1032d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1032r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1033.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1033cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1033cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1033d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1033r.png  \n",
            "  inflating: /content/cornell_dataset/10/pcd1034.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1034cneg.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1034cpos.txt  \n",
            "  inflating: /content/cornell_dataset/10/pcd1034d.tiff  \n",
            "  inflating: /content/cornell_dataset/10/pcd1034r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0002r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0003r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0004r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0005r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0006r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0007r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0008r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0010r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0011r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0012r.png  \n",
            "  inflating: /content/cornell_dataset/backgrounds/pcdb0013r.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ-Eb7d7oUfL"
      },
      "source": [
        "filepath='/content/drive/MyDrive/GR_ConvNet_Code/logs'\n",
        "if not os.path.exists(filepath):\n",
        "    os.mkdir(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsx4KtUdIbAQ"
      },
      "source": [
        "# Transfer to .tiff Depth Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwvHqN6DmUEW",
        "outputId": "92d73693-8fd3-437e-82e2-d630e25c01d3"
      },
      "source": [
        "%%writefile /content/drive/MyDrive/GR_ConvNet_Code/utils/dataset_processing/generate_cornell_depth2.py\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from imageio import imsave\n",
        "\n",
        "from utils.dataset_processing.image import DepthImage\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Generate depth images from Cornell PCD files.')\n",
        "    #parser.add_argument('path', type=str, help='Path to Cornell Grasping Dataset')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    pcd = '/content/drive/MyDrive/cornell_grasp_dataset/02/pcd0223.txt'\n",
        "    di = DepthImage.from_pcd(pcd, (480, 640))\n",
        "    di.inpaint()\n",
        "    of_name = '../pcd0223test.tiff'\n",
        "    print(of_name)\n",
        "    imsave(of_name, di.img.astype(np.float32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/GR_ConvNet_Code/utils/dataset_processing/generate_cornell_depth2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO5xsspqnAKf",
        "outputId": "5cef358d-9d60-4454-b16c-cc7f4b1b6620"
      },
      "source": [
        "!python -m utils.dataset_processing.generate_cornell_depth2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../pcd0223test.tiff\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWzRBQMTInCC"
      },
      "source": [
        "# Check cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmLFrDFq7Fvt",
        "outputId": "986eacc1-d092-41ff-a16c-b30d0d14a5e6"
      },
      "source": [
        "import torch\n",
        "# 判断cuda是否可用；\n",
        "print(torch.cuda.is_available())\n",
        "# 获取gpu数量；\n",
        "print(torch.cuda.device_count())\n",
        "# 获取gpu名字；\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# 返回当前gpu设备索引，默认从0开始；\n",
        "print(torch.cuda.current_device())\n",
        "# 查看tensor或者model在哪块GPU上\n",
        "print(torch.tensor([0]).get_device())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n",
            "0\n",
            "-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt2dsDXkFhvR",
        "outputId": "72121230-e273-4294-f16f-efe46beae608"
      },
      "source": [
        "!cat /proc/cpuinfo \n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 2\n",
            "initial apicid\t: 2\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 2\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 3\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 3\n",
            "initial apicid\t: 3\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "Wed Apr  7 03:06:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMExlRQQJoQG"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZDVoH97K9nt",
        "outputId": "fac2b703-e3cc-43e5-995b-ad231ce43ae6"
      },
      "source": [
        "from utils.data import get_dataset\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "\n",
        "Dataset = get_dataset(\"cornell\")\n",
        "dataset = Dataset('/content/cornell_dataset',\n",
        "                      ds_rotate=0.0,\n",
        "                      random_rotate=True,\n",
        "                      random_zoom=True,\n",
        "                      include_depth=1,\n",
        "                      include_rgb=1)\n",
        "\n",
        "indices = list(range(dataset.length))\n",
        "print(indices)\n",
        "\n",
        "indices = indices[int(dataset.length*0.2):] + indices[:int(dataset.length*0.2)]\n",
        "print(indices)\n",
        "print(len(indices))\n",
        "print(indices[-1])\n",
        "print('--------------')\n",
        "\n",
        "split = int(np.floor(0.8 * dataset.length))\n",
        "# if True:\n",
        "        # np.random.seed(123)\n",
        "        # np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
        "print(train_indices)\n",
        "print('After reshuffling at every epoch...')\n",
        "\n",
        "# np.random.seed(None)\n",
        "# np.random.shuffle(train_indices)\n",
        "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
        "\n",
        "train_data = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=8,\n",
        "    num_workers=8,\n",
        "    sampler=train_sampler\n",
        "    # shuffle=False\n",
        ")\n",
        "val_data = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    num_workers=8,\n",
        "    sampler=val_sampler\n",
        ")\n",
        "\n",
        "print(type(train_indices))\n",
        "print(type(train_sampler))\n",
        "print(type(train_data))\n",
        "print(train_indices)\n",
        "print(train_sampler)\n",
        "print(train_sampler.indices)\n",
        "print(train_data)\n",
        "print(train_data.sampler.indices)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884]\n",
            "[177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176]\n",
            "885\n",
            "176\n",
            "--------------\n",
            "[177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884]\n",
            "After reshuffling at every epoch...\n",
            "<class 'list'>\n",
            "<class 'torch.utils.data.sampler.SubsetRandomSampler'>\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n",
            "[177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884]\n",
            "<torch.utils.data.sampler.SubsetRandomSampler object at 0x7fb73f2652d0>\n",
            "[177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884]\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7fb73f24d850>\n",
            "[177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoi64yXmYDkG"
      },
      "source": [
        "# make a unlimited generator demo\n",
        "def yes_or_no():\n",
        "    while True:\n",
        "        yield \"yes\"\n",
        "        yield \"no\"\n",
        "g=yes_or_no()\n",
        "for i in range(20):\n",
        "    print(next(g))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW9AZugstdcz"
      },
      "source": [
        "Tasks:\n",
        "\n",
        "1. If the speed is improved by setting the params -num-workers 20 --batch-size 16 --batches-per-epoch 500 ? -  *not evident*\n",
        "2. If the network is trained better (detection accuracy, the trend of loss) when the params are set as above ? -  \n",
        "\n",
        "**Optimal Performance:** The best performance has reached **0.955** without any shuffling operation.   \n",
        "**batchsize=16**, channel_size=32, **learning rate=0.001**, use rgbd, split=0.9  \n",
        "\n",
        "Results are saved in /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell\n",
        "\n",
        "\n",
        "**Another Optimal Performance** has reached **0.966**\n",
        "batchsize=8, channel_size=32, learning rate=0.001, use rgbd, split=0.9  \n",
        "Results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell    \n",
        "\n",
        "**Note that**      \n",
        "*  no shuffling, \n",
        "*  the validation set contains only 89 images \n",
        "*  the original training set is larger than ones in 5-fold validation  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kQH3UDrrGjR",
        "outputId": "9f06ee63-1188-42bf-a1d0-a79cfb0bc0db"
      },
      "source": [
        "!python train_network.py --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 20 --batch-size 16 --batches-per-epoch 500"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 796\n",
            "root        : INFO     Validation size: 89\n",
            "root        : INFO     Done\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1139\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0923\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0999\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1055\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     39/89 = 0.438202\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0847\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0771\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0728\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0786\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     54/89 = 0.606742\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1082\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0802\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0703\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0796\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     73/89 = 0.820225\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0827\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0553\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0757\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0649\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     68/89 = 0.764045\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0565\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0619\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0774\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0601\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     75/89 = 0.842697\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0797\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0675\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0554\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0569\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     72/89 = 0.808989\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0492\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0804\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0689\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0664\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     74/89 = 0.831461\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0546\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0584\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0532\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0858\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     84/89 = 0.943820\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0922\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0558\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0704\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0805\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0868\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1034\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0469\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0544\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0862\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0739\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0725\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0939\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     82/89 = 0.921348\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0810\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0745\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0626\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0575\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     72/89 = 0.808989\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0598\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0593\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0506\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0599\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     82/89 = 0.921348\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0384\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0620\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0724\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0588\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0453\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0700\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0726\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0665\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     84/89 = 0.943820\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0557\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0408\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0535\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0529\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0761\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0616\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0574\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0718\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     77/89 = 0.865169\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0479\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0766\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0556\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0836\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0301\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0414\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0748\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0607\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     76/89 = 0.853933\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0324\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0538\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0549\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0626\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     75/89 = 0.842697\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0583\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0624\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0914\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0511\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0758\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0493\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0771\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0689\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     77/89 = 0.865169\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0569\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0629\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0693\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0638\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     72/89 = 0.808989\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0383\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0507\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0565\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0630\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0404\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0548\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0431\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0378\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     85/89 = 0.955056\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0590\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0539\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0604\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0467\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     77/89 = 0.865169\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0682\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0395\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0411\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0462\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0717\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0589\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0910\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0740\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     79/89 = 0.887640\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0746\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0594\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0520\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0751\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     79/89 = 0.887640\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0536\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0587\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0491\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0600\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/89 = 0.932584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll5WcbwanCek",
        "outputId": "2e4fdba8-a408-497a-d4fc-5644f5b7a603"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 89\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 100.25539558924986ms\n",
            "INFO:root:IOU Results: 85/89 = 0.955056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvOwhX7LqMv0",
        "outputId": "26480c0f-fded-4bb7-faa1-d32d53a454f2"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --ds-rotate 520 --augment --ds-shuffle --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 102.03508307031318ms\n",
            "INFO:root:IOU Results: 816/885 = 0.922034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVK2bOWVsjhn",
        "outputId": "bbc95e44-64fd-4600-b8db-214bb5e35fc3"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --augment --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 99.31852642425709ms\n",
            "INFO:root:IOU Results: 828/885 = 0.935593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSs9FeW2p5TT",
        "outputId": "686b9a42-f588-4b2b-d76e-e1ed42d4ae68"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210323_0421_training_cornell/epoch_24_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 95.27233738010213ms\n",
            "INFO:root:IOU Results: 764/885 = 0.863277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvctzxKvvZwx"
      },
      "source": [
        "Conclusions of the 4 evaluation experiments above:\n",
        "\n",
        "1. Augmentation before evaluating the whole data will improve the detection accuracy. -  **why ?**\n",
        "2. when evaluate the network, the augmented dataset performs better than the original one. However, the augmented images are not counted in the validation set, so does the training proces. - **why ?**\n",
        "3. The results of evaluate.py in evaluate process performs the same with utils/dataset_processing/evaluation.py in training process. - **But what are the differences ?**\n",
        "    Why there is not net.eval() in evaluate.py?\n",
        "4. Why the batch_size of test set in evaluation segment should only be assigned to 1?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTqe0R25rL2O",
        "outputId": "970d05e5-f5db-46d7-8c66-d0ebc4e6aa82"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell/epoch_13_iou_0.97 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 89\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell/epoch_13_iou_0.97\n",
            "INFO:root:Average evaluation time per image: 104.38177826699247ms\n",
            "INFO:root:IOU Results: 86/89 = 0.966292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUCnrJ4dq9pY",
        "outputId": "27571f74-375b-4769-c319-092d23bbea08"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell/epoch_13_iou_0.97 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --ds-rotate 520 --augment --ds-shuffle --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell/epoch_13_iou_0.97\n",
            "INFO:root:Average evaluation time per image: 99.10004502635891ms\n",
            "INFO:root:IOU Results: 742/885 = 0.838418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEc99x1Lrsov",
        "outputId": "84c9db23-4361-4dcf-de40-088092230846"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell/epoch_13_iou_0.97 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --split 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell/epoch_13_iou_0.97\n",
            "INFO:root:Average evaluation time per image: 94.51917174172267ms\n",
            "INFO:root:IOU Results: 708/885 = 0.800000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsNvuDpImDtW"
      },
      "source": [
        "Tasks:\n",
        " \n",
        "\n",
        "1. logging infomation added  √\n",
        "2. save model of every epoch √\n",
        "3. reshuffle at every epoch  √\n",
        "4. if the speed is improved after altering the num_of_work to 40 - *not evident* \n",
        "5. if the network is trained better (detection accuracy, the trend of loss) when batch_size=8 (batchs per epoch =1000)\n",
        "\n",
        "The best performance has reached **0.955**, but the dataset was shuffled firstly before dividing into training set and validation set, which means that **the most objects in validation set were not novel**. \n",
        "\n",
        "Results are saved in /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQoxZH6ztITq",
        "outputId": "7a954af2-a6f3-4bcb-9d7a-b0de51a0e3bb"
      },
      "source": [
        "!python train_network.py --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --ds-shuffle --num-workers 40 --random-seed 520"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.90, ds-rotate = 0.00, number of workers = 40, random seed = 520.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 1000, optimizer = adam\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 796\n",
            "root        : INFO     Validation size: 89\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1031\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1472\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0602\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1537\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.1170\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1183\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0556\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1033\n",
            "root        : INFO     Epoch: 0, Batch: 900, Loss: 0.1431\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     62/89 = 0.696629\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0796\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1508\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0598\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0664\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.1405\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.1171\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.1517\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0310\n",
            "root        : INFO     Epoch: 1, Batch: 900, Loss: 0.2065\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     74/89 = 0.831461\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1113\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.1674\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.1809\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0702\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0822\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0464\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.1188\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0931\n",
            "root        : INFO     Epoch: 2, Batch: 900, Loss: 0.0595\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     70/89 = 0.786517\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0788\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.2113\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.1514\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0868\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0966\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0996\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0919\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0867\n",
            "root        : INFO     Epoch: 3, Batch: 900, Loss: 0.0908\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1441\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0932\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1294\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0654\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.2193\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.1406\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.1000\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.1552\n",
            "root        : INFO     Epoch: 4, Batch: 900, Loss: 0.0592\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     71/89 = 0.797753\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0680\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0371\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0784\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.1041\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.1416\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.1549\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0912\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.1222\n",
            "root        : INFO     Epoch: 5, Batch: 900, Loss: 0.0766\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     79/89 = 0.887640\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0714\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0418\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0623\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.1288\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.1240\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0961\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0496\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0620\n",
            "root        : INFO     Epoch: 6, Batch: 900, Loss: 0.1069\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     84/89 = 0.943820\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0736\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0710\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0797\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0611\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0476\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.1134\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0907\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0761\n",
            "root        : INFO     Epoch: 7, Batch: 900, Loss: 0.1298\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0902\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0600\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0992\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0558\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0309\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0387\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0462\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0325\n",
            "root        : INFO     Epoch: 8, Batch: 900, Loss: 0.0957\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/89 = 0.932584\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0382\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0419\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0629\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0758\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0744\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0226\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0209\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0542\n",
            "root        : INFO     Epoch: 9, Batch: 900, Loss: 0.0672\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.1053\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0556\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.1134\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0422\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0644\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0891\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0624\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0487\n",
            "root        : INFO     Epoch: 10, Batch: 900, Loss: 0.0586\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0527\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0545\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0199\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0193\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0317\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0733\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0645\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0413\n",
            "root        : INFO     Epoch: 11, Batch: 900, Loss: 0.0530\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/89 = 0.932584\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0474\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0390\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0687\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0360\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.1069\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0335\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0408\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0805\n",
            "root        : INFO     Epoch: 12, Batch: 900, Loss: 0.0464\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     82/89 = 0.921348\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0272\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0767\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0591\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0297\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0319\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0728\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0480\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0501\n",
            "root        : INFO     Epoch: 13, Batch: 900, Loss: 0.0516\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/89 = 0.932584\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0616\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0704\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0354\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0835\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0578\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0772\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0925\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.1374\n",
            "root        : INFO     Epoch: 14, Batch: 900, Loss: 0.0332\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.1311\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.1563\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0702\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.1384\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0393\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.1096\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0316\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0523\n",
            "root        : INFO     Epoch: 15, Batch: 900, Loss: 0.0384\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0835\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0793\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0525\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0657\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.1512\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0609\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.1033\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0669\n",
            "root        : INFO     Epoch: 16, Batch: 900, Loss: 0.1107\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     85/89 = 0.955056\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.1301\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.1233\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0901\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.1385\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.1357\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0617\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0820\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.1245\n",
            "root        : INFO     Epoch: 17, Batch: 900, Loss: 0.0424\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0635\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.1431\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0709\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.1212\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.1936\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0736\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.0985\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0903\n",
            "root        : INFO     Epoch: 18, Batch: 900, Loss: 0.0689\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/89 = 0.932584\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0367\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0753\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.1565\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0880\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0401\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.0837\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0792\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0712\n",
            "root        : INFO     Epoch: 19, Batch: 900, Loss: 0.0360\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0611\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0710\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0789\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0335\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.0344\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0916\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.0743\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.0475\n",
            "root        : INFO     Epoch: 20, Batch: 900, Loss: 0.0522\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     79/89 = 0.887640\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0737\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.1437\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0557\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0745\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.0816\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.1794\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.1177\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0618\n",
            "root        : INFO     Epoch: 21, Batch: 900, Loss: 0.0366\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     82/89 = 0.921348\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0779\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0696\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0552\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0484\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0901\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.0423\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.0415\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.0455\n",
            "root        : INFO     Epoch: 22, Batch: 900, Loss: 0.0333\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0469\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0794\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0591\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0528\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0528\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0886\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.0374\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.0905\n",
            "root        : INFO     Epoch: 23, Batch: 900, Loss: 0.0752\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     82/89 = 0.921348\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0808\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0800\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0854\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0510\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.1212\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.1015\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.0324\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.1025\n",
            "root        : INFO     Epoch: 24, Batch: 900, Loss: 0.0848\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     76/89 = 0.853933\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0414\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0890\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0280\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0523\n",
            "root        : INFO     Epoch: 25, Batch: 500, Loss: 0.0451\n",
            "root        : INFO     Epoch: 25, Batch: 600, Loss: 0.0812\n",
            "root        : INFO     Epoch: 25, Batch: 700, Loss: 0.0431\n",
            "root        : INFO     Epoch: 25, Batch: 800, Loss: 0.0417\n",
            "root        : INFO     Epoch: 25, Batch: 900, Loss: 0.0299\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/89 = 0.898876\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0396\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0451\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0459\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0484\n",
            "root        : INFO     Epoch: 26, Batch: 500, Loss: 0.0507\n",
            "root        : INFO     Epoch: 26, Batch: 600, Loss: 0.0634\n",
            "root        : INFO     Epoch: 26, Batch: 700, Loss: 0.0527\n",
            "root        : INFO     Epoch: 26, Batch: 800, Loss: 0.0421\n",
            "root        : INFO     Epoch: 26, Batch: 900, Loss: 0.0748\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/89 = 0.932584\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0599\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0292\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0553\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.1020\n",
            "root        : INFO     Epoch: 27, Batch: 500, Loss: 0.0603\n",
            "root        : INFO     Epoch: 27, Batch: 600, Loss: 0.0401\n",
            "root        : INFO     Epoch: 27, Batch: 700, Loss: 0.0645\n",
            "root        : INFO     Epoch: 27, Batch: 800, Loss: 0.1146\n",
            "root        : INFO     Epoch: 27, Batch: 900, Loss: 0.0546\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     81/89 = 0.910112\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0541\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0536\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0220\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0328\n",
            "root        : INFO     Epoch: 28, Batch: 500, Loss: 0.0684\n",
            "root        : INFO     Epoch: 28, Batch: 600, Loss: 0.0518\n",
            "root        : INFO     Epoch: 28, Batch: 700, Loss: 0.0371\n",
            "root        : INFO     Epoch: 28, Batch: 800, Loss: 0.0747\n",
            "root        : INFO     Epoch: 28, Batch: 900, Loss: 0.0486\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     74/89 = 0.831461\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0481\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0497\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0509\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0952\n",
            "root        : INFO     Epoch: 29, Batch: 500, Loss: 0.1399\n",
            "root        : INFO     Epoch: 29, Batch: 600, Loss: 0.0337\n",
            "root        : INFO     Epoch: 29, Batch: 700, Loss: 0.0892\n",
            "root        : INFO     Epoch: 29, Batch: 800, Loss: 0.0529\n",
            "root        : INFO     Epoch: 29, Batch: 900, Loss: 0.0677\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     75/89 = 0.842697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOfjKdmQzs0Z",
        "outputId": "694521a8-73dd-4531-f8ef-06be5e8e9537"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_16_iou_0.96 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --augment --ds-shuffle --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_16_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 104.29836073837711ms\n",
            "INFO:root:IOU Results: 807/885 = 0.911864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu3PWnsU0NCq",
        "outputId": "d6567606-d763-4ba1-fc46-b48a3a80d128"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_16_iou_0.96 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_16_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 97.35761389220501ms\n",
            "INFO:root:IOU Results: 777/885 = 0.877966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go0Sgsyd0TCq",
        "outputId": "19ce7d2e-89f6-4eab-afb2-5b5ea4b2c5db"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_16_iou_0.96 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --random-seed 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 89\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_16_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 105.71914308526542ms\n",
            "INFO:root:IOU Results: 85/89 = 0.955056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaAl5I8i2Suk"
      },
      "source": [
        "Why do different random-seeds (520, 123, 20, etc) achieve the same evaluation results ?\n",
        "\n",
        "\n",
        "*   Is the validation results in training process caculated by cross-validation (but why the detection result of the whole set is so low)? \n",
        "*   Is the random seed in evaluate.py only change the order of the 89 images but the images themselves is unable to be changed?\n",
        "\n",
        "*   the evaluate.py results is diffrent from the results of validation in training, **is that caused by reshuffling ?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI8pWF70YPSj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j129kPx0iG8",
        "outputId": "bb999a9c-844b-480d-a3a9-ce48e9c43757"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_29_iou_0.84 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --ds-shuffle --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_29_iou_0.84\n",
            "INFO:root:Average evaluation time per image: 100.96240232219805ms\n",
            "INFO:root:IOU Results: 730/885 = 0.824859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi0ZJ8Cs4_zI",
        "outputId": "22db3735-fbe8-4a46-8b85-ac040286a9d1"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_29_iou_0.84 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 89\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_29_iou_0.84\n",
            "INFO:root:Average evaluation time per image: 106.66910985882362ms\n",
            "INFO:root:IOU Results: 81/89 = 0.910112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XO3egFE5NRS",
        "outputId": "0768665a-cf27-48bb-d33d-3308c2b7caad"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_29_iou_0.84 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --random-seed 520"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 89\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_29_iou_0.84\n",
            "INFO:root:Average evaluation time per image: 104.3187848637613ms\n",
            "INFO:root:IOU Results: 81/89 = 0.910112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Raeapn7x02Sx",
        "outputId": "80de41ad-c24a-4894-f8d2-e5be873f5308"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_26_iou_0.93 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --split 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_26_iou_0.93\n",
            "INFO:root:Average evaluation time per image: 100.01989704067424ms\n",
            "INFO:root:IOU Results: 798/885 = 0.901695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzqlnEL-4VkZ",
        "outputId": "84ebcabd-1f7b-489a-afc1-3bfb1c23a4f4"
      },
      "source": [
        "!python evaluate.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_26_iou_0.93 --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --iou-eval --random-seed 520"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 89\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210324_0457_training_cornell/epoch_26_iou_0.93\n",
            "INFO:root:Average evaluation time per image: 105.84091068653578ms\n",
            "INFO:root:IOU Results: 85/89 = 0.955056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vENBZha843vZ"
      },
      "source": [
        "What the hell...?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWeaWYmVZRhr",
        "outputId": "43195e97-910a-44c3-dd25-5324dac069c1"
      },
      "source": [
        "!python run_offline.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210402_0701_training_cornell/epoch_19_iou_0.92 --rgb_path /content/cornell_grasp_dataset/06/pcd0601r.png --depth_path /content/cornell_grasp_dataset/06/pcd0601d.tiff --save 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:Loading image...\n",
            "INFO:root:Loading model...\n",
            "INFO:root:Done\n",
            "INFO:root:CUDA detected. Running with GPU acceleration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcWE-qc4R-XP",
        "outputId": "22c9eac4-fb34-4844-ecaf-3f3c43f80cac"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8 --ds-shuffle --ds-rotate 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 16\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 16, bacthes per epoch = 448, optimizer = adam\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]           5,200\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "            Conv2d-3         [-1, 32, 112, 112]           8,224\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            "            Conv2d-5           [-1, 64, 56, 56]          32,832\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "            Conv2d-7           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "           Conv2d-24           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "           Conv2d-29           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-31           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 32, 113, 113]          32,800\n",
            "      BatchNorm2d-33         [-1, 32, 113, 113]              64\n",
            "  ConvTranspose2d-34         [-1, 16, 225, 225]           8,208\n",
            "      BatchNorm2d-35         [-1, 16, 225, 225]              32\n",
            "  ConvTranspose2d-36         [-1, 16, 225, 225]          20,752\n",
            "          Dropout-37         [-1, 16, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]              65\n",
            "          Dropout-39         [-1, 16, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]              65\n",
            "          Dropout-41         [-1, 16, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]              65\n",
            "          Dropout-43         [-1, 16, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 479,156\n",
            "Trainable params: 479,156\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 110.74\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 113.34\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 10, Loss: 0.4007\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1815\n",
            "root        : INFO     Epoch: 0, Batch: 30, Loss: 0.1893\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.1758\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1564\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.1433\n",
            "root        : INFO     Epoch: 0, Batch: 70, Loss: 0.1721\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.1481\n",
            "root        : INFO     Epoch: 0, Batch: 90, Loss: 0.1372\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1717\n",
            "root        : INFO     Epoch: 0, Batch: 110, Loss: 0.0871\n",
            "root        : INFO     Epoch: 0, Batch: 120, Loss: 0.1577\n",
            "root        : INFO     Epoch: 0, Batch: 130, Loss: 0.1136\n",
            "root        : INFO     Epoch: 0, Batch: 140, Loss: 0.1197\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1467\n",
            "root        : INFO     Epoch: 0, Batch: 160, Loss: 0.1905\n",
            "root        : INFO     Epoch: 0, Batch: 170, Loss: 0.1427\n",
            "root        : INFO     Epoch: 0, Batch: 180, Loss: 0.1676\n",
            "root        : INFO     Epoch: 0, Batch: 190, Loss: 0.1179\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1115\n",
            "root        : INFO     Epoch: 0, Batch: 210, Loss: 0.1226\n",
            "root        : INFO     Epoch: 0, Batch: 220, Loss: 0.1045\n",
            "root        : INFO     Epoch: 0, Batch: 230, Loss: 0.1390\n",
            "root        : INFO     Epoch: 0, Batch: 240, Loss: 0.1793\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.1237\n",
            "root        : INFO     Epoch: 0, Batch: 260, Loss: 0.1247\n",
            "root        : INFO     Epoch: 0, Batch: 270, Loss: 0.1162\n",
            "root        : INFO     Epoch: 0, Batch: 280, Loss: 0.1459\n",
            "root        : INFO     Epoch: 0, Batch: 290, Loss: 0.1114\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1241\n",
            "root        : INFO     Epoch: 0, Batch: 310, Loss: 0.1470\n",
            "root        : INFO     Epoch: 0, Batch: 320, Loss: 0.1084\n",
            "root        : INFO     Epoch: 0, Batch: 330, Loss: 0.1722\n",
            "root        : INFO     Epoch: 0, Batch: 340, Loss: 0.1089\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1398\n",
            "root        : INFO     Epoch: 0, Batch: 360, Loss: 0.1084\n",
            "root        : INFO     Epoch: 0, Batch: 370, Loss: 0.1218\n",
            "root        : INFO     Epoch: 0, Batch: 380, Loss: 0.0811\n",
            "root        : INFO     Epoch: 0, Batch: 390, Loss: 0.1368\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0925\n",
            "root        : INFO     Epoch: 0, Batch: 410, Loss: 0.1122\n",
            "root        : INFO     Epoch: 0, Batch: 420, Loss: 0.1064\n",
            "root        : INFO     Epoch: 0, Batch: 430, Loss: 0.1129\n",
            "root        : INFO     Epoch: 0, Batch: 440, Loss: 0.1364\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     64/177 = 0.361582\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 10, Loss: 0.1319\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.1313\n",
            "root        : INFO     Epoch: 1, Batch: 30, Loss: 0.1024\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.1246\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0899\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0899\n",
            "root        : INFO     Epoch: 1, Batch: 70, Loss: 0.0848\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0903\n",
            "root        : INFO     Epoch: 1, Batch: 90, Loss: 0.1781\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1110\n",
            "root        : INFO     Epoch: 1, Batch: 110, Loss: 0.1387\n",
            "root        : INFO     Epoch: 1, Batch: 120, Loss: 0.0963\n",
            "root        : INFO     Epoch: 1, Batch: 130, Loss: 0.1222\n",
            "root        : INFO     Epoch: 1, Batch: 140, Loss: 0.1236\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.1017\n",
            "root        : INFO     Epoch: 1, Batch: 160, Loss: 0.0965\n",
            "root        : INFO     Epoch: 1, Batch: 170, Loss: 0.0911\n",
            "root        : INFO     Epoch: 1, Batch: 180, Loss: 0.1755\n",
            "root        : INFO     Epoch: 1, Batch: 190, Loss: 0.1046\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1516\n",
            "root        : INFO     Epoch: 1, Batch: 210, Loss: 0.1011\n",
            "root        : INFO     Epoch: 1, Batch: 220, Loss: 0.1279\n",
            "root        : INFO     Epoch: 1, Batch: 230, Loss: 0.0935\n",
            "root        : INFO     Epoch: 1, Batch: 240, Loss: 0.0772\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.1123\n",
            "root        : INFO     Epoch: 1, Batch: 260, Loss: 0.1376\n",
            "root        : INFO     Epoch: 1, Batch: 270, Loss: 0.1245\n",
            "root        : INFO     Epoch: 1, Batch: 280, Loss: 0.1151\n",
            "root        : INFO     Epoch: 1, Batch: 290, Loss: 0.0909\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1102\n",
            "root        : INFO     Epoch: 1, Batch: 310, Loss: 0.1126\n",
            "root        : INFO     Epoch: 1, Batch: 320, Loss: 0.0748\n",
            "root        : INFO     Epoch: 1, Batch: 330, Loss: 0.1050\n",
            "root        : INFO     Epoch: 1, Batch: 340, Loss: 0.0913\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1024\n",
            "root        : INFO     Epoch: 1, Batch: 360, Loss: 0.0990\n",
            "root        : INFO     Epoch: 1, Batch: 370, Loss: 0.0973\n",
            "root        : INFO     Epoch: 1, Batch: 380, Loss: 0.1237\n",
            "root        : INFO     Epoch: 1, Batch: 390, Loss: 0.1172\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.1283\n",
            "root        : INFO     Epoch: 1, Batch: 410, Loss: 0.0975\n",
            "root        : INFO     Epoch: 1, Batch: 420, Loss: 0.0928\n",
            "root        : INFO     Epoch: 1, Batch: 430, Loss: 0.1331\n",
            "root        : INFO     Epoch: 1, Batch: 440, Loss: 0.1001\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     111/177 = 0.627119\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 10, Loss: 0.0969\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.1050\n",
            "root        : INFO     Epoch: 2, Batch: 30, Loss: 0.1337\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0943\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.1204\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.1164\n",
            "root        : INFO     Epoch: 2, Batch: 70, Loss: 0.0894\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.1020\n",
            "root        : INFO     Epoch: 2, Batch: 90, Loss: 0.0997\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0938\n",
            "root        : INFO     Epoch: 2, Batch: 110, Loss: 0.0901\n",
            "root        : INFO     Epoch: 2, Batch: 120, Loss: 0.1043\n",
            "root        : INFO     Epoch: 2, Batch: 130, Loss: 0.0961\n",
            "root        : INFO     Epoch: 2, Batch: 140, Loss: 0.1002\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0829\n",
            "root        : INFO     Epoch: 2, Batch: 160, Loss: 0.1465\n",
            "root        : INFO     Epoch: 2, Batch: 170, Loss: 0.0962\n",
            "root        : INFO     Epoch: 2, Batch: 180, Loss: 0.1889\n",
            "root        : INFO     Epoch: 2, Batch: 190, Loss: 0.0952\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0648\n",
            "root        : INFO     Epoch: 2, Batch: 210, Loss: 0.1064\n",
            "root        : INFO     Epoch: 2, Batch: 220, Loss: 0.0990\n",
            "root        : INFO     Epoch: 2, Batch: 230, Loss: 0.0626\n",
            "root        : INFO     Epoch: 2, Batch: 240, Loss: 0.1012\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1520\n",
            "root        : INFO     Epoch: 2, Batch: 260, Loss: 0.0810\n",
            "root        : INFO     Epoch: 2, Batch: 270, Loss: 0.1243\n",
            "root        : INFO     Epoch: 2, Batch: 280, Loss: 0.0788\n",
            "root        : INFO     Epoch: 2, Batch: 290, Loss: 0.0858\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.1079\n",
            "root        : INFO     Epoch: 2, Batch: 310, Loss: 0.1225\n",
            "root        : INFO     Epoch: 2, Batch: 320, Loss: 0.1061\n",
            "root        : INFO     Epoch: 2, Batch: 330, Loss: 0.1170\n",
            "root        : INFO     Epoch: 2, Batch: 340, Loss: 0.1277\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.1113\n",
            "root        : INFO     Epoch: 2, Batch: 360, Loss: 0.0569\n",
            "root        : INFO     Epoch: 2, Batch: 370, Loss: 0.1169\n",
            "root        : INFO     Epoch: 2, Batch: 380, Loss: 0.0789\n",
            "root        : INFO     Epoch: 2, Batch: 390, Loss: 0.1094\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0890\n",
            "root        : INFO     Epoch: 2, Batch: 410, Loss: 0.0729\n",
            "root        : INFO     Epoch: 2, Batch: 420, Loss: 0.0996\n",
            "root        : INFO     Epoch: 2, Batch: 430, Loss: 0.1072\n",
            "root        : INFO     Epoch: 2, Batch: 440, Loss: 0.0826\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     120/177 = 0.677966\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 10, Loss: 0.0990\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0904\n",
            "root        : INFO     Epoch: 3, Batch: 30, Loss: 0.1095\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0946\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.1271\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0872\n",
            "root        : INFO     Epoch: 3, Batch: 70, Loss: 0.0986\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.1200\n",
            "root        : INFO     Epoch: 3, Batch: 90, Loss: 0.1479\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0807\n",
            "root        : INFO     Epoch: 3, Batch: 110, Loss: 0.1013\n",
            "root        : INFO     Epoch: 3, Batch: 120, Loss: 0.0945\n",
            "root        : INFO     Epoch: 3, Batch: 130, Loss: 0.1039\n",
            "root        : INFO     Epoch: 3, Batch: 140, Loss: 0.0608\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0792\n",
            "root        : INFO     Epoch: 3, Batch: 160, Loss: 0.1079\n",
            "root        : INFO     Epoch: 3, Batch: 170, Loss: 0.0985\n",
            "root        : INFO     Epoch: 3, Batch: 180, Loss: 0.0613\n",
            "root        : INFO     Epoch: 3, Batch: 190, Loss: 0.0910\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0925\n",
            "root        : INFO     Epoch: 3, Batch: 210, Loss: 0.1114\n",
            "root        : INFO     Epoch: 3, Batch: 220, Loss: 0.0947\n",
            "root        : INFO     Epoch: 3, Batch: 230, Loss: 0.0891\n",
            "root        : INFO     Epoch: 3, Batch: 240, Loss: 0.1095\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.1035\n",
            "root        : INFO     Epoch: 3, Batch: 260, Loss: 0.1044\n",
            "root        : INFO     Epoch: 3, Batch: 270, Loss: 0.0865\n",
            "root        : INFO     Epoch: 3, Batch: 280, Loss: 0.0917\n",
            "root        : INFO     Epoch: 3, Batch: 290, Loss: 0.0649\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0736\n",
            "root        : INFO     Epoch: 3, Batch: 310, Loss: 0.0795\n",
            "root        : INFO     Epoch: 3, Batch: 320, Loss: 0.0739\n",
            "root        : INFO     Epoch: 3, Batch: 330, Loss: 0.0807\n",
            "root        : INFO     Epoch: 3, Batch: 340, Loss: 0.1119\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.1198\n",
            "root        : INFO     Epoch: 3, Batch: 360, Loss: 0.0995\n",
            "root        : INFO     Epoch: 3, Batch: 370, Loss: 0.0818\n",
            "root        : INFO     Epoch: 3, Batch: 380, Loss: 0.0798\n",
            "root        : INFO     Epoch: 3, Batch: 390, Loss: 0.0844\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0730\n",
            "root        : INFO     Epoch: 3, Batch: 410, Loss: 0.1097\n",
            "root        : INFO     Epoch: 3, Batch: 420, Loss: 0.0842\n",
            "root        : INFO     Epoch: 3, Batch: 430, Loss: 0.0991\n",
            "root        : INFO     Epoch: 3, Batch: 440, Loss: 0.1226\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 10, Loss: 0.1008\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0926\n",
            "root        : INFO     Epoch: 4, Batch: 30, Loss: 0.0937\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.1113\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0903\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.1064\n",
            "root        : INFO     Epoch: 4, Batch: 70, Loss: 0.1025\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0904\n",
            "root        : INFO     Epoch: 4, Batch: 90, Loss: 0.0749\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0880\n",
            "root        : INFO     Epoch: 4, Batch: 110, Loss: 0.0877\n",
            "root        : INFO     Epoch: 4, Batch: 120, Loss: 0.1077\n",
            "root        : INFO     Epoch: 4, Batch: 130, Loss: 0.0984\n",
            "root        : INFO     Epoch: 4, Batch: 140, Loss: 0.0953\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0528\n",
            "root        : INFO     Epoch: 4, Batch: 160, Loss: 0.0921\n",
            "root        : INFO     Epoch: 4, Batch: 170, Loss: 0.0761\n",
            "root        : INFO     Epoch: 4, Batch: 180, Loss: 0.0694\n",
            "root        : INFO     Epoch: 4, Batch: 190, Loss: 0.0792\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0919\n",
            "root        : INFO     Epoch: 4, Batch: 210, Loss: 0.0859\n",
            "root        : INFO     Epoch: 4, Batch: 220, Loss: 0.0830\n",
            "root        : INFO     Epoch: 4, Batch: 230, Loss: 0.0827\n",
            "root        : INFO     Epoch: 4, Batch: 240, Loss: 0.1177\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0604\n",
            "root        : INFO     Epoch: 4, Batch: 260, Loss: 0.1015\n",
            "root        : INFO     Epoch: 4, Batch: 270, Loss: 0.0652\n",
            "root        : INFO     Epoch: 4, Batch: 280, Loss: 0.0925\n",
            "root        : INFO     Epoch: 4, Batch: 290, Loss: 0.0799\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1075\n",
            "root        : INFO     Epoch: 4, Batch: 310, Loss: 0.0956\n",
            "root        : INFO     Epoch: 4, Batch: 320, Loss: 0.1384\n",
            "root        : INFO     Epoch: 4, Batch: 330, Loss: 0.0985\n",
            "root        : INFO     Epoch: 4, Batch: 340, Loss: 0.0825\n",
            "Traceback (most recent call last):\n",
            "  File \"train_network3.py\", line 359, in <module>\n",
            "  File \"train_network3.py\", line 331, in run\n",
            "    )                                                                                            \n",
            "  File \"train_network3.py\", line 157, in train\n",
            "    for x, y, _, _, _ in train_data:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1138, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auUTDTOcNZ8H"
      },
      "source": [
        "*Date: 2nd April*\n",
        "**5-fold Cross Validation**  \n",
        "--ds-rotate = 0.0, 0.2, 0.4, 0.6, 0.8  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcmRjqniOsCl"
      },
      "source": [
        "**Good Performance**  \n",
        "**1. ds-rotate =0.0, Image Wise, batchsize=16, learning rate =0.002, channel size 16**  \n",
        "**Achieved 0.938**\n",
        "\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210402_0701_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46jzw-DXXfwH",
        "outputId": "34f1e993-4445-4ddb-bf2a-81f418e5c7be"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-shuffle --ds-rotate 0.0 --lr=0.002"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 16\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 16, bacthes per epoch = 448, optimizer = adam\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]           5,200\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "            Conv2d-3         [-1, 32, 112, 112]           8,224\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            "            Conv2d-5           [-1, 64, 56, 56]          32,832\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "            Conv2d-7           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "           Conv2d-24           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "           Conv2d-29           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-31           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 32, 113, 113]          32,800\n",
            "      BatchNorm2d-33         [-1, 32, 113, 113]              64\n",
            "  ConvTranspose2d-34         [-1, 16, 225, 225]           8,208\n",
            "      BatchNorm2d-35         [-1, 16, 225, 225]              32\n",
            "  ConvTranspose2d-36         [-1, 16, 225, 225]          20,752\n",
            "          Dropout-37         [-1, 16, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]              65\n",
            "          Dropout-39         [-1, 16, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]              65\n",
            "          Dropout-41         [-1, 16, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]              65\n",
            "          Dropout-43         [-1, 16, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 479,156\n",
            "Trainable params: 479,156\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 110.74\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 113.34\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1568\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1147\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1181\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1071\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0883\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0974\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1354\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1213\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     114/177 = 0.644068\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0902\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0742\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0851\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1039\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0799\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1339\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1312\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0906\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     113/177 = 0.638418\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0973\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1010\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0633\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.1102\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1430\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0761\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.1138\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.1013\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0752\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1029\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0992\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0895\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0771\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0929\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0929\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0649\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0925\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0854\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0730\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0735\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0788\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0591\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0797\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0645\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.1059\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0877\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0982\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.1118\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0843\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0777\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0918\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0634\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0525\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0600\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0848\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0479\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0758\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0666\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0848\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0628\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0998\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0821\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0646\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0871\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0762\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0748\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0709\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.1076\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0676\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0491\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0552\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0747\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0796\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.1099\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0791\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0560\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0712\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0965\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0583\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0382\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0886\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0787\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0700\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0802\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0495\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0814\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0810\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0807\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.1100\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0957\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0643\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.1032\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0651\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.1012\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0854\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0711\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0876\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0873\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0552\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0673\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0534\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.1169\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0804\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0856\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.1021\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0573\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0955\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0701\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0691\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0520\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0720\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0460\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0888\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0700\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0549\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0745\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0617\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0446\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0541\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0895\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0665\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0658\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0950\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0603\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0504\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.1026\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0510\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0543\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0759\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0721\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0431\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0514\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0390\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0572\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0917\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0673\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0558\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0416\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.1030\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0796\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0831\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0739\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0670\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0607\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0710\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0581\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0901\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0517\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0731\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0674\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0600\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0681\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0847\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0764\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0450\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0576\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0702\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0703\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0630\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0711\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0543\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0404\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0945\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0956\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0564\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0545\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0522\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0526\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0615\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0772\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0534\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0433\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0867\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0758\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0921\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0664\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0809\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0861\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0518\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0539\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0591\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0891\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0869\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.1182\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0600\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0742\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0525\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0619\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0752\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0874\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.1025\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0857\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0614\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0594\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0659\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0708\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0434\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0826\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0829\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0739\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0858\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0647\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0877\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0638\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0627\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0711\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0775\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0412\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0605\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0626\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0617\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0607\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0507\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0694\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.0664\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0509\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0589\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0445\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0698\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0448\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0538\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0403\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0750\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0569\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0902\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0712\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0607\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0715\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0776\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0482\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.0737\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0489\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0487\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0457\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.0556\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0527\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0624\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0589\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0558\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.1134\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.0791\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0486\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.0383\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0685\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35l0Bwhxd4kQ"
      },
      "source": [
        "**1. ds-rotate =0.0, Object-Wise, batchsize=8, Adam, learning rate =0.001, channel size 32**  \n",
        "**Achieved 0.927**\n",
        "logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmiKI_ztd4_M",
        "outputId": "87ff13b7-f197-4958-da58-6c56c0a03b08"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.0 --lr=0.001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1699\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1685\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1881\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1198\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.1895\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1518\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1389\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1518\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0912\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0813\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.1351\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1261\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.1411\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.1252\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.1260\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1211\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0958\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     123/177 = 0.694915\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0802\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1082\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0889\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0731\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0912\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1038\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1266\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0599\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.1686\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0622\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.0888\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.1221\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.1083\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0960\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.1015\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.1168\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.0811\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0597\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0850\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0628\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0779\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1113\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0418\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0683\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.1206\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0831\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0744\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.0725\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0525\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.1188\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0652\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.1085\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0963\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0417\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0686\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0681\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0893\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0993\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.1269\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.1478\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0801\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.1146\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0627\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0986\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.0570\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0769\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.1018\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.1273\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0792\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0914\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0982\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0716\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0819\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0720\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0999\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0772\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1164\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0967\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1046\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.1174\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0515\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0836\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0695\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.1590\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.1282\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0736\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0669\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0881\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0956\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0587\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.1060\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0811\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.1352\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0528\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.1132\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0729\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.1078\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0748\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0539\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0633\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.1284\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.1112\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0971\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0631\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0863\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.1096\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0594\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0466\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0563\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0661\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0749\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.1060\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0940\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.1028\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0493\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.2326\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0703\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0664\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0808\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0526\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0636\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0946\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.1025\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0673\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0496\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0569\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0504\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0617\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.1148\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0989\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.1296\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.1010\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0682\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0885\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.1086\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0827\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0647\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0774\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0657\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0784\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0775\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0616\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0659\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.1321\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0959\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0327\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0624\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0525\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0676\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0569\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0913\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0727\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0829\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0706\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0433\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0465\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0427\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0664\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0419\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1363\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0668\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0757\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0776\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.1099\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0711\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0412\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0674\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.1429\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0364\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0761\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0516\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.1219\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0840\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0757\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0922\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0419\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0895\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0828\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.1343\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0756\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0806\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.1158\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.1126\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0747\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0712\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0480\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0653\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0787\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0943\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.1158\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.1379\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0909\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0728\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0678\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0410\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0752\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0493\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.1105\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0605\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0868\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0835\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.1601\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0731\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0488\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0672\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0880\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0382\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0729\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0824\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0492\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0879\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0645\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0923\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0628\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0591\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.0794\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0690\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0746\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0552\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0584\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0410\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0540\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0944\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0720\n",
            "Traceback (most recent call last):\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0497\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0802\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.1392\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0450\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0480\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0545\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0790\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0743\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.1011\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0580\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.1037\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0451\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0563\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0898\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.0790\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0418\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.0338\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0537\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0525\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0524\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0554\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0866\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0863\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0673\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.1062\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0981\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0874\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.0806\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0921\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0880\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.1107\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0595\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0792\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0456\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0682\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0719\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.1206\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0510\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0900\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0439\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0411\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0946\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.0840\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0496\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.0548\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0762\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.0442\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0830\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.0647\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0902\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0671\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0484\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0890\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0833\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0977\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0670\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0486\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0604\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.1053\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.0555\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0676\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.1096\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0768\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0856\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0727\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0821\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0393\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0893\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0400\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0526\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0856\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0513\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.1014\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0987\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0816\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0730\n",
            "root        : INFO     Epoch: 17, Batch: 450, Loss: 0.0289\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0452\n",
            "root        : INFO     Epoch: 17, Batch: 550, Loss: 0.0606\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.1026\n",
            "root        : INFO     Epoch: 17, Batch: 650, Loss: 0.0429\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0353\n",
            "root        : INFO     Epoch: 17, Batch: 750, Loss: 0.0403\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0594\n",
            "root        : INFO     Epoch: 17, Batch: 850, Loss: 0.0587\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0534\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0542\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0653\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0635\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0413\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0574\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0681\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0857\n",
            "root        : INFO     Epoch: 18, Batch: 450, Loss: 0.0838\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0369\n",
            "root        : INFO     Epoch: 18, Batch: 550, Loss: 0.0868\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0768\n",
            "root        : INFO     Epoch: 18, Batch: 650, Loss: 0.0631\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.0956\n",
            "root        : INFO     Epoch: 18, Batch: 750, Loss: 0.0393\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0730\n",
            "root        : INFO     Epoch: 18, Batch: 850, Loss: 0.0430\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0291\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0827\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0454\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0911\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0584\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.1117\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0647\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0785\n",
            "root        : INFO     Epoch: 19, Batch: 450, Loss: 0.1314\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0383\n",
            "root        : INFO     Epoch: 19, Batch: 550, Loss: 0.1053\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.1160\n",
            "root        : INFO     Epoch: 19, Batch: 650, Loss: 0.0540\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0594\n",
            "root        : INFO     Epoch: 19, Batch: 750, Loss: 0.0993\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0438\n",
            "root        : INFO     Epoch: 19, Batch: 850, Loss: 0.0406\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0588\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0592\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0511\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0684\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0969\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0368\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0848\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0488\n",
            "root        : INFO     Epoch: 20, Batch: 450, Loss: 0.1035\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.0506\n",
            "root        : INFO     Epoch: 20, Batch: 550, Loss: 0.0632\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0621\n",
            "root        : INFO     Epoch: 20, Batch: 650, Loss: 0.0445\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.0612\n",
            "root        : INFO     Epoch: 20, Batch: 750, Loss: 0.0626\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.0485\n",
            "root        : INFO     Epoch: 20, Batch: 850, Loss: 0.0522\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0630\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0910\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0689\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0961\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0655\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0455\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0431\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0655\n",
            "root        : INFO     Epoch: 21, Batch: 450, Loss: 0.0471\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.0452\n",
            "root        : INFO     Epoch: 21, Batch: 550, Loss: 0.0772\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.0761\n",
            "root        : INFO     Epoch: 21, Batch: 650, Loss: 0.0414\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.0477\n",
            "root        : INFO     Epoch: 21, Batch: 750, Loss: 0.0463\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0710\n",
            "root        : INFO     Epoch: 21, Batch: 850, Loss: 0.0362\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0247\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0849\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0570\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0481\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0363\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0462\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0618\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0625\n",
            "root        : INFO     Epoch: 22, Batch: 450, Loss: 0.0603\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0723\n",
            "root        : INFO     Epoch: 22, Batch: 550, Loss: 0.0903\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.0918\n",
            "root        : INFO     Epoch: 22, Batch: 650, Loss: 0.0602\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.0707\n",
            "root        : INFO     Epoch: 22, Batch: 750, Loss: 0.0401\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.1153\n",
            "root        : INFO     Epoch: 22, Batch: 850, Loss: 0.1059\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.1281\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0545\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0677\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0581\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0509\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0739\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0511\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0875\n",
            "root        : INFO     Epoch: 23, Batch: 450, Loss: 0.0605\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0616\n",
            "root        : INFO     Epoch: 23, Batch: 550, Loss: 0.0415\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0802\n",
            "root        : INFO     Epoch: 23, Batch: 650, Loss: 0.0713\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.0914\n",
            "root        : INFO     Epoch: 23, Batch: 750, Loss: 0.0756\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.0449\n",
            "root        : INFO     Epoch: 23, Batch: 850, Loss: 0.0967\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0464\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0527\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0714\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0539\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0602\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0692\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0705\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0616\n",
            "root        : INFO     Epoch: 24, Batch: 450, Loss: 0.0415\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.0535\n",
            "root        : INFO     Epoch: 24, Batch: 550, Loss: 0.0515\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.0824\n",
            "root        : INFO     Epoch: 24, Batch: 650, Loss: 0.0856\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.0599\n",
            "root        : INFO     Epoch: 24, Batch: 750, Loss: 0.0664\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.0624\n",
            "root        : INFO     Epoch: 24, Batch: 850, Loss: 0.0614\n",
            "Traceback (most recent call last):\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0729\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0790\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0339\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0468\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0561\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0705\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0367\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0910\n",
            "root        : INFO     Epoch: 25, Batch: 450, Loss: 0.0702\n",
            "root        : INFO     Epoch: 25, Batch: 500, Loss: 0.0472\n",
            "root        : INFO     Epoch: 25, Batch: 550, Loss: 0.0492\n",
            "root        : INFO     Epoch: 25, Batch: 600, Loss: 0.0531\n",
            "root        : INFO     Epoch: 25, Batch: 650, Loss: 0.0620\n",
            "root        : INFO     Epoch: 25, Batch: 700, Loss: 0.0451\n",
            "root        : INFO     Epoch: 25, Batch: 750, Loss: 0.0564\n",
            "root        : INFO     Epoch: 25, Batch: 800, Loss: 0.0474\n",
            "root        : INFO     Epoch: 25, Batch: 850, Loss: 0.0356\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0676\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0534\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.0923\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.1004\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0554\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0776\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0581\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0265\n",
            "root        : INFO     Epoch: 26, Batch: 450, Loss: 0.0665\n",
            "root        : INFO     Epoch: 26, Batch: 500, Loss: 0.0889\n",
            "root        : INFO     Epoch: 26, Batch: 550, Loss: 0.0558\n",
            "root        : INFO     Epoch: 26, Batch: 600, Loss: 0.1103\n",
            "root        : INFO     Epoch: 26, Batch: 650, Loss: 0.0569\n",
            "root        : INFO     Epoch: 26, Batch: 700, Loss: 0.1036\n",
            "root        : INFO     Epoch: 26, Batch: 750, Loss: 0.0482\n",
            "root        : INFO     Epoch: 26, Batch: 800, Loss: 0.0896\n",
            "root        : INFO     Epoch: 26, Batch: 850, Loss: 0.0529\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0496\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0675\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0524\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.1348\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0882\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0985\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0730\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0475\n",
            "root        : INFO     Epoch: 27, Batch: 450, Loss: 0.0306\n",
            "root        : INFO     Epoch: 27, Batch: 500, Loss: 0.0608\n",
            "root        : INFO     Epoch: 27, Batch: 550, Loss: 0.0320\n",
            "root        : INFO     Epoch: 27, Batch: 600, Loss: 0.0311\n",
            "root        : INFO     Epoch: 27, Batch: 650, Loss: 0.0497\n",
            "root        : INFO     Epoch: 27, Batch: 700, Loss: 0.0582\n",
            "root        : INFO     Epoch: 27, Batch: 750, Loss: 0.0590\n",
            "root        : INFO     Epoch: 27, Batch: 800, Loss: 0.0948\n",
            "root        : INFO     Epoch: 27, Batch: 850, Loss: 0.0605\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0467\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.1069\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.1040\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.1121\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0438\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0761\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.0527\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0728\n",
            "root        : INFO     Epoch: 28, Batch: 450, Loss: 0.0754\n",
            "root        : INFO     Epoch: 28, Batch: 500, Loss: 0.0680\n",
            "root        : INFO     Epoch: 28, Batch: 550, Loss: 0.0884\n",
            "root        : INFO     Epoch: 28, Batch: 600, Loss: 0.0533\n",
            "root        : INFO     Epoch: 28, Batch: 650, Loss: 0.0802\n",
            "root        : INFO     Epoch: 28, Batch: 700, Loss: 0.0560\n",
            "root        : INFO     Epoch: 28, Batch: 750, Loss: 0.0641\n",
            "root        : INFO     Epoch: 28, Batch: 800, Loss: 0.1353\n",
            "root        : INFO     Epoch: 28, Batch: 850, Loss: 0.0888\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0432\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0806\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0697\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0808\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.0925\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0690\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.1115\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0635\n",
            "root        : INFO     Epoch: 29, Batch: 450, Loss: 0.0728\n",
            "root        : INFO     Epoch: 29, Batch: 500, Loss: 0.0844\n",
            "root        : INFO     Epoch: 29, Batch: 550, Loss: 0.0838\n",
            "root        : INFO     Epoch: 29, Batch: 600, Loss: 0.0657\n",
            "root        : INFO     Epoch: 29, Batch: 650, Loss: 0.0353\n",
            "root        : INFO     Epoch: 29, Batch: 700, Loss: 0.1081\n",
            "root        : INFO     Epoch: 29, Batch: 750, Loss: 0.0633\n",
            "root        : INFO     Epoch: 29, Batch: 800, Loss: 0.0534\n",
            "root        : INFO     Epoch: 29, Batch: 850, Loss: 0.0443\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_b0Z4_ZJ77e"
      },
      "source": [
        "# ds-rotate=0.0 without augmentation, Object-Wise, batch size=8, use rgbd,channel size =32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K-wAg7nKSwd"
      },
      "source": [
        "## GCoTNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em47DK-2LhLJ",
        "outputId": "7f6282cb-680d-4dfb-9944-bf57d588d46e"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/content/drive/MyDrive/GR_ConvNet_Code_GCoTNet')\n",
        "!pwd"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GR_ConvNet_Code\n",
            "/content/drive/MyDrive/GR_ConvNet_Code_GCoTNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Do5DQ7dYL-M2",
        "outputId": "731efab9-e826-4303-da31-9bc2053bfa87"
      },
      "source": [
        "#!python -m pip install 'git+https://github.com/RealMarco/detectron2.git'\n",
        "#!git clone https://github.com/RealMarco/detectron2.git\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html  --target /content/drive/MyDrive/GR_ConvNet_Code_GCoTNet"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
            "Collecting detectron2\n",
            "  Using cached https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/detectron2-0.5%2Bcu102-cp37-cp37m-linux_x86_64.whl (6.4 MB)\n",
            "Collecting Pillow>=7.1\n",
            "  Using cached Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Collecting tensorboard\n",
            "  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "Collecting iopath<0.1.9,>=0.1.7\n",
            "  Using cached iopath-0.1.8-py3-none-any.whl (19 kB)\n",
            "Collecting pycocotools>=2.0.2\n",
            "  Using cached pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Using cached fvcore-0.1.5.post20210924-py3-none-any.whl\n",
            "Collecting future\n",
            "  Using cached future-0.18.2-py3-none-any.whl\n",
            "Collecting omegaconf>=2.1\n",
            "  Using cached omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "Collecting tqdm>4.29.0\n",
            "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Collecting termcolor>=1.1\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Collecting yacs>=0.1.6\n",
            "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting cloudpickle\n",
            "  Using cached cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting black==21.4b2\n",
            "  Using cached black-21.4b2-py3-none-any.whl (130 kB)\n",
            "Collecting pydot\n",
            "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting hydra-core>=1.1\n",
            "  Using cached hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.4.3-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
            "Collecting tabulate\n",
            "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Using cached mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting toml>=0.10.1\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting appdirs\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Using cached typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "Collecting typing-extensions>=3.7.4\n",
            "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting regex>=2020.1.8\n",
            "  Using cached regex-2021.9.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (747 kB)\n",
            "Collecting click>=7.1.2\n",
            "  Using cached click-8.0.1-py3-none-any.whl (97 kB)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Using cached pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting importlib-metadata\n",
            "  Using cached importlib_metadata-4.8.1-py3-none-any.whl (17 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Using cached PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Using cached antlr4_python3_runtime-4.8-py3-none-any.whl\n",
            "Collecting importlib-resources\n",
            "  Using cached importlib_resources-5.2.2-py3-none-any.whl (27 kB)\n",
            "Collecting portalocker\n",
            "  Using cached portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting cython>=0.27.3\n",
            "  Using cached Cython-0.29.24-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "Collecting setuptools>=18.0\n",
            "  Using cached setuptools-58.1.0-py3-none-any.whl (816 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Using cached kiwisolver-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting python-dateutil>=2.7\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting six\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Using cached zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
            "Collecting protobuf>=3.6.0\n",
            "  Using cached protobuf-3.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "Collecting wheel>=0.26\n",
            "  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Using cached absl_py-0.14.0-py3-none-any.whl (131 kB)\n",
            "Collecting requests<3,>=2.21.0\n",
            "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Using cached grpcio-1.40.0-cp37-cp37m-manylinux2014_x86_64.whl (4.3 MB)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "  Using cached google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.2-py3-none-any.whl (59 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Using cached charset_normalizer-2.0.6-py3-none-any.whl (37 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, typing-extensions, six, setuptools, rsa, requests, pyasn1-modules, oauthlib, cachetools, tqdm, requests-oauthlib, pyyaml, python-dateutil, pyparsing, portalocker, Pillow, numpy, kiwisolver, importlib-metadata, google-auth, cycler, antlr4-python3-runtime, yacs, wheel, werkzeug, typed-ast, toml, termcolor, tensorboard-plugin-wit, tensorboard-data-server, tabulate, regex, protobuf, pathspec, omegaconf, mypy-extensions, matplotlib, markdown, iopath, importlib-resources, grpcio, google-auth-oauthlib, cython, click, appdirs, absl-py, tensorboard, pydot, pycocotools, hydra-core, fvcore, future, cloudpickle, black, detectron2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "tensorflow-metadata 1.2.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.14.0 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.1 which is incompatible.\n",
            "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.0.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.3.2 absl-py-0.14.0 antlr4-python3-runtime-4.8 appdirs-1.4.4 black-21.4b2 cachetools-4.2.2 certifi-2021.5.30 charset-normalizer-2.0.6 click-8.0.1 cloudpickle-2.0.0 cycler-0.10.0 cython-0.29.24 detectron2-0.5+cu102 future-0.18.2 fvcore-0.1.5.post20210924 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.40.0 hydra-core-1.1.1 idna-3.2 importlib-metadata-4.8.1 importlib-resources-5.2.2 iopath-0.1.8 kiwisolver-1.3.2 markdown-3.3.4 matplotlib-3.4.3 mypy-extensions-0.4.3 numpy-1.21.2 oauthlib-3.1.1 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.3.2 protobuf-3.18.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.2 pydot-1.4.2 pyparsing-2.4.7 python-dateutil-2.8.2 pyyaml-5.4.1 regex-2021.9.24 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 setuptools-58.1.0 six-1.16.0 tabulate-0.8.9 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 termcolor-1.1.0 toml-0.10.2 tqdm-4.62.3 typed-ast-1.4.3 typing-extensions-3.10.0.2 urllib3-1.26.7 werkzeug-2.0.1 wheel-0.37.0 yacs-0.1.8 zipp-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "detectron2",
                  "fvcore",
                  "google",
                  "kiwisolver",
                  "pydevd_plugins",
                  "pyparsing",
                  "tabulate",
                  "termcolor",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "8A7DJtja0oxe",
        "outputId": "1aff1438-6c81-4039-d3ac-be671b7e162b"
      },
      "source": [
        "# import detectron.detectron2 as detectron2\n",
        "from detectron2.modeling.backbone.cotnet import CoTBlock ###"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-d034903b92bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import detectron.detectron2 as detectron2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcotnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoTBlock\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2.modeling'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rET52eky0zD4"
      },
      "source": [
        "**1. gcotnet without augmentation, ds-rotate=0.0, Object-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32**  \n",
        "**Achived 0**saved at"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEeR3xMaPZE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686825bc-feb0-4108-fe38-a331bc480bfa"
      },
      "source": [
        "!python train_network_o.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --network=gcotnet --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.0 --augment 0 --lr=0.001 --epochs 80"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:matplotlib.font_manager:generated new fontManager\n",
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla T4, number of GPUs: 1\n",
            "root        : INFO     network = gcotnet, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 80, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210925_1349_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "       BatchNorm2d-7          [-1, 128, 56, 56]             256\n",
            "            Conv2d-8          [-1, 128, 56, 56]          16,384\n",
            "       BatchNorm2d-9          [-1, 128, 56, 56]             256\n",
            "           Conv2d-10          [-1, 128, 56, 56]          36,864\n",
            "             ReLU-11          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
            "           Conv2d-13           [-1, 64, 56, 56]          16,384\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15          [-1, 144, 56, 56]           9,360\n",
            "        GroupNorm-16          [-1, 144, 56, 56]             288\n",
            "           Conv2d-17          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            " LocalConvolution-19          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "             SiLU-21          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-22             [-1, 64, 1, 1]             128\n",
            "           Conv2d-23             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-24             [-1, 64, 1, 1]               0\n",
            "           Conv2d-25            [-1, 256, 1, 1]          16,640\n",
            "         CoTLayer-26          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-27          [-1, 128, 56, 56]             256\n",
            "           Conv2d-28          [-1, 128, 56, 56]          16,384\n",
            "         CoTBlock-29          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "           Conv2d-31          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
            "           Conv2d-33          [-1, 128, 56, 56]          36,864\n",
            "             ReLU-34          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
            "           Conv2d-36           [-1, 64, 56, 56]          16,384\n",
            "             ReLU-37           [-1, 64, 56, 56]               0\n",
            "           Conv2d-38          [-1, 144, 56, 56]           9,360\n",
            "        GroupNorm-39          [-1, 144, 56, 56]             288\n",
            "           Conv2d-40          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
            " LocalConvolution-42          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-43          [-1, 128, 56, 56]             256\n",
            "             SiLU-44          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-45             [-1, 64, 1, 1]             128\n",
            "           Conv2d-46             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-47             [-1, 64, 1, 1]               0\n",
            "           Conv2d-48            [-1, 256, 1, 1]          16,640\n",
            "         CoTLayer-49          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-50          [-1, 128, 56, 56]             256\n",
            "           Conv2d-51          [-1, 128, 56, 56]          16,384\n",
            "         CoTBlock-52          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-53          [-1, 128, 56, 56]             256\n",
            "           Conv2d-54          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-55          [-1, 128, 56, 56]             256\n",
            "           Conv2d-56          [-1, 128, 56, 56]          36,864\n",
            "             ReLU-57          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "           Conv2d-59           [-1, 64, 56, 56]          16,384\n",
            "             ReLU-60           [-1, 64, 56, 56]               0\n",
            "           Conv2d-61          [-1, 144, 56, 56]           9,360\n",
            "        GroupNorm-62          [-1, 144, 56, 56]             288\n",
            "           Conv2d-63          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-64          [-1, 128, 56, 56]             256\n",
            " LocalConvolution-65          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-66          [-1, 128, 56, 56]             256\n",
            "             SiLU-67          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-68             [-1, 64, 1, 1]             128\n",
            "           Conv2d-69             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-70             [-1, 64, 1, 1]               0\n",
            "           Conv2d-71            [-1, 256, 1, 1]          16,640\n",
            "         CoTLayer-72          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-73          [-1, 128, 56, 56]             256\n",
            "           Conv2d-74          [-1, 128, 56, 56]          16,384\n",
            "         CoTBlock-75          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-76          [-1, 128, 56, 56]             256\n",
            "           Conv2d-77          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-78          [-1, 128, 56, 56]             256\n",
            "           Conv2d-79          [-1, 128, 56, 56]          36,864\n",
            "             ReLU-80          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-81           [-1, 64, 56, 56]             128\n",
            "           Conv2d-82           [-1, 64, 56, 56]          16,384\n",
            "             ReLU-83           [-1, 64, 56, 56]               0\n",
            "           Conv2d-84          [-1, 144, 56, 56]           9,360\n",
            "        GroupNorm-85          [-1, 144, 56, 56]             288\n",
            "           Conv2d-86          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-87          [-1, 128, 56, 56]             256\n",
            " LocalConvolution-88          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-89          [-1, 128, 56, 56]             256\n",
            "             SiLU-90          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-91             [-1, 64, 1, 1]             128\n",
            "           Conv2d-92             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-93             [-1, 64, 1, 1]               0\n",
            "           Conv2d-94            [-1, 256, 1, 1]          16,640\n",
            "         CoTLayer-95          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-96          [-1, 128, 56, 56]             256\n",
            "           Conv2d-97          [-1, 128, 56, 56]          16,384\n",
            "         CoTBlock-98          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-99          [-1, 128, 56, 56]             256\n",
            "          Conv2d-100          [-1, 128, 56, 56]          16,384\n",
            "     BatchNorm2d-101          [-1, 128, 56, 56]             256\n",
            "          Conv2d-102          [-1, 128, 56, 56]          36,864\n",
            "            ReLU-103          [-1, 128, 56, 56]               0\n",
            "     BatchNorm2d-104           [-1, 64, 56, 56]             128\n",
            "          Conv2d-105           [-1, 64, 56, 56]          16,384\n",
            "            ReLU-106           [-1, 64, 56, 56]               0\n",
            "          Conv2d-107          [-1, 144, 56, 56]           9,360\n",
            "       GroupNorm-108          [-1, 144, 56, 56]             288\n",
            "          Conv2d-109          [-1, 128, 56, 56]          16,384\n",
            "     BatchNorm2d-110          [-1, 128, 56, 56]             256\n",
            "LocalConvolution-111          [-1, 128, 56, 56]               0\n",
            "     BatchNorm2d-112          [-1, 128, 56, 56]             256\n",
            "            SiLU-113          [-1, 128, 56, 56]               0\n",
            "     BatchNorm2d-114             [-1, 64, 1, 1]             128\n",
            "          Conv2d-115             [-1, 64, 1, 1]           8,256\n",
            "            ReLU-116             [-1, 64, 1, 1]               0\n",
            "          Conv2d-117            [-1, 256, 1, 1]          16,640\n",
            "        CoTLayer-118          [-1, 128, 56, 56]               0\n",
            "     BatchNorm2d-119          [-1, 128, 56, 56]             256\n",
            "          Conv2d-120          [-1, 128, 56, 56]          16,384\n",
            "        CoTBlock-121          [-1, 128, 56, 56]               0\n",
            " ConvTranspose2d-122         [-1, 64, 113, 113]         131,136\n",
            "     BatchNorm2d-123         [-1, 64, 113, 113]             128\n",
            " ConvTranspose2d-124         [-1, 32, 225, 225]          32,800\n",
            "     BatchNorm2d-125         [-1, 32, 225, 225]              64\n",
            " ConvTranspose2d-126         [-1, 32, 225, 225]          82,976\n",
            "         Dropout-127         [-1, 32, 225, 225]               0\n",
            "          Conv2d-128          [-1, 1, 224, 224]             129\n",
            "         Dropout-129         [-1, 32, 225, 225]               0\n",
            "          Conv2d-130          [-1, 1, 224, 224]             129\n",
            "         Dropout-131         [-1, 32, 225, 225]               0\n",
            "          Conv2d-132          [-1, 1, 224, 224]             129\n",
            "         Dropout-133         [-1, 32, 225, 225]               0\n",
            "          Conv2d-134          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,114,900\n",
            "Trainable params: 1,114,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 415.21\n",
            "Params size (MB): 4.25\n",
            "Estimated Total Size (MB): 420.23\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.0937\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.1108\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0828\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.0580\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     69/177 = 0.389831\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0429\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0667\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0543\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0543\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     115/177 = 0.649718\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0525\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0572\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0669\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0916\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     102/177 = 0.576271\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0690\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0523\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0706\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0535\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0571\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0497\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0516\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0664\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0661\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0516\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0655\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0455\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     121/177 = 0.683616\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0605\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0630\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0433\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0532\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0601\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0648\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0462\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0507\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0521\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0805\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0647\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0623\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0556\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0413\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0472\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0348\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0527\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0260\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0481\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0510\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0226\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0300\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0755\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0434\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0401\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0485\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0638\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0339\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0757\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0635\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0381\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0587\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0707\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0546\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0547\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0471\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0410\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0388\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0829\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0423\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0558\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0473\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0299\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0365\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0776\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0326\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0544\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0480\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0551\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0378\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0573\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0516\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0479\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0468\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0413\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0289\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0343\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0371\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0539\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0442\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0541\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0496\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0270\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0387\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0516\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0379\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0185\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0569\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0381\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0312\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0674\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0488\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0712\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0367\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0396\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0330\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0332\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0404\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0285\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0284\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0335\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0368\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0378\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0303\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0344\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0363\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0519\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0486\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0238\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0588\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0368\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0435\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0361\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0296\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0292\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0379\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 30, Batch: 20, Loss: 0.0326\n",
            "root        : INFO     Epoch: 30, Batch: 40, Loss: 0.0504\n",
            "root        : INFO     Epoch: 30, Batch: 60, Loss: 0.0372\n",
            "root        : INFO     Epoch: 30, Batch: 80, Loss: 0.0384\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 31, Batch: 20, Loss: 0.0669\n",
            "root        : INFO     Epoch: 31, Batch: 40, Loss: 0.0289\n",
            "root        : INFO     Epoch: 31, Batch: 60, Loss: 0.0378\n",
            "root        : INFO     Epoch: 31, Batch: 80, Loss: 0.0602\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 32, Batch: 20, Loss: 0.0264\n",
            "root        : INFO     Epoch: 32, Batch: 40, Loss: 0.0559\n",
            "root        : INFO     Epoch: 32, Batch: 60, Loss: 0.0245\n",
            "root        : INFO     Epoch: 32, Batch: 80, Loss: 0.0351\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 33, Batch: 20, Loss: 0.0345\n",
            "root        : INFO     Epoch: 33, Batch: 40, Loss: 0.0277\n",
            "root        : INFO     Epoch: 33, Batch: 60, Loss: 0.0424\n",
            "root        : INFO     Epoch: 33, Batch: 80, Loss: 0.0562\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 34, Batch: 20, Loss: 0.0307\n",
            "root        : INFO     Epoch: 34, Batch: 40, Loss: 0.0318\n",
            "root        : INFO     Epoch: 34, Batch: 60, Loss: 0.0332\n",
            "root        : INFO     Epoch: 34, Batch: 80, Loss: 0.0478\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 35, Batch: 20, Loss: 0.0274\n",
            "root        : INFO     Epoch: 35, Batch: 40, Loss: 0.0267\n",
            "root        : INFO     Epoch: 35, Batch: 60, Loss: 0.0367\n",
            "root        : INFO     Epoch: 35, Batch: 80, Loss: 0.0416\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 36, Batch: 20, Loss: 0.0331\n",
            "root        : INFO     Epoch: 36, Batch: 40, Loss: 0.0305\n",
            "root        : INFO     Epoch: 36, Batch: 60, Loss: 0.0349\n",
            "root        : INFO     Epoch: 36, Batch: 80, Loss: 0.0293\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 37, Batch: 20, Loss: 0.0370\n",
            "root        : INFO     Epoch: 37, Batch: 40, Loss: 0.0456\n",
            "root        : INFO     Epoch: 37, Batch: 60, Loss: 0.0566\n",
            "root        : INFO     Epoch: 37, Batch: 80, Loss: 0.0331\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 38, Batch: 20, Loss: 0.0330\n",
            "root        : INFO     Epoch: 38, Batch: 40, Loss: 0.0401\n",
            "root        : INFO     Epoch: 38, Batch: 60, Loss: 0.0293\n",
            "root        : INFO     Epoch: 38, Batch: 80, Loss: 0.0285\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 39, Batch: 20, Loss: 0.0446\n",
            "root        : INFO     Epoch: 39, Batch: 40, Loss: 0.0457\n",
            "root        : INFO     Epoch: 39, Batch: 60, Loss: 0.0373\n",
            "root        : INFO     Epoch: 39, Batch: 80, Loss: 0.0372\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 40, Batch: 20, Loss: 0.0275\n",
            "root        : INFO     Epoch: 40, Batch: 40, Loss: 0.0463\n",
            "root        : INFO     Epoch: 40, Batch: 60, Loss: 0.0427\n",
            "root        : INFO     Epoch: 40, Batch: 80, Loss: 0.0307\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 41, Batch: 20, Loss: 0.0293\n",
            "root        : INFO     Epoch: 41, Batch: 40, Loss: 0.0347\n",
            "root        : INFO     Epoch: 41, Batch: 60, Loss: 0.0299\n",
            "root        : INFO     Epoch: 41, Batch: 80, Loss: 0.0389\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 42, Batch: 20, Loss: 0.0241\n",
            "root        : INFO     Epoch: 42, Batch: 40, Loss: 0.0389\n",
            "root        : INFO     Epoch: 42, Batch: 60, Loss: 0.0291\n",
            "root        : INFO     Epoch: 42, Batch: 80, Loss: 0.0431\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 43, Batch: 20, Loss: 0.0238\n",
            "root        : INFO     Epoch: 43, Batch: 40, Loss: 0.0292\n",
            "root        : INFO     Epoch: 43, Batch: 60, Loss: 0.0306\n",
            "root        : INFO     Epoch: 43, Batch: 80, Loss: 0.0209\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 44, Batch: 20, Loss: 0.0342\n",
            "root        : INFO     Epoch: 44, Batch: 40, Loss: 0.0234\n",
            "root        : INFO     Epoch: 44, Batch: 60, Loss: 0.0179\n",
            "root        : INFO     Epoch: 44, Batch: 80, Loss: 0.0375\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 45, Batch: 20, Loss: 0.0204\n",
            "root        : INFO     Epoch: 45, Batch: 40, Loss: 0.0281\n",
            "root        : INFO     Epoch: 45, Batch: 60, Loss: 0.0207\n",
            "root        : INFO     Epoch: 45, Batch: 80, Loss: 0.0337\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 46, Batch: 20, Loss: 0.0367\n",
            "root        : INFO     Epoch: 46, Batch: 40, Loss: 0.0280\n",
            "root        : INFO     Epoch: 46, Batch: 60, Loss: 0.0267\n",
            "root        : INFO     Epoch: 46, Batch: 80, Loss: 0.0505\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 47, Batch: 20, Loss: 0.0187\n",
            "root        : INFO     Epoch: 47, Batch: 40, Loss: 0.0288\n",
            "root        : INFO     Epoch: 47, Batch: 60, Loss: 0.0181\n",
            "root        : INFO     Epoch: 47, Batch: 80, Loss: 0.0353\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 48, Batch: 20, Loss: 0.0231\n",
            "root        : INFO     Epoch: 48, Batch: 40, Loss: 0.0346\n",
            "root        : INFO     Epoch: 48, Batch: 60, Loss: 0.0217\n",
            "root        : INFO     Epoch: 48, Batch: 80, Loss: 0.0298\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 49, Batch: 20, Loss: 0.0318\n",
            "root        : INFO     Epoch: 49, Batch: 40, Loss: 0.0232\n",
            "root        : INFO     Epoch: 49, Batch: 60, Loss: 0.0333\n",
            "root        : INFO     Epoch: 49, Batch: 80, Loss: 0.0245\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 50\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 50, Batch: 20, Loss: 0.0154\n",
            "root        : INFO     Epoch: 50, Batch: 40, Loss: 0.0287\n",
            "root        : INFO     Epoch: 50, Batch: 60, Loss: 0.0401\n",
            "root        : INFO     Epoch: 50, Batch: 80, Loss: 0.0381\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 51\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 51, Batch: 20, Loss: 0.0275\n",
            "root        : INFO     Epoch: 51, Batch: 40, Loss: 0.0422\n",
            "root        : INFO     Epoch: 51, Batch: 60, Loss: 0.0278\n",
            "root        : INFO     Epoch: 51, Batch: 80, Loss: 0.0272\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 52\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 52, Batch: 20, Loss: 0.0129\n",
            "root        : INFO     Epoch: 52, Batch: 40, Loss: 0.0274\n",
            "root        : INFO     Epoch: 52, Batch: 60, Loss: 0.0321\n",
            "root        : INFO     Epoch: 52, Batch: 80, Loss: 0.0326\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 53\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 53, Batch: 20, Loss: 0.0293\n",
            "root        : INFO     Epoch: 53, Batch: 40, Loss: 0.0271\n",
            "root        : INFO     Epoch: 53, Batch: 60, Loss: 0.0394\n",
            "root        : INFO     Epoch: 53, Batch: 80, Loss: 0.0243\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 54\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 54, Batch: 20, Loss: 0.0326\n",
            "root        : INFO     Epoch: 54, Batch: 40, Loss: 0.0358\n",
            "root        : INFO     Epoch: 54, Batch: 60, Loss: 0.0330\n",
            "root        : INFO     Epoch: 54, Batch: 80, Loss: 0.0274\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 55\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 55, Batch: 20, Loss: 0.0189\n",
            "root        : INFO     Epoch: 55, Batch: 40, Loss: 0.0269\n",
            "root        : INFO     Epoch: 55, Batch: 60, Loss: 0.0341\n",
            "root        : INFO     Epoch: 55, Batch: 80, Loss: 0.0271\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 56\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 56, Batch: 20, Loss: 0.0325\n",
            "root        : INFO     Epoch: 56, Batch: 40, Loss: 0.0234\n",
            "root        : INFO     Epoch: 56, Batch: 60, Loss: 0.0341\n",
            "root        : INFO     Epoch: 56, Batch: 80, Loss: 0.0347\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 57\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 57, Batch: 20, Loss: 0.0248\n",
            "root        : INFO     Epoch: 57, Batch: 40, Loss: 0.0272\n",
            "root        : INFO     Epoch: 57, Batch: 60, Loss: 0.0220\n",
            "root        : INFO     Epoch: 57, Batch: 80, Loss: 0.0266\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 58\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 58, Batch: 20, Loss: 0.0237\n",
            "root        : INFO     Epoch: 58, Batch: 40, Loss: 0.0300\n",
            "root        : INFO     Epoch: 58, Batch: 60, Loss: 0.0222\n",
            "root        : INFO     Epoch: 58, Batch: 80, Loss: 0.0258\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 59\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 59, Batch: 20, Loss: 0.0268\n",
            "root        : INFO     Epoch: 59, Batch: 40, Loss: 0.0397\n",
            "root        : INFO     Epoch: 59, Batch: 60, Loss: 0.0296\n",
            "root        : INFO     Epoch: 59, Batch: 80, Loss: 0.0279\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 60\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 60, Batch: 20, Loss: 0.0194\n",
            "root        : INFO     Epoch: 60, Batch: 40, Loss: 0.0226\n",
            "root        : INFO     Epoch: 60, Batch: 60, Loss: 0.0269\n",
            "root        : INFO     Epoch: 60, Batch: 80, Loss: 0.0263\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 61\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 61, Batch: 20, Loss: 0.0166\n",
            "root        : INFO     Epoch: 61, Batch: 40, Loss: 0.0344\n",
            "root        : INFO     Epoch: 61, Batch: 60, Loss: 0.0185\n",
            "root        : INFO     Epoch: 61, Batch: 80, Loss: 0.0274\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 62\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 62, Batch: 20, Loss: 0.0209\n",
            "root        : INFO     Epoch: 62, Batch: 40, Loss: 0.0372\n",
            "root        : INFO     Epoch: 62, Batch: 60, Loss: 0.0304\n",
            "root        : INFO     Epoch: 62, Batch: 80, Loss: 0.0267\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 63\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 63, Batch: 20, Loss: 0.0321\n",
            "root        : INFO     Epoch: 63, Batch: 40, Loss: 0.0317\n",
            "root        : INFO     Epoch: 63, Batch: 60, Loss: 0.0335\n",
            "root        : INFO     Epoch: 63, Batch: 80, Loss: 0.0336\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 64\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Epoch: 64, Batch: 20, Loss: 0.0346\n",
            "root        : INFO     Epoch: 64, Batch: 40, Loss: 0.0190\n",
            "root        : INFO     Epoch: 64, Batch: 60, Loss: 0.0257\n",
            "root        : INFO     Epoch: 64, Batch: 80, Loss: 0.0249\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     Validating...\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 65\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Traceback (most recent call last):\n",
            "  File \"train_network_o.py\", line 367, in <module>\n",
            "    run()\n",
            "  File \"train_network_o.py\", line 339, in run\n",
            "    train_results = train(epoch, net, device, train_data, optimizer, args.batches_per_epoch, vis=args.vis)\n",
            "  File \"train_network_o.py\", line 182, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 255, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 149, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKBvXdwZVB2l"
      },
      "source": [
        "rm -rf /content/drive/MyDrive/GR_ConvNet_Code/logs/210925_0919_training_cornell"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb5RwBqVJOtf"
      },
      "source": [
        "cp -r /content/drive/MyDrive/GR_ConvNet_Code/train_network_it.py   /content/drive/MyDrive/GR_ConvNet_Code_GCoTNet/"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4lX4ytQKhUO"
      },
      "source": [
        "## GR-ConvNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7gfd3n-7HKA"
      },
      "source": [
        "**1. without augmentation, ds-rotate=0.0, Object-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32**  \n",
        "**Achived 0.944**saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1500_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_bE6Gwg41bF",
        "outputId": "54733463-19d0-456a-bb38-6d1df5d06a08"
      },
      "source": [
        "!python train_network_o.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.0 --augment 0 --lr=0.001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1500_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1336\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.2602\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0802\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.0936\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     97/177 = 0.548023\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0967\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0941\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0601\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0803\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     91/177 = 0.514124\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.1097\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0885\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0682\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0711\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     88/177 = 0.497175\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0597\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.1068\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0556\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0700\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     102/177 = 0.576271\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0641\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0817\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0446\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0485\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     96/177 = 0.542373\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0473\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0340\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0537\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0765\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     111/177 = 0.627119\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0530\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0500\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0441\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0688\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     110/177 = 0.621469\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0772\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0576\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0586\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0600\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     99/177 = 0.559322\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0686\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0512\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0410\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0504\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0343\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0498\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0281\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0577\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0593\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0701\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0571\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0548\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0876\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0573\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0587\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0597\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0323\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.1105\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0617\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0531\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0487\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0472\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0525\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0365\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0660\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0816\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0380\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0516\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     130/177 = 0.734463\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0395\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0445\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0385\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0487\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0211\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0595\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0478\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0715\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0504\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0407\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0428\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0535\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0492\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0657\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0340\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0302\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0463\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0490\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0397\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0401\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0324\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0508\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0259\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0489\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0432\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0476\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0663\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0585\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0502\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0348\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0434\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0307\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0330\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0210\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0424\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0376\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0583\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0238\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0386\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0406\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0393\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0496\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0503\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0312\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0439\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0257\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0280\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0686\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0623\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0327\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0566\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0280\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     165/177 = 0.932203\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0398\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0507\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0494\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0245\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0429\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0453\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0372\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0370\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     167/177 = 0.943503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq3tqm7f6nn6"
      },
      "source": [
        "**1. without augmentation, ds-rotate=0.0, Object-Wise, Transfer Learning  batch size=8, use rgbd, SGD 0.001, channel size =32**  \n",
        "**Achived ** saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210512_0344_training_cornell\n",
        "perform poor没有达到Adam+SGD优化的效果\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsgbXPLjprjV"
      },
      "source": [
        "!python train_network_ot.py --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1500_training_cornell/epoch_29_iou_0.94 --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.0 --optim SGD --lr=0.0005 --augment 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sapuRLGF5wr6"
      },
      "source": [
        "**1. without augmentation, ds-rotate=0.0, Object-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32 计算更多轮more epochs = 50**  \n",
        "**Achived 0.949 ** saved at  /content/drive/MyDrive/GR_ConvNet_Code/logs/210512_0447_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLYoaexC5MfN",
        "outputId": "6a97d096-09f7-4edb-a8da-1cc803666e01"
      },
      "source": [
        "!python train_network_o.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.0 --augment 0 --lr=0.001 --epochs 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 50, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210512_0447_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1368\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.1469\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0652\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.0983\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     101/177 = 0.570621\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0975\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0834\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.1005\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.1441\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     48/177 = 0.271186\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0629\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0526\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.1062\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0858\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     75/177 = 0.423729\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0684\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0573\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0854\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0583\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     104/177 = 0.587571\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0563\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.1041\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0695\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0375\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     114/177 = 0.644068\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0643\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0550\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0510\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0603\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0941\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0612\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0732\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0551\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     127/177 = 0.717514\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0406\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0486\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0600\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0652\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0599\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0554\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0631\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0545\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0568\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0333\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0354\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0562\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0600\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0429\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0697\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0478\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0386\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0552\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0710\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0724\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0450\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0380\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0336\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0463\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0401\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0728\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0585\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0525\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     121/177 = 0.683616\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0304\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0457\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0568\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0385\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0521\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0309\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0525\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0414\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0608\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0404\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0312\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0548\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0469\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0386\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0383\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0430\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0393\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0364\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0664\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0454\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0537\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0292\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0436\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0714\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0232\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0323\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0224\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0551\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0736\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0327\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0372\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0529\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0460\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0230\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0636\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0384\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0278\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0386\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0650\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0611\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0442\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0342\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0489\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0342\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0291\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0313\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0644\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0422\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0562\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0489\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0479\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0424\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0360\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0574\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0385\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0399\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0236\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0497\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0597\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0326\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0344\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0491\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0418\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0393\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 20, Loss: 0.0346\n",
            "root        : INFO     Epoch: 30, Batch: 40, Loss: 0.0318\n",
            "root        : INFO     Epoch: 30, Batch: 60, Loss: 0.0248\n",
            "root        : INFO     Epoch: 30, Batch: 80, Loss: 0.0271\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 20, Loss: 0.0422\n",
            "root        : INFO     Epoch: 31, Batch: 40, Loss: 0.0572\n",
            "root        : INFO     Epoch: 31, Batch: 60, Loss: 0.0277\n",
            "root        : INFO     Epoch: 31, Batch: 80, Loss: 0.0371\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 20, Loss: 0.0322\n",
            "root        : INFO     Epoch: 32, Batch: 40, Loss: 0.0448\n",
            "root        : INFO     Epoch: 32, Batch: 60, Loss: 0.0365\n",
            "root        : INFO     Epoch: 32, Batch: 80, Loss: 0.0351\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 20, Loss: 0.0412\n",
            "root        : INFO     Epoch: 33, Batch: 40, Loss: 0.0333\n",
            "root        : INFO     Epoch: 33, Batch: 60, Loss: 0.0415\n",
            "root        : INFO     Epoch: 33, Batch: 80, Loss: 0.0396\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 20, Loss: 0.0605\n",
            "root        : INFO     Epoch: 34, Batch: 40, Loss: 0.0345\n",
            "root        : INFO     Epoch: 34, Batch: 60, Loss: 0.0382\n",
            "root        : INFO     Epoch: 34, Batch: 80, Loss: 0.0452\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 20, Loss: 0.0456\n",
            "root        : INFO     Epoch: 35, Batch: 40, Loss: 0.0459\n",
            "root        : INFO     Epoch: 35, Batch: 60, Loss: 0.0499\n",
            "root        : INFO     Epoch: 35, Batch: 80, Loss: 0.0379\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 20, Loss: 0.0403\n",
            "root        : INFO     Epoch: 36, Batch: 40, Loss: 0.0415\n",
            "root        : INFO     Epoch: 36, Batch: 60, Loss: 0.0398\n",
            "root        : INFO     Epoch: 36, Batch: 80, Loss: 0.0752\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 20, Loss: 0.0263\n",
            "root        : INFO     Epoch: 37, Batch: 40, Loss: 0.0637\n",
            "root        : INFO     Epoch: 37, Batch: 60, Loss: 0.0315\n",
            "root        : INFO     Epoch: 37, Batch: 80, Loss: 0.0337\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 20, Loss: 0.0476\n",
            "root        : INFO     Epoch: 38, Batch: 60, Loss: 0.0480\n",
            "root        : INFO     Epoch: 38, Batch: 80, Loss: 0.0564\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 20, Loss: 0.0226\n",
            "root        : INFO     Epoch: 39, Batch: 40, Loss: 0.0257\n",
            "root        : INFO     Epoch: 39, Batch: 60, Loss: 0.0415\n",
            "root        : INFO     Epoch: 39, Batch: 80, Loss: 0.0303\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     168/177 = 0.949153\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 20, Loss: 0.0567\n",
            "root        : INFO     Epoch: 40, Batch: 40, Loss: 0.0494\n",
            "root        : INFO     Epoch: 40, Batch: 60, Loss: 0.0579\n",
            "root        : INFO     Epoch: 40, Batch: 80, Loss: 0.0406\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 20, Loss: 0.0468\n",
            "root        : INFO     Epoch: 41, Batch: 40, Loss: 0.0273\n",
            "root        : INFO     Epoch: 41, Batch: 60, Loss: 0.0627\n",
            "root        : INFO     Epoch: 41, Batch: 80, Loss: 0.0264\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 20, Loss: 0.0795\n",
            "root        : INFO     Epoch: 42, Batch: 40, Loss: 0.0301\n",
            "root        : INFO     Epoch: 42, Batch: 60, Loss: 0.0436\n",
            "root        : INFO     Epoch: 42, Batch: 80, Loss: 0.0247\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 20, Loss: 0.0342\n",
            "root        : INFO     Epoch: 43, Batch: 40, Loss: 0.0525\n",
            "root        : INFO     Epoch: 43, Batch: 60, Loss: 0.0287\n",
            "root        : INFO     Epoch: 43, Batch: 80, Loss: 0.0365\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 20, Loss: 0.3508\n",
            "root        : INFO     Epoch: 44, Batch: 40, Loss: 0.0810\n",
            "root        : INFO     Epoch: 44, Batch: 60, Loss: 0.0520\n",
            "root        : INFO     Epoch: 44, Batch: 80, Loss: 0.0494\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     87/177 = 0.491525\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 20, Loss: 0.0937\n",
            "root        : INFO     Epoch: 45, Batch: 40, Loss: 0.0278\n",
            "root        : INFO     Epoch: 45, Batch: 60, Loss: 0.0421\n",
            "root        : INFO     Epoch: 45, Batch: 80, Loss: 0.0741\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     92/177 = 0.519774\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 20, Loss: 0.0537\n",
            "root        : INFO     Epoch: 46, Batch: 40, Loss: 0.0691\n",
            "root        : INFO     Epoch: 46, Batch: 60, Loss: 0.0607\n",
            "root        : INFO     Epoch: 46, Batch: 80, Loss: 0.0622\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 20, Loss: 0.0585\n",
            "root        : INFO     Epoch: 47, Batch: 40, Loss: 0.0493\n",
            "root        : INFO     Epoch: 47, Batch: 60, Loss: 0.0752\n",
            "root        : INFO     Epoch: 47, Batch: 80, Loss: 0.0297\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     126/177 = 0.711864\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 20, Loss: 0.0484\n",
            "root        : INFO     Epoch: 48, Batch: 40, Loss: 0.0255\n",
            "root        : INFO     Epoch: 48, Batch: 60, Loss: 0.0338\n",
            "root        : INFO     Epoch: 48, Batch: 80, Loss: 0.0438\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     118/177 = 0.666667\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 20, Loss: 0.0272\n",
            "root        : INFO     Epoch: 49, Batch: 40, Loss: 0.0472\n",
            "root        : INFO     Epoch: 49, Batch: 60, Loss: 0.0533\n",
            "root        : INFO     Epoch: 49, Batch: 80, Loss: 0.0492\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNJHUTujmHUf"
      },
      "source": [
        "**visualisation by tensorboard**  \n",
        "without dropout: /content/drive/MyDrive/GR_ConvNet_Code/logs/210512_0329_training_cornell  \n",
        "without BN: /content/drive/MyDrive/GR_ConvNet_Code/logs/210513_1000_training_cornell  \n",
        "original: /content/drive/MyDrive/GR_ConvNet_Code/logs/210512_0447_training_cornell  \n",
        "/content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1500_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ec0oLnjPuGT",
        "outputId": "e8b63305-d9af-431e-c1d6-7ffd89646813"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-05-18 03:57:58--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.202.43.88, 52.5.194.13, 54.159.34.239, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.202.43.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.4’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  15.6MB/s    in 0.8s    \n",
            "\n",
            "2021-05-18 03:57:59 (15.6 MB/s) - ‘ngrok-stable-linux-amd64.zip.4’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03boiGXKPwsU",
        "outputId": "0eb29af9-b2a7-4978-e8dd-037e8cf9e43f"
      },
      "source": [
        "LOG_DIR = '/content/drive/MyDrive/GR_ConvNet_Code/logs/210513_1432_training_cornell'\n",
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6008 &'.format(LOG_DIR))\n",
        "#开启ngrok service，绑定port 6006(tensorboard)\n",
        "get_ipython().system_raw('./ngrok http 6008 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://0ae3a3e79a2e.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WodSI12ql2Na",
        "outputId": "a269a3dd-0e6e-474e-eb43-595ec2b46769"
      },
      "source": [
        "!tensorboard --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs/210513_1432_training_cornell --port 6008 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-05-18 04:07:09.326738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.4.1 at http://localhost:6008/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwy0q3GWJygh"
      },
      "source": [
        "**1. without augmentation, without Batch Normalization in convolutional and transposed convolutional layer, ds-rotate=0.0, Object-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32  epochs = 50**  \n",
        "**Achived  ** saved at  /content/drive/MyDrive/GR_ConvNet_Code/logs/210513_1000_training_cornell  \n",
        "grconvnet3_noBN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWr_3ColJx1i",
        "outputId": "9e549352-cdf3-48bb-dcdc-40d38bc26ee8"
      },
      "source": [
        "!python train_network_o.py --network grconvnet3_nobn --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.0 --augment 0 --lr=0.001 --epochs 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3_nobn, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 50, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210513_1000_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "            Conv2d-2         [-1, 64, 112, 112]          32,832\n",
            "            Conv2d-3          [-1, 128, 56, 56]         131,200\n",
            "            Conv2d-4          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-5          [-1, 128, 56, 56]             256\n",
            "            Conv2d-6          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-7          [-1, 128, 56, 56]             256\n",
            "     ResidualBlock-8          [-1, 128, 56, 56]               0\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "           Conv2d-11          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-13          [-1, 128, 56, 56]               0\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "           Conv2d-16          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-18          [-1, 128, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "           Conv2d-21          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-22          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-23          [-1, 128, 56, 56]               0\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "           Conv2d-26          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-27          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-28          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-29         [-1, 64, 113, 113]         131,136\n",
            "  ConvTranspose2d-30         [-1, 32, 225, 225]          32,800\n",
            "  ConvTranspose2d-31         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-32         [-1, 32, 225, 225]               0\n",
            "           Conv2d-33          [-1, 1, 224, 224]             129\n",
            "          Dropout-34         [-1, 32, 225, 225]               0\n",
            "           Conv2d-35          [-1, 1, 224, 224]             129\n",
            "          Dropout-36         [-1, 32, 225, 225]               0\n",
            "           Conv2d-37          [-1, 1, 224, 224]             129\n",
            "          Dropout-38         [-1, 32, 225, 225]               0\n",
            "           Conv2d-39          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,260\n",
            "Trainable params: 1,900,260\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 179.92\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 187.94\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1215\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.0610\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0850\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.0621\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     90/177 = 0.508475\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0626\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0815\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0419\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0785\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     78/177 = 0.440678\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0956\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0633\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0572\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0623\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     105/177 = 0.593220\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0491\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0465\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0753\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0538\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0708\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0673\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0528\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0661\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     118/177 = 0.666667\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0456\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0765\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0547\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0362\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0618\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0626\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0450\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0654\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0655\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0456\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0716\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0692\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0696\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0404\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0620\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0388\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0459\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0430\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0761\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0796\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0533\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0372\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0392\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0737\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0530\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0399\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0552\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0611\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0364\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0446\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0613\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0497\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0715\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0516\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0668\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0356\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0321\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0419\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0467\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0375\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0422\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0499\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0683\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0484\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0721\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0350\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0566\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0518\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0337\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0325\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0531\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0343\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0359\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0448\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0372\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0393\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0314\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0479\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0437\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0331\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0631\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0558\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0161\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0397\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0512\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0619\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0477\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0303\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0439\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0403\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0264\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0627\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0376\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0369\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0588\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0260\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0443\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0416\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0359\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0569\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0432\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0341\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0382\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0271\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0427\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0237\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0342\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0375\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0626\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0622\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0423\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0373\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0400\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0322\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0307\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0261\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0526\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0255\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0339\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0654\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 20, Loss: 0.0681\n",
            "root        : INFO     Epoch: 30, Batch: 40, Loss: 0.0231\n",
            "root        : INFO     Epoch: 30, Batch: 60, Loss: 0.0245\n",
            "root        : INFO     Epoch: 30, Batch: 80, Loss: 0.0541\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 20, Loss: 0.0198\n",
            "root        : INFO     Epoch: 31, Batch: 40, Loss: 0.0378\n",
            "root        : INFO     Epoch: 31, Batch: 60, Loss: 0.0325\n",
            "root        : INFO     Epoch: 31, Batch: 80, Loss: 0.0406\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 20, Loss: 0.0555\n",
            "root        : INFO     Epoch: 32, Batch: 40, Loss: 0.0401\n",
            "root        : INFO     Epoch: 32, Batch: 60, Loss: 0.0291\n",
            "root        : INFO     Epoch: 32, Batch: 80, Loss: 0.0261\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 20, Loss: 0.0368\n",
            "root        : INFO     Epoch: 33, Batch: 40, Loss: 0.0482\n",
            "root        : INFO     Epoch: 33, Batch: 60, Loss: 0.0230\n",
            "root        : INFO     Epoch: 33, Batch: 80, Loss: 0.0174\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 20, Loss: 0.0565\n",
            "root        : INFO     Epoch: 34, Batch: 40, Loss: 0.0555\n",
            "root        : INFO     Epoch: 34, Batch: 60, Loss: 0.0312\n",
            "root        : INFO     Epoch: 34, Batch: 80, Loss: 0.0369\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 20, Loss: 0.0360\n",
            "root        : INFO     Epoch: 35, Batch: 40, Loss: 0.0232\n",
            "root        : INFO     Epoch: 35, Batch: 60, Loss: 0.0326\n",
            "root        : INFO     Epoch: 35, Batch: 80, Loss: 0.0257\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 20, Loss: 0.0491\n",
            "root        : INFO     Epoch: 36, Batch: 40, Loss: 0.0426\n",
            "root        : INFO     Epoch: 36, Batch: 60, Loss: 0.0238\n",
            "root        : INFO     Epoch: 36, Batch: 80, Loss: 0.0223\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 20, Loss: 0.0326\n",
            "root        : INFO     Epoch: 37, Batch: 40, Loss: 0.0433\n",
            "root        : INFO     Epoch: 37, Batch: 60, Loss: 0.0316\n",
            "root        : INFO     Epoch: 37, Batch: 80, Loss: 0.0489\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 20, Loss: 0.0531\n",
            "root        : INFO     Epoch: 38, Batch: 40, Loss: 0.0854\n",
            "root        : INFO     Epoch: 38, Batch: 60, Loss: 0.0397\n",
            "root        : INFO     Epoch: 38, Batch: 80, Loss: 0.0569\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 20, Loss: 0.0281\n",
            "root        : INFO     Epoch: 39, Batch: 40, Loss: 0.0474\n",
            "root        : INFO     Epoch: 39, Batch: 60, Loss: 0.0250\n",
            "root        : INFO     Epoch: 39, Batch: 80, Loss: 0.0436\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 20, Loss: 0.0475\n",
            "root        : INFO     Epoch: 40, Batch: 40, Loss: 0.0295\n",
            "root        : INFO     Epoch: 40, Batch: 60, Loss: 0.0301\n",
            "root        : INFO     Epoch: 40, Batch: 80, Loss: 0.0513\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 20, Loss: 0.0463\n",
            "root        : INFO     Epoch: 41, Batch: 40, Loss: 0.0296\n",
            "root        : INFO     Epoch: 41, Batch: 60, Loss: 0.0194\n",
            "root        : INFO     Epoch: 41, Batch: 80, Loss: 0.0388\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 20, Loss: 0.0324\n",
            "root        : INFO     Epoch: 42, Batch: 40, Loss: 0.0452\n",
            "root        : INFO     Epoch: 42, Batch: 60, Loss: 0.0331\n",
            "root        : INFO     Epoch: 42, Batch: 80, Loss: 0.0453\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 20, Loss: 0.0318\n",
            "root        : INFO     Epoch: 43, Batch: 40, Loss: 0.0364\n",
            "root        : INFO     Epoch: 43, Batch: 60, Loss: 0.0363\n",
            "root        : INFO     Epoch: 43, Batch: 80, Loss: 0.0335\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 20, Loss: 0.0455\n",
            "root        : INFO     Epoch: 44, Batch: 40, Loss: 0.0571\n",
            "root        : INFO     Epoch: 44, Batch: 60, Loss: 0.0647\n",
            "root        : INFO     Epoch: 44, Batch: 80, Loss: 0.0328\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 20, Loss: 0.0706\n",
            "root        : INFO     Epoch: 45, Batch: 40, Loss: 0.0620\n",
            "root        : INFO     Epoch: 45, Batch: 60, Loss: 0.0321\n",
            "root        : INFO     Epoch: 45, Batch: 80, Loss: 0.0343\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 20, Loss: 0.0545\n",
            "root        : INFO     Epoch: 46, Batch: 40, Loss: 0.0419\n",
            "root        : INFO     Epoch: 46, Batch: 60, Loss: 0.0454\n",
            "root        : INFO     Epoch: 46, Batch: 80, Loss: 0.0213\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 20, Loss: 0.0318\n",
            "root        : INFO     Epoch: 47, Batch: 40, Loss: 0.0280\n",
            "root        : INFO     Epoch: 47, Batch: 60, Loss: 0.0258\n",
            "root        : INFO     Epoch: 47, Batch: 80, Loss: 0.0223\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 20, Loss: 0.0483\n",
            "root        : INFO     Epoch: 48, Batch: 40, Loss: 0.0240\n",
            "root        : INFO     Epoch: 48, Batch: 60, Loss: 0.0334\n",
            "root        : INFO     Epoch: 48, Batch: 80, Loss: 0.0387\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 20, Loss: 0.0211\n",
            "root        : INFO     Epoch: 49, Batch: 40, Loss: 0.0404\n",
            "root        : INFO     Epoch: 49, Batch: 60, Loss: 0.0383\n",
            "root        : INFO     Epoch: 49, Batch: 80, Loss: 0.0454\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yekp48dyhPSl"
      },
      "source": [
        "**1. without augmentation, without dropout (dropout probability = 0) ds-rotate=0.0, Object-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32**  \n",
        "**Achived 0.944 but slower**saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210512_0329_training_cornell\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6dEaIg-gONP",
        "outputId": "71c5ff56-009d-4b2e-b76d-057104a3ed36"
      },
      "source": [
        "!python train_network_o.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.0 --augment 0 --lr=0.001 --epochs 50 --dropout-prob 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.00, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 50, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210512_0329_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1700\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.0767\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0649\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.1115\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0836\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0464\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0766\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.1039\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     73/177 = 0.412429\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0649\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0563\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0465\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0967\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0712\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0877\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0489\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0468\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/177 = 0.468927\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.1003\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0725\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0403\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0632\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     105/177 = 0.593220\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0539\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0878\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0591\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0478\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     112/177 = 0.632768\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0294\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0285\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0296\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0582\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     108/177 = 0.610169\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0780\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.1091\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0508\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0357\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     114/177 = 0.644068\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0662\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0506\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0452\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0384\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0591\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0499\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0422\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0433\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0458\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0478\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0401\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0704\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0505\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0781\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0521\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0407\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0451\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0381\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0287\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0760\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0338\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0621\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0361\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0533\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0298\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0436\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0244\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0739\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0453\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0353\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0297\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0440\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0323\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0619\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0258\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0422\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0650\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0441\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0499\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0571\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0292\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0302\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0338\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0383\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0442\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0203\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0358\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0316\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0757\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0291\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0305\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0600\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0309\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0743\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0733\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0387\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0622\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0445\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0504\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0276\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0385\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0438\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0471\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0386\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0264\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0324\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0396\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0632\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0274\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0349\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0718\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0166\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0629\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0420\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0540\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0380\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0385\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0471\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0444\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0222\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0574\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0546\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0511\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0393\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0551\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0355\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0411\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0359\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 20, Loss: 0.0581\n",
            "root        : INFO     Epoch: 30, Batch: 40, Loss: 0.0568\n",
            "root        : INFO     Epoch: 30, Batch: 60, Loss: 0.0514\n",
            "root        : INFO     Epoch: 30, Batch: 80, Loss: 0.0408\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 20, Loss: 0.0449\n",
            "root        : INFO     Epoch: 31, Batch: 40, Loss: 0.0267\n",
            "root        : INFO     Epoch: 31, Batch: 60, Loss: 0.0293\n",
            "root        : INFO     Epoch: 31, Batch: 80, Loss: 0.0329\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 20, Loss: 0.0377\n",
            "root        : INFO     Epoch: 32, Batch: 40, Loss: 0.0423\n",
            "root        : INFO     Epoch: 32, Batch: 60, Loss: 0.0516\n",
            "root        : INFO     Epoch: 32, Batch: 80, Loss: 0.0543\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 20, Loss: 0.0473\n",
            "root        : INFO     Epoch: 33, Batch: 40, Loss: 0.0485\n",
            "root        : INFO     Epoch: 33, Batch: 60, Loss: 0.0249\n",
            "root        : INFO     Epoch: 33, Batch: 80, Loss: 0.0301\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 20, Loss: 0.0363\n",
            "root        : INFO     Epoch: 34, Batch: 40, Loss: 0.0558\n",
            "root        : INFO     Epoch: 34, Batch: 60, Loss: 0.0375\n",
            "root        : INFO     Epoch: 34, Batch: 80, Loss: 0.0350\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 20, Loss: 0.0492\n",
            "root        : INFO     Epoch: 35, Batch: 40, Loss: 0.0447\n",
            "root        : INFO     Epoch: 35, Batch: 60, Loss: 0.0192\n",
            "root        : INFO     Epoch: 35, Batch: 80, Loss: 0.0271\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 20, Loss: 0.0312\n",
            "root        : INFO     Epoch: 36, Batch: 40, Loss: 0.0462\n",
            "root        : INFO     Epoch: 36, Batch: 60, Loss: 0.0366\n",
            "root        : INFO     Epoch: 36, Batch: 80, Loss: 0.0329\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 20, Loss: 0.0619\n",
            "root        : INFO     Epoch: 37, Batch: 40, Loss: 0.0465\n",
            "root        : INFO     Epoch: 37, Batch: 60, Loss: 0.0371\n",
            "root        : INFO     Epoch: 37, Batch: 80, Loss: 0.0280\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 20, Loss: 0.0353\n",
            "root        : INFO     Epoch: 38, Batch: 40, Loss: 0.0393\n",
            "root        : INFO     Epoch: 38, Batch: 60, Loss: 0.0237\n",
            "root        : INFO     Epoch: 38, Batch: 80, Loss: 0.0252\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 20, Loss: 0.0374\n",
            "root        : INFO     Epoch: 39, Batch: 40, Loss: 0.0500\n",
            "root        : INFO     Epoch: 39, Batch: 60, Loss: 0.0245\n",
            "root        : INFO     Epoch: 39, Batch: 80, Loss: 0.0597\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 20, Loss: 0.0477\n",
            "root        : INFO     Epoch: 40, Batch: 40, Loss: 0.0246\n",
            "root        : INFO     Epoch: 40, Batch: 60, Loss: 0.0280\n",
            "root        : INFO     Epoch: 40, Batch: 80, Loss: 0.0365\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 20, Loss: 0.0699\n",
            "root        : INFO     Epoch: 41, Batch: 40, Loss: 0.0389\n",
            "root        : INFO     Epoch: 41, Batch: 60, Loss: 0.0330\n",
            "root        : INFO     Epoch: 41, Batch: 80, Loss: 0.0275\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     167/177 = 0.943503\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 20, Loss: 0.0205\n",
            "root        : INFO     Epoch: 42, Batch: 40, Loss: 0.0392\n",
            "root        : INFO     Epoch: 42, Batch: 60, Loss: 0.0213\n",
            "root        : INFO     Epoch: 42, Batch: 80, Loss: 0.0378\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 20, Loss: 0.0237\n",
            "root        : INFO     Epoch: 43, Batch: 40, Loss: 0.0262\n",
            "root        : INFO     Epoch: 43, Batch: 60, Loss: 0.0342\n",
            "root        : INFO     Epoch: 43, Batch: 80, Loss: 0.0398\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 20, Loss: 0.0374\n",
            "root        : INFO     Epoch: 44, Batch: 40, Loss: 0.0451\n",
            "root        : INFO     Epoch: 44, Batch: 60, Loss: 0.0271\n",
            "root        : INFO     Epoch: 44, Batch: 80, Loss: 0.0449\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 20, Loss: 0.0373\n",
            "root        : INFO     Epoch: 45, Batch: 40, Loss: 0.0233\n",
            "root        : INFO     Epoch: 45, Batch: 60, Loss: 0.0307\n",
            "root        : INFO     Epoch: 45, Batch: 80, Loss: 0.0712\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 20, Loss: 0.0213\n",
            "root        : INFO     Epoch: 46, Batch: 40, Loss: 0.0239\n",
            "root        : INFO     Epoch: 46, Batch: 60, Loss: 0.0253\n",
            "root        : INFO     Epoch: 46, Batch: 80, Loss: 0.0519\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 20, Loss: 0.0383\n",
            "root        : INFO     Epoch: 47, Batch: 40, Loss: 0.0576\n",
            "root        : INFO     Epoch: 47, Batch: 60, Loss: 0.0263\n",
            "root        : INFO     Epoch: 47, Batch: 80, Loss: 0.0433\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 20, Loss: 0.0279\n",
            "root        : INFO     Epoch: 48, Batch: 40, Loss: 0.0247\n",
            "root        : INFO     Epoch: 48, Batch: 60, Loss: 0.0290\n",
            "root        : INFO     Epoch: 48, Batch: 80, Loss: 0.0468\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 20, Loss: 0.0372\n",
            "root        : INFO     Epoch: 49, Batch: 40, Loss: 0.0388\n",
            "root        : INFO     Epoch: 49, Batch: 60, Loss: 0.0507\n",
            "root        : INFO     Epoch: 49, Batch: 80, Loss: 0.0326\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCnrIdwre0gR"
      },
      "source": [
        "**1. without augmentation, ds-rotate=0.0, Image-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32**  \n",
        "**Achived 0.910** saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1826_training_cornell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPFOgOvLoNE9",
        "outputId": "10c1a5b4-332f-4f76-c622-cd4a6b835ffa"
      },
      "source": [
        "!python train_network_i.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.0 --augment 0 --lr=0.001 --epochs=50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.00, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 50, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1826_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1440\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.0786\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.1564\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.1145\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     64/177 = 0.361582\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0963\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0833\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0747\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.1055\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     71/177 = 0.401130\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0910\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0763\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0637\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0575\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     64/177 = 0.361582\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.1016\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0541\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0433\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0640\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/177 = 0.451977\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0841\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0443\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0738\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0551\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     104/177 = 0.587571\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0438\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.1030\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0502\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.1108\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0695\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0302\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0658\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0823\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     91/177 = 0.514124\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0477\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0546\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0956\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0752\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     97/177 = 0.548023\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0573\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0608\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0535\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0344\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     106/177 = 0.598870\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0392\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0329\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0725\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0629\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0427\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0851\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0610\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0472\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0496\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0568\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0418\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0591\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0417\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0774\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0554\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0458\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0648\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0628\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0545\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0397\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     101/177 = 0.570621\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0502\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0734\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0926\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0457\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     83/177 = 0.468927\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0470\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0636\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0519\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0491\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0675\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0780\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0511\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0436\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0423\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0748\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0626\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0533\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0394\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0663\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0798\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0722\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0429\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0704\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0421\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0494\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0418\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0314\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.1027\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0477\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0492\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0368\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0729\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0483\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     101/177 = 0.570621\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0436\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0437\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0341\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0514\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0621\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0369\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0282\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0319\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     110/177 = 0.621469\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0486\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0323\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0467\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0398\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0548\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0318\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0801\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0232\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0444\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0310\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0251\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0332\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0499\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0333\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0514\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0254\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0488\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0275\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0621\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0474\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0304\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0311\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0344\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0424\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 20, Loss: 0.0406\n",
            "root        : INFO     Epoch: 30, Batch: 40, Loss: 0.0406\n",
            "root        : INFO     Epoch: 30, Batch: 60, Loss: 0.0708\n",
            "root        : INFO     Epoch: 30, Batch: 80, Loss: 0.0348\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 20, Loss: 0.0632\n",
            "root        : INFO     Epoch: 31, Batch: 40, Loss: 0.0254\n",
            "root        : INFO     Epoch: 31, Batch: 60, Loss: 0.0366\n",
            "root        : INFO     Epoch: 31, Batch: 80, Loss: 0.0863\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 20, Loss: 0.0547\n",
            "root        : INFO     Epoch: 32, Batch: 40, Loss: 0.0411\n",
            "root        : INFO     Epoch: 32, Batch: 60, Loss: 0.0780\n",
            "root        : INFO     Epoch: 32, Batch: 80, Loss: 0.0532\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 20, Loss: 0.0518\n",
            "root        : INFO     Epoch: 33, Batch: 40, Loss: 0.0616\n",
            "root        : INFO     Epoch: 33, Batch: 60, Loss: 0.0654\n",
            "root        : INFO     Epoch: 33, Batch: 80, Loss: 0.0342\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 20, Loss: 0.0288\n",
            "root        : INFO     Epoch: 34, Batch: 40, Loss: 0.0661\n",
            "root        : INFO     Epoch: 34, Batch: 60, Loss: 0.0501\n",
            "root        : INFO     Epoch: 34, Batch: 80, Loss: 0.0348\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 20, Loss: 0.0471\n",
            "root        : INFO     Epoch: 35, Batch: 40, Loss: 0.0538\n",
            "root        : INFO     Epoch: 35, Batch: 60, Loss: 0.0379\n",
            "root        : INFO     Epoch: 35, Batch: 80, Loss: 0.0540\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 20, Loss: 0.0376\n",
            "root        : INFO     Epoch: 36, Batch: 40, Loss: 0.0273\n",
            "root        : INFO     Epoch: 36, Batch: 60, Loss: 0.0623\n",
            "root        : INFO     Epoch: 36, Batch: 80, Loss: 0.0262\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 20, Loss: 0.0526\n",
            "root        : INFO     Epoch: 37, Batch: 40, Loss: 0.0241\n",
            "root        : INFO     Epoch: 37, Batch: 60, Loss: 0.0453\n",
            "root        : INFO     Epoch: 37, Batch: 80, Loss: 0.0505\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 20, Loss: 0.0480\n",
            "root        : INFO     Epoch: 38, Batch: 40, Loss: 0.0604\n",
            "root        : INFO     Epoch: 38, Batch: 60, Loss: 0.0377\n",
            "root        : INFO     Epoch: 38, Batch: 80, Loss: 0.0615\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 20, Loss: 0.0437\n",
            "root        : INFO     Epoch: 39, Batch: 40, Loss: 0.0345\n",
            "root        : INFO     Epoch: 39, Batch: 60, Loss: 0.0474\n",
            "root        : INFO     Epoch: 39, Batch: 80, Loss: 0.0241\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 20, Loss: 0.0189\n",
            "root        : INFO     Epoch: 40, Batch: 40, Loss: 0.0226\n",
            "root        : INFO     Epoch: 40, Batch: 60, Loss: 0.0345\n",
            "root        : INFO     Epoch: 40, Batch: 80, Loss: 0.0376\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 20, Loss: 0.0419\n",
            "root        : INFO     Epoch: 41, Batch: 40, Loss: 0.0227\n",
            "root        : INFO     Epoch: 41, Batch: 60, Loss: 0.0339\n",
            "root        : INFO     Epoch: 41, Batch: 80, Loss: 0.0637\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 20, Loss: 0.0232\n",
            "root        : INFO     Epoch: 42, Batch: 40, Loss: 0.0392\n",
            "root        : INFO     Epoch: 42, Batch: 60, Loss: 0.0241\n",
            "root        : INFO     Epoch: 42, Batch: 80, Loss: 0.0307\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 20, Loss: 0.0769\n",
            "root        : INFO     Epoch: 43, Batch: 40, Loss: 0.0332\n",
            "root        : INFO     Epoch: 43, Batch: 60, Loss: 0.0330\n",
            "root        : INFO     Epoch: 43, Batch: 80, Loss: 0.0339\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 20, Loss: 0.0326\n",
            "root        : INFO     Epoch: 44, Batch: 40, Loss: 0.0599\n",
            "root        : INFO     Epoch: 44, Batch: 60, Loss: 0.0492\n",
            "root        : INFO     Epoch: 44, Batch: 80, Loss: 0.0434\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 20, Loss: 0.0567\n",
            "root        : INFO     Epoch: 45, Batch: 40, Loss: 0.0524\n",
            "root        : INFO     Epoch: 45, Batch: 60, Loss: 0.0329\n",
            "root        : INFO     Epoch: 45, Batch: 80, Loss: 0.0399\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 20, Loss: 0.0407\n",
            "root        : INFO     Epoch: 46, Batch: 40, Loss: 0.0404\n",
            "root        : INFO     Epoch: 46, Batch: 60, Loss: 0.0326\n",
            "root        : INFO     Epoch: 46, Batch: 80, Loss: 0.0296\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 20, Loss: 0.0836\n",
            "root        : INFO     Epoch: 47, Batch: 40, Loss: 0.0524\n",
            "root        : INFO     Epoch: 47, Batch: 60, Loss: 0.0202\n",
            "root        : INFO     Epoch: 47, Batch: 80, Loss: 0.0303\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 20, Loss: 0.0737\n",
            "root        : INFO     Epoch: 48, Batch: 40, Loss: 0.0262\n",
            "root        : INFO     Epoch: 48, Batch: 60, Loss: 0.0351\n",
            "root        : INFO     Epoch: 48, Batch: 80, Loss: 0.0410\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 20, Loss: 0.0505\n",
            "root        : INFO     Epoch: 49, Batch: 40, Loss: 0.0196\n",
            "root        : INFO     Epoch: 49, Batch: 60, Loss: 0.0331\n",
            "root        : INFO     Epoch: 49, Batch: 80, Loss: 0.0300\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxKF3iL9d5f8"
      },
      "source": [
        "**Evaluation --split 0.8 --ds-rotate 0.0 --iou-eval --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93 **\n",
        "\n",
        "Why the validation accuracy in evaluation segment (0.915) is different from that in training segment (0.93) ? \n",
        "\n",
        "*   Dropout, BN layer, etc produce randomness, and the lack of **net.eval()** may be responsible for it. \n",
        "*   random_zoom and random_rotate.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh04cgtkZUds",
        "outputId": "e46e5da4-cb19-41e2-9ce0-6dd2abd3d8f1"
      },
      "source": [
        "!python evaluate2.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93 --dataset cornell --dataset-path /content/cornell_dataset --num-workers 8 --split 0.8 --ds-rotate 0.0 --iou-eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 177\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93\n",
            "INFO:root:Average evaluation time per image: 78.81698500638628ms\n",
            "INFO:root:IOU Results: 162/177 = 0.915254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP2UqOJrekVB"
      },
      "source": [
        "**Evaluation --split 0.0 --ds-rotate 0.0 --iou-eval --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93 **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYVBMNbNdIFx",
        "outputId": "1f87c6a4-dbf6-447a-8bb9-a28fb00df2a2"
      },
      "source": [
        "!python evaluate2.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93 --dataset cornell --dataset-path /content/cornell_dataset --num-workers 8 --split 0.0 --iou-eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 885\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93\n",
            "INFO:root:Average evaluation time per image: 77.28449476640776ms\n",
            "INFO:root:IOU Results: 777/885 = 0.877966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cipeya2UcX4c"
      },
      "source": [
        "**Do not use augmentation (random zoom and random rotate) in evaluation segment, because this adds randomness which makes outputs unstable.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sogZ5T_EbRD3",
        "outputId": "bc265a24-5354-4857-c6e6-a14351f42c5e"
      },
      "source": [
        "!python evaluate2.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93 --dataset cornell --dataset-path /content/cornell_dataset --num-workers 8 --split 0.8 --ds-rotate 0.0 --iou-eval --augment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 177\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0716_training_cornell/epoch_17_iou_0.93\n",
            "INFO:root:Average evaluation time per image: 84.30235399364753ms\n",
            "INFO:root:IOU Results: 153/177 = 0.864407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i23iw_dHxU9A"
      },
      "source": [
        "**2.ds-rotate=0.2, Image-Wise, Using original code train_network.py to train the cornell dataset, , batch size=8, use rgbd, Adam 0.001, channel size =32**\n",
        "\n",
        "**achieved 0.927**\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0837_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn5cE-mjxU0J",
        "outputId": "b18bfb1d-9b9c-43e4-851d-473593fa336a"
      },
      "source": [
        "!python train_network.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8 --ds-shuffle --ds-rotate 0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Done\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1022\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1866\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0660\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1763\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0974\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1356\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.1203\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1162\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     96/177 = 0.542373\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0760\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1567\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0862\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0767\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0538\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0838\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.1530\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0659\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1093\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.1349\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0879\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0957\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0818\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.1256\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0776\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0428\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0815\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0725\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0601\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0602\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0798\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0890\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0774\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0668\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1046\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.1200\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0694\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1067\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0452\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0866\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0792\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.1190\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.1107\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.1027\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0595\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.1112\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.1073\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.1236\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.1035\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0815\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0876\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.1368\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0430\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0880\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0584\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0632\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0691\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0462\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0946\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.1044\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0631\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0482\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0495\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.1282\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.1132\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0840\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0504\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0916\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0650\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0578\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0946\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.1030\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.1080\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0637\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.1468\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1064\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0823\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0509\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0939\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0789\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0936\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0750\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.1360\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0992\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0679\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0507\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0883\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0745\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0894\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0634\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0805\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0549\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0503\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.1019\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.1033\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.1159\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0427\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0605\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0893\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0392\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0748\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0746\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0746\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0650\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.1257\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0419\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0833\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0900\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0495\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0842\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0506\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.1029\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.1258\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0477\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0837\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0921\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0987\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0713\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0960\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0602\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0787\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0629\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0623\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0790\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0572\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0751\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0905\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.1056\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0848\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0533\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0792\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0765\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0607\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0864\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0527\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0918\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0963\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0585\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0967\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.1092\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0679\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0565\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0788\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.1021\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0890\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0365\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.1055\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0843\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0266\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0669\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0429\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0928\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.0897\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0893\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.1576\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0545\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0539\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0421\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0446\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.1064\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0798\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0720\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0634\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0707\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0283\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0597\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.0564\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0485\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.0874\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.0346\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0950\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0835\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0468\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0530\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.0520\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.1155\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.0892\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0833\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0844\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0705\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0469\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0562\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0573\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.0727\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.1348\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.0962\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0555\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0789\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0352\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0457\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0393\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0468\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.0702\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.0533\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0924\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0433\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0683\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0702\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.0898\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.0569\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.0611\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.0426\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0622\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0765\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0660\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0638\n",
            "root        : INFO     Epoch: 25, Batch: 500, Loss: 0.0342\n",
            "root        : INFO     Epoch: 25, Batch: 600, Loss: 0.0532\n",
            "root        : INFO     Epoch: 25, Batch: 700, Loss: 0.0523\n",
            "root        : INFO     Epoch: 25, Batch: 800, Loss: 0.0467\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0621\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.1089\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0581\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0557\n",
            "root        : INFO     Epoch: 26, Batch: 500, Loss: 0.0519\n",
            "root        : INFO     Epoch: 26, Batch: 600, Loss: 0.0701\n",
            "root        : INFO     Epoch: 26, Batch: 700, Loss: 0.0531\n",
            "root        : INFO     Epoch: 26, Batch: 800, Loss: 0.0741\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0553\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0625\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0405\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0679\n",
            "root        : INFO     Epoch: 27, Batch: 500, Loss: 0.0510\n",
            "root        : INFO     Epoch: 27, Batch: 600, Loss: 0.0817\n",
            "root        : INFO     Epoch: 27, Batch: 700, Loss: 0.0499\n",
            "root        : INFO     Epoch: 27, Batch: 800, Loss: 0.0472\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0634\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0949\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0564\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0490\n",
            "root        : INFO     Epoch: 28, Batch: 500, Loss: 0.0487\n",
            "root        : INFO     Epoch: 28, Batch: 600, Loss: 0.0807\n",
            "root        : INFO     Epoch: 28, Batch: 700, Loss: 0.0410\n",
            "root        : INFO     Epoch: 28, Batch: 800, Loss: 0.0886\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0995\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.1200\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0340\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0464\n",
            "root        : INFO     Epoch: 29, Batch: 500, Loss: 0.0543\n",
            "root        : INFO     Epoch: 29, Batch: 600, Loss: 0.0421\n",
            "root        : INFO     Epoch: 29, Batch: 700, Loss: 0.0732\n",
            "root        : INFO     Epoch: 29, Batch: 800, Loss: 0.0849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T-tqu43t-pQ"
      },
      "source": [
        "!rm -rf /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1408_training_cornell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEv7WiMNsbGW"
      },
      "source": [
        "**2. without augmentation, ds-rotate=0.2, Image-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32**  \n",
        "achive 0.927 saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1410_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvVHyK47sM4Y",
        "outputId": "0bb0a182-1654-49e3-c5f3-192773188a07"
      },
      "source": [
        "!python train_network_o.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.2 --augment 0 --lr 0.001 --epochs 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.20, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_1410_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1581\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.1169\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0824\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.1005\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     67/177 = 0.378531\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.1003\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0847\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0578\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0715\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     74/177 = 0.418079\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0588\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0954\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0728\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0512\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     69/177 = 0.389831\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0646\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0881\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0733\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0796\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     72/177 = 0.406780\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0697\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0538\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0479\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0622\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     85/177 = 0.480226\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0384\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0545\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0473\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0476\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     89/177 = 0.502825\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0806\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.1301\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0285\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0387\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     91/177 = 0.514124\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0975\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0693\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0541\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0843\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     101/177 = 0.570621\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0562\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0433\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.1088\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0722\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     112/177 = 0.632768\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0462\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0496\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0449\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0630\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     104/177 = 0.587571\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0790\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0735\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0385\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0488\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0381\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0758\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0458\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0722\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     123/177 = 0.694915\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0712\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0826\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0810\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0525\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     118/177 = 0.666667\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0499\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0422\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0542\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0700\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     123/177 = 0.694915\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0344\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0635\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0451\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0643\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0512\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0529\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0674\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0677\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     128/177 = 0.723164\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0640\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0459\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0373\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0355\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0565\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0406\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0604\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0766\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0474\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0433\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0679\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0550\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0566\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0611\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0749\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0659\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0274\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0698\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0761\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0328\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0581\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0749\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0828\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0223\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0499\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0785\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0596\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0831\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0346\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0873\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0549\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0830\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0576\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0299\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0629\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0367\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0445\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0526\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0518\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0374\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0493\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0539\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0577\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0467\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0638\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0456\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0382\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0579\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0720\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0462\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0767\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0447\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0384\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0449\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0863\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0375\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy09eRksDux4"
      },
      "source": [
        "**2. without augmentation, ds-rotate=0.2, Object-Wise, batch size=8, use rgbd, Adam 0.001, channel size =32 epochs=100**  \n",
        "achive  saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210513_1411_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CYeOHMCDQDF",
        "outputId": "b4936c75-4b36-4680-80e7-0c821dca5cbf"
      },
      "source": [
        "!python train_network_o.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.2 --augment 0 --lr 0.001 --epochs 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.20, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 100, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210513_1411_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.2001\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.1085\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0823\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.0666\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     61/177 = 0.344633\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.1012\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0641\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0715\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0875\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     55/177 = 0.310734\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0814\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0469\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0749\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0763\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     51/177 = 0.288136\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0724\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0508\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0836\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0472\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     62/177 = 0.350282\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0645\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0487\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0458\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0494\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     65/177 = 0.367232\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0786\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0758\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0419\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0722\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     56/177 = 0.316384\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0830\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0688\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0479\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0443\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     66/177 = 0.372881\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0667\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0661\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0429\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0575\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/177 = 0.355932\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0484\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0659\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0477\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0423\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     84/177 = 0.474576\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0609\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0517\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0422\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0380\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     99/177 = 0.559322\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0845\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0380\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0347\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0408\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/177 = 0.355932\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0751\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0483\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0353\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0648\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0546\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0564\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0477\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0583\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     117/177 = 0.661017\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0498\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0436\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0705\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0510\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     82/177 = 0.463277\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0412\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0374\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0586\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0474\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0426\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0590\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0515\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0565\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0752\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0300\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0475\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0498\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     106/177 = 0.598870\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0478\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0781\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0560\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0499\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0536\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0592\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0372\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0441\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0337\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0289\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0574\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0571\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     123/177 = 0.694915\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0426\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0490\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.1095\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0502\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/177 = 0.451977\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0658\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0669\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0633\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0692\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0511\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0348\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0635\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0577\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0855\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0484\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0565\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0829\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0535\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0261\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0352\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0505\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0566\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0426\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0331\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0557\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     118/177 = 0.666667\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0373\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0408\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0495\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0608\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     110/177 = 0.621469\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0414\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0365\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0511\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0590\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0494\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0508\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0451\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0454\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     115/177 = 0.649718\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0590\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0390\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0492\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0448\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 20, Loss: 0.0354\n",
            "root        : INFO     Epoch: 30, Batch: 40, Loss: 0.0289\n",
            "root        : INFO     Epoch: 30, Batch: 60, Loss: 0.0781\n",
            "root        : INFO     Epoch: 30, Batch: 80, Loss: 0.0542\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 20, Loss: 0.0291\n",
            "root        : INFO     Epoch: 31, Batch: 40, Loss: 0.0293\n",
            "root        : INFO     Epoch: 31, Batch: 60, Loss: 0.0455\n",
            "root        : INFO     Epoch: 31, Batch: 80, Loss: 0.0600\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 20, Loss: 0.0507\n",
            "root        : INFO     Epoch: 32, Batch: 40, Loss: 0.0516\n",
            "root        : INFO     Epoch: 32, Batch: 60, Loss: 0.0378\n",
            "root        : INFO     Epoch: 32, Batch: 80, Loss: 0.0528\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     73/177 = 0.412429\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 20, Loss: 0.0348\n",
            "root        : INFO     Epoch: 33, Batch: 40, Loss: 0.0493\n",
            "root        : INFO     Epoch: 33, Batch: 60, Loss: 0.0419\n",
            "root        : INFO     Epoch: 33, Batch: 80, Loss: 0.0444\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     100/177 = 0.564972\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 20, Loss: 0.0453\n",
            "root        : INFO     Epoch: 34, Batch: 40, Loss: 0.0329\n",
            "root        : INFO     Epoch: 34, Batch: 60, Loss: 0.0273\n",
            "root        : INFO     Epoch: 34, Batch: 80, Loss: 0.0554\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 20, Loss: 0.0465\n",
            "root        : INFO     Epoch: 35, Batch: 40, Loss: 0.0692\n",
            "root        : INFO     Epoch: 35, Batch: 60, Loss: 0.0400\n",
            "root        : INFO     Epoch: 35, Batch: 80, Loss: 0.0291\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     114/177 = 0.644068\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 20, Loss: 0.0436\n",
            "root        : INFO     Epoch: 36, Batch: 40, Loss: 0.0230\n",
            "root        : INFO     Epoch: 36, Batch: 60, Loss: 0.0456\n",
            "root        : INFO     Epoch: 36, Batch: 80, Loss: 0.0509\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 20, Loss: 0.0411\n",
            "root        : INFO     Epoch: 37, Batch: 40, Loss: 0.0469\n",
            "root        : INFO     Epoch: 37, Batch: 60, Loss: 0.0576\n",
            "root        : INFO     Epoch: 37, Batch: 80, Loss: 0.0363\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 20, Loss: 0.0342\n",
            "root        : INFO     Epoch: 38, Batch: 40, Loss: 0.0662\n",
            "root        : INFO     Epoch: 38, Batch: 60, Loss: 0.0247\n",
            "root        : INFO     Epoch: 38, Batch: 80, Loss: 0.0335\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 20, Loss: 0.1031\n",
            "root        : INFO     Epoch: 39, Batch: 40, Loss: 0.0849\n",
            "root        : INFO     Epoch: 39, Batch: 60, Loss: 0.0393\n",
            "root        : INFO     Epoch: 39, Batch: 80, Loss: 0.0535\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 20, Loss: 0.0696\n",
            "root        : INFO     Epoch: 40, Batch: 40, Loss: 0.0280\n",
            "root        : INFO     Epoch: 40, Batch: 60, Loss: 0.0364\n",
            "root        : INFO     Epoch: 40, Batch: 80, Loss: 0.0362\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 20, Loss: 0.0324\n",
            "root        : INFO     Epoch: 41, Batch: 40, Loss: 0.0373\n",
            "root        : INFO     Epoch: 41, Batch: 60, Loss: 0.0368\n",
            "root        : INFO     Epoch: 41, Batch: 80, Loss: 0.0378\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     126/177 = 0.711864\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 20, Loss: 0.0274\n",
            "root        : INFO     Epoch: 42, Batch: 40, Loss: 0.0612\n",
            "root        : INFO     Epoch: 42, Batch: 60, Loss: 0.0340\n",
            "root        : INFO     Epoch: 42, Batch: 80, Loss: 0.0452\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     116/177 = 0.655367\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 20, Loss: 0.0239\n",
            "root        : INFO     Epoch: 43, Batch: 40, Loss: 0.0358\n",
            "root        : INFO     Epoch: 43, Batch: 60, Loss: 0.0424\n",
            "root        : INFO     Epoch: 43, Batch: 80, Loss: 0.0627\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 20, Loss: 0.0314\n",
            "root        : INFO     Epoch: 44, Batch: 40, Loss: 0.0388\n",
            "root        : INFO     Epoch: 44, Batch: 60, Loss: 0.0530\n",
            "root        : INFO     Epoch: 44, Batch: 80, Loss: 0.0352\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 20, Loss: 0.0367\n",
            "root        : INFO     Epoch: 45, Batch: 40, Loss: 0.0272\n",
            "root        : INFO     Epoch: 45, Batch: 60, Loss: 0.0333\n",
            "root        : INFO     Epoch: 45, Batch: 80, Loss: 0.0405\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     119/177 = 0.672316\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 20, Loss: 0.0263\n",
            "root        : INFO     Epoch: 46, Batch: 40, Loss: 0.0211\n",
            "root        : INFO     Epoch: 46, Batch: 60, Loss: 0.0489\n",
            "root        : INFO     Epoch: 46, Batch: 80, Loss: 0.0378\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 20, Loss: 0.0424\n",
            "root        : INFO     Epoch: 47, Batch: 40, Loss: 0.0250\n",
            "root        : INFO     Epoch: 47, Batch: 60, Loss: 0.0526\n",
            "root        : INFO     Epoch: 47, Batch: 80, Loss: 0.0539\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 20, Loss: 0.0384\n",
            "root        : INFO     Epoch: 48, Batch: 40, Loss: 0.0301\n",
            "root        : INFO     Epoch: 48, Batch: 60, Loss: 0.0374\n",
            "root        : INFO     Epoch: 48, Batch: 80, Loss: 0.0247\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 20, Loss: 0.0281\n",
            "root        : INFO     Epoch: 49, Batch: 40, Loss: 0.0537\n",
            "root        : INFO     Epoch: 49, Batch: 60, Loss: 0.0228\n",
            "root        : INFO     Epoch: 49, Batch: 80, Loss: 0.0498\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 50\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 50, Batch: 20, Loss: 0.0366\n",
            "root        : INFO     Epoch: 50, Batch: 40, Loss: 0.0494\n",
            "root        : INFO     Epoch: 50, Batch: 60, Loss: 0.0335\n",
            "root        : INFO     Epoch: 50, Batch: 80, Loss: 0.0658\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 51\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 51, Batch: 20, Loss: 0.0335\n",
            "root        : INFO     Epoch: 51, Batch: 40, Loss: 0.0501\n",
            "root        : INFO     Epoch: 51, Batch: 60, Loss: 0.0324\n",
            "root        : INFO     Epoch: 51, Batch: 80, Loss: 0.0303\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 52\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 52, Batch: 20, Loss: 0.0507\n",
            "root        : INFO     Epoch: 52, Batch: 40, Loss: 0.0339\n",
            "root        : INFO     Epoch: 52, Batch: 60, Loss: 0.0333\n",
            "root        : INFO     Epoch: 52, Batch: 80, Loss: 0.0377\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 53\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 53, Batch: 20, Loss: 0.0396\n",
            "root        : INFO     Epoch: 53, Batch: 40, Loss: 0.0390\n",
            "root        : INFO     Epoch: 53, Batch: 60, Loss: 0.0307\n",
            "root        : INFO     Epoch: 53, Batch: 80, Loss: 0.0379\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 54\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 54, Batch: 20, Loss: 0.0312\n",
            "root        : INFO     Epoch: 54, Batch: 40, Loss: 0.0453\n",
            "root        : INFO     Epoch: 54, Batch: 60, Loss: 0.0305\n",
            "root        : INFO     Epoch: 54, Batch: 80, Loss: 0.0265\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 55\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 55, Batch: 20, Loss: 0.0502\n",
            "root        : INFO     Epoch: 55, Batch: 40, Loss: 0.0481\n",
            "root        : INFO     Epoch: 55, Batch: 60, Loss: 0.0391\n",
            "root        : INFO     Epoch: 55, Batch: 80, Loss: 0.0335\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     100/177 = 0.564972\n",
            "root        : INFO     Beginning Epoch 56\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 56, Batch: 20, Loss: 0.0276\n",
            "root        : INFO     Epoch: 56, Batch: 40, Loss: 0.0354\n",
            "root        : INFO     Epoch: 56, Batch: 60, Loss: 0.0313\n",
            "root        : INFO     Epoch: 56, Batch: 80, Loss: 0.0261\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     106/177 = 0.598870\n",
            "root        : INFO     Beginning Epoch 57\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 57, Batch: 20, Loss: 0.0496\n",
            "root        : INFO     Epoch: 57, Batch: 40, Loss: 0.0960\n",
            "root        : INFO     Epoch: 57, Batch: 60, Loss: 0.0461\n",
            "root        : INFO     Epoch: 57, Batch: 80, Loss: 0.0681\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 58\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 58, Batch: 20, Loss: 0.0413\n",
            "root        : INFO     Epoch: 58, Batch: 40, Loss: 0.0607\n",
            "root        : INFO     Epoch: 58, Batch: 60, Loss: 0.0318\n",
            "root        : INFO     Epoch: 58, Batch: 80, Loss: 0.0324\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 59\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 59, Batch: 20, Loss: 0.0535\n",
            "root        : INFO     Epoch: 59, Batch: 40, Loss: 0.0375\n",
            "root        : INFO     Epoch: 59, Batch: 60, Loss: 0.0233\n",
            "root        : INFO     Epoch: 59, Batch: 80, Loss: 0.0655\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     119/177 = 0.672316\n",
            "root        : INFO     Beginning Epoch 60\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 60, Batch: 20, Loss: 0.0480\n",
            "root        : INFO     Epoch: 60, Batch: 40, Loss: 0.0597\n",
            "root        : INFO     Epoch: 60, Batch: 60, Loss: 0.0398\n",
            "root        : INFO     Epoch: 60, Batch: 80, Loss: 0.0505\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 61\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 61, Batch: 20, Loss: 0.0426\n",
            "root        : INFO     Epoch: 61, Batch: 40, Loss: 0.0289\n",
            "root        : INFO     Epoch: 61, Batch: 60, Loss: 0.0630\n",
            "root        : INFO     Epoch: 61, Batch: 80, Loss: 0.0563\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     116/177 = 0.655367\n",
            "root        : INFO     Beginning Epoch 62\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 62, Batch: 20, Loss: 0.0427\n",
            "root        : INFO     Epoch: 62, Batch: 40, Loss: 0.0287\n",
            "root        : INFO     Epoch: 62, Batch: 60, Loss: 0.0351\n",
            "root        : INFO     Epoch: 62, Batch: 80, Loss: 0.0527\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 63\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 63, Batch: 20, Loss: 0.0360\n",
            "root        : INFO     Epoch: 63, Batch: 40, Loss: 0.0346\n",
            "root        : INFO     Epoch: 63, Batch: 60, Loss: 0.0631\n",
            "root        : INFO     Epoch: 63, Batch: 80, Loss: 0.0325\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 64\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 64, Batch: 20, Loss: 0.0411\n",
            "root        : INFO     Epoch: 64, Batch: 40, Loss: 0.0300\n",
            "root        : INFO     Epoch: 64, Batch: 60, Loss: 0.0450\n",
            "root        : INFO     Epoch: 64, Batch: 80, Loss: 0.0451\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 65\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 65, Batch: 20, Loss: 0.0781\n",
            "root        : INFO     Epoch: 65, Batch: 40, Loss: 0.0361\n",
            "root        : INFO     Epoch: 65, Batch: 60, Loss: 0.0484\n",
            "root        : INFO     Epoch: 65, Batch: 80, Loss: 0.0618\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 66\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 66, Batch: 20, Loss: 0.0624\n",
            "root        : INFO     Epoch: 66, Batch: 40, Loss: 0.0506\n",
            "root        : INFO     Epoch: 66, Batch: 60, Loss: 0.0416\n",
            "root        : INFO     Epoch: 66, Batch: 80, Loss: 0.0498\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 67\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 67, Batch: 20, Loss: 0.0584\n",
            "root        : INFO     Epoch: 67, Batch: 40, Loss: 0.0527\n",
            "root        : INFO     Epoch: 67, Batch: 80, Loss: 0.0412\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 68\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 68, Batch: 20, Loss: 0.0278\n",
            "root        : INFO     Epoch: 68, Batch: 40, Loss: 0.0415\n",
            "root        : INFO     Epoch: 68, Batch: 60, Loss: 0.0417\n",
            "root        : INFO     Epoch: 68, Batch: 80, Loss: 0.0511\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 69\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 69, Batch: 20, Loss: 0.0457\n",
            "root        : INFO     Epoch: 69, Batch: 40, Loss: 0.0308\n",
            "root        : INFO     Epoch: 69, Batch: 60, Loss: 0.0267\n",
            "root        : INFO     Epoch: 69, Batch: 80, Loss: 0.0488\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 70\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 70, Batch: 20, Loss: 0.0463\n",
            "root        : INFO     Epoch: 70, Batch: 40, Loss: 0.0291\n",
            "root        : INFO     Epoch: 70, Batch: 60, Loss: 0.0368\n",
            "root        : INFO     Epoch: 70, Batch: 80, Loss: 0.0298\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     107/177 = 0.604520\n",
            "root        : INFO     Beginning Epoch 71\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 71, Batch: 20, Loss: 0.0245\n",
            "root        : INFO     Epoch: 71, Batch: 40, Loss: 0.0336\n",
            "root        : INFO     Epoch: 71, Batch: 60, Loss: 0.0393\n",
            "root        : INFO     Epoch: 71, Batch: 80, Loss: 0.0418\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     117/177 = 0.661017\n",
            "root        : INFO     Beginning Epoch 72\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 72, Batch: 20, Loss: 0.0360\n",
            "root        : INFO     Epoch: 72, Batch: 40, Loss: 0.0619\n",
            "root        : INFO     Epoch: 72, Batch: 60, Loss: 0.0351\n",
            "root        : INFO     Epoch: 72, Batch: 80, Loss: 0.0335\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     119/177 = 0.672316\n",
            "root        : INFO     Beginning Epoch 73\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 73, Batch: 20, Loss: 0.0379\n",
            "root        : INFO     Epoch: 73, Batch: 40, Loss: 0.0404\n",
            "root        : INFO     Epoch: 73, Batch: 60, Loss: 0.0543\n",
            "root        : INFO     Epoch: 73, Batch: 80, Loss: 0.0309\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 74\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 74, Batch: 20, Loss: 0.0385\n",
            "root        : INFO     Epoch: 74, Batch: 40, Loss: 0.0271\n",
            "root        : INFO     Epoch: 74, Batch: 60, Loss: 0.0449\n",
            "root        : INFO     Epoch: 74, Batch: 80, Loss: 0.0286\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     114/177 = 0.644068\n",
            "root        : INFO     Beginning Epoch 75\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 75, Batch: 20, Loss: 0.0448\n",
            "root        : INFO     Epoch: 75, Batch: 40, Loss: 0.0502\n",
            "root        : INFO     Epoch: 75, Batch: 60, Loss: 0.0335\n",
            "root        : INFO     Epoch: 75, Batch: 80, Loss: 0.0316\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 76\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 76, Batch: 20, Loss: 0.0325\n",
            "root        : INFO     Epoch: 76, Batch: 40, Loss: 0.0344\n",
            "root        : INFO     Epoch: 76, Batch: 60, Loss: 0.0379\n",
            "root        : INFO     Epoch: 76, Batch: 80, Loss: 0.0341\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     128/177 = 0.723164\n",
            "root        : INFO     Beginning Epoch 77\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 77, Batch: 20, Loss: 0.0276\n",
            "root        : INFO     Epoch: 77, Batch: 40, Loss: 0.0348\n",
            "root        : INFO     Epoch: 77, Batch: 60, Loss: 0.0527\n",
            "root        : INFO     Epoch: 77, Batch: 80, Loss: 0.0245\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     116/177 = 0.655367\n",
            "root        : INFO     Beginning Epoch 78\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 78, Batch: 20, Loss: 0.0281\n",
            "root        : INFO     Epoch: 78, Batch: 40, Loss: 0.0442\n",
            "root        : INFO     Epoch: 78, Batch: 60, Loss: 0.0439\n",
            "root        : INFO     Epoch: 78, Batch: 80, Loss: 0.0217\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 79\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 79, Batch: 20, Loss: 0.0284\n",
            "root        : INFO     Epoch: 79, Batch: 40, Loss: 0.0268\n",
            "root        : INFO     Epoch: 79, Batch: 60, Loss: 0.0331\n",
            "root        : INFO     Epoch: 79, Batch: 80, Loss: 0.0328\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     123/177 = 0.694915\n",
            "root        : INFO     Beginning Epoch 80\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 80, Batch: 20, Loss: 0.0264\n",
            "root        : INFO     Epoch: 80, Batch: 40, Loss: 0.0617\n",
            "root        : INFO     Epoch: 80, Batch: 60, Loss: 0.0251\n",
            "root        : INFO     Epoch: 80, Batch: 80, Loss: 0.0424\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     105/177 = 0.593220\n",
            "root        : INFO     Beginning Epoch 81\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 81, Batch: 20, Loss: 0.0230\n",
            "root        : INFO     Epoch: 81, Batch: 40, Loss: 0.0287\n",
            "root        : INFO     Epoch: 81, Batch: 60, Loss: 0.0274\n",
            "root        : INFO     Epoch: 81, Batch: 80, Loss: 0.0512\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     115/177 = 0.649718\n",
            "root        : INFO     Beginning Epoch 82\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 82, Batch: 20, Loss: 0.0209\n",
            "root        : INFO     Epoch: 82, Batch: 40, Loss: 0.0345\n",
            "root        : INFO     Epoch: 82, Batch: 60, Loss: 0.0224\n",
            "root        : INFO     Epoch: 82, Batch: 80, Loss: 0.0495\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     110/177 = 0.621469\n",
            "root        : INFO     Beginning Epoch 83\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 83, Batch: 20, Loss: 0.0343\n",
            "root        : INFO     Epoch: 83, Batch: 40, Loss: 0.0357\n",
            "root        : INFO     Epoch: 83, Batch: 60, Loss: 0.0223\n",
            "root        : INFO     Epoch: 83, Batch: 80, Loss: 0.0324\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 84\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 84, Batch: 20, Loss: 0.0304\n",
            "root        : INFO     Epoch: 84, Batch: 40, Loss: 0.0311\n",
            "root        : INFO     Epoch: 84, Batch: 60, Loss: 0.0384\n",
            "root        : INFO     Epoch: 84, Batch: 80, Loss: 0.0210\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     130/177 = 0.734463\n",
            "root        : INFO     Beginning Epoch 85\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 85, Batch: 20, Loss: 0.0312\n",
            "root        : INFO     Epoch: 85, Batch: 40, Loss: 0.0351\n",
            "root        : INFO     Epoch: 85, Batch: 60, Loss: 0.0236\n",
            "root        : INFO     Epoch: 85, Batch: 80, Loss: 0.0426\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     121/177 = 0.683616\n",
            "root        : INFO     Beginning Epoch 86\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 86, Batch: 20, Loss: 0.0562\n",
            "root        : INFO     Epoch: 86, Batch: 40, Loss: 0.0264\n",
            "root        : INFO     Epoch: 86, Batch: 60, Loss: 0.0275\n",
            "root        : INFO     Epoch: 86, Batch: 80, Loss: 0.0288\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     121/177 = 0.683616\n",
            "root        : INFO     Beginning Epoch 87\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 87, Batch: 20, Loss: 0.0389\n",
            "root        : INFO     Epoch: 87, Batch: 40, Loss: 0.0281\n",
            "root        : INFO     Epoch: 87, Batch: 60, Loss: 0.0309\n",
            "root        : INFO     Epoch: 87, Batch: 80, Loss: 0.0283\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     127/177 = 0.717514\n",
            "root        : INFO     Beginning Epoch 88\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 88, Batch: 20, Loss: 0.0228\n",
            "root        : INFO     Epoch: 88, Batch: 40, Loss: 0.0262\n",
            "root        : INFO     Epoch: 88, Batch: 60, Loss: 0.0158\n",
            "root        : INFO     Epoch: 88, Batch: 80, Loss: 0.0443\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n",
            "root        : INFO     Beginning Epoch 89\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 89, Batch: 20, Loss: 0.0202\n",
            "root        : INFO     Epoch: 89, Batch: 40, Loss: 0.0134\n",
            "root        : INFO     Epoch: 89, Batch: 60, Loss: 0.0371\n",
            "root        : INFO     Epoch: 89, Batch: 80, Loss: 0.0520\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 90\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 90, Batch: 20, Loss: 0.0465\n",
            "root        : INFO     Epoch: 90, Batch: 40, Loss: 0.0346\n",
            "root        : INFO     Epoch: 90, Batch: 60, Loss: 0.0260\n",
            "root        : INFO     Epoch: 90, Batch: 80, Loss: 0.0320\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     102/177 = 0.576271\n",
            "root        : INFO     Beginning Epoch 91\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 91, Batch: 20, Loss: 0.0378\n",
            "root        : INFO     Epoch: 91, Batch: 40, Loss: 0.0405\n",
            "root        : INFO     Epoch: 91, Batch: 60, Loss: 0.0189\n",
            "root        : INFO     Epoch: 91, Batch: 80, Loss: 0.0259\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 92\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 92, Batch: 20, Loss: 0.0305\n",
            "root        : INFO     Epoch: 92, Batch: 40, Loss: 0.0330\n",
            "root        : INFO     Epoch: 92, Batch: 60, Loss: 0.0268\n",
            "root        : INFO     Epoch: 92, Batch: 80, Loss: 0.0212\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     96/177 = 0.542373\n",
            "root        : INFO     Beginning Epoch 93\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 93, Batch: 20, Loss: 0.0416\n",
            "root        : INFO     Epoch: 93, Batch: 40, Loss: 0.0318\n",
            "root        : INFO     Epoch: 93, Batch: 60, Loss: 0.0310\n",
            "root        : INFO     Epoch: 93, Batch: 80, Loss: 0.0212\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n",
            "root        : INFO     Beginning Epoch 94\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 94, Batch: 20, Loss: 0.0408\n",
            "root        : INFO     Epoch: 94, Batch: 40, Loss: 0.0363\n",
            "root        : INFO     Epoch: 94, Batch: 60, Loss: 0.0365\n",
            "root        : INFO     Epoch: 94, Batch: 80, Loss: 0.0400\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 95\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 95, Batch: 20, Loss: 0.0252\n",
            "root        : INFO     Epoch: 95, Batch: 40, Loss: 0.0399\n",
            "root        : INFO     Epoch: 95, Batch: 60, Loss: 0.0300\n",
            "root        : INFO     Epoch: 95, Batch: 80, Loss: 0.0340\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     126/177 = 0.711864\n",
            "root        : INFO     Beginning Epoch 96\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 96, Batch: 20, Loss: 0.0311\n",
            "root        : INFO     Epoch: 96, Batch: 40, Loss: 0.0353\n",
            "root        : INFO     Epoch: 96, Batch: 60, Loss: 0.0334\n",
            "root        : INFO     Epoch: 96, Batch: 80, Loss: 0.0326\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     101/177 = 0.570621\n",
            "root        : INFO     Beginning Epoch 97\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 97, Batch: 20, Loss: 0.0332\n",
            "root        : INFO     Epoch: 97, Batch: 40, Loss: 0.0237\n",
            "root        : INFO     Epoch: 97, Batch: 60, Loss: 0.0374\n",
            "root        : INFO     Epoch: 97, Batch: 80, Loss: 0.0345\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     113/177 = 0.638418\n",
            "root        : INFO     Beginning Epoch 98\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 98, Batch: 20, Loss: 0.0230\n",
            "root        : INFO     Epoch: 98, Batch: 40, Loss: 0.0332\n",
            "root        : INFO     Epoch: 98, Batch: 60, Loss: 0.0397\n",
            "root        : INFO     Epoch: 98, Batch: 80, Loss: 0.0200\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     108/177 = 0.610169\n",
            "root        : INFO     Beginning Epoch 99\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 99, Batch: 20, Loss: 0.0387\n",
            "root        : INFO     Epoch: 99, Batch: 40, Loss: 0.0264\n",
            "root        : INFO     Epoch: 99, Batch: 60, Loss: 0.0492\n",
            "root        : INFO     Epoch: 99, Batch: 80, Loss: 0.0301\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     101/177 = 0.570621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVlODiRogCct"
      },
      "source": [
        "**2. ds-rotate =0.2, Object-Wise, batchsize=16, learning rate =0.002, channel size 32**  \n",
        "**achived 0.864**\n",
        "\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210403_1609_training_cornell\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr_7biapdtNT",
        "outputId": "0dbb95e1-3f48-40bc-da86-bc4d91859c4d"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-shuffle --ds-rotate 0.2 --lr=0.002"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.20, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 16, bacthes per epoch = 448, optimizer = adam, learning rate = 0.002000\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1521\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1978\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1453\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1063\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.1271\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1174\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1353\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1295\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     38/177 = 0.214689\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0860\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1289\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0789\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1061\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.1078\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1309\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1099\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.1008\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     86/177 = 0.485876\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.1277\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0837\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0964\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0889\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1191\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0859\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0851\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0793\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0960\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1071\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.1131\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0829\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.1540\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0909\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0845\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.1282\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     104/177 = 0.587571\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.1173\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1046\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0904\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0712\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0705\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1091\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0902\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1217\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0920\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.1153\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.1133\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.1146\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.1022\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0779\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.1179\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.1246\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     107/177 = 0.604520\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0741\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.1357\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0949\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0678\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.1166\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.1184\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0959\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0632\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     126/177 = 0.711864\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.1267\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0894\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.1369\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0968\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0967\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0741\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0946\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0811\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.1402\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0755\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0994\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.1431\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0457\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0803\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0740\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0786\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.1131\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0816\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.1058\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0704\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.1132\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.1013\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0745\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0693\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0893\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0692\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0751\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.1343\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.1336\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0885\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0763\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0912\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     112/177 = 0.632768\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0795\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0753\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0909\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.1139\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0972\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.1069\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0685\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.1214\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     113/177 = 0.638418\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0951\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0722\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0975\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.1073\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0859\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0808\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0927\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0877\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0879\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0614\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.1023\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0980\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0777\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0847\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0807\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0685\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0720\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0804\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0881\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0990\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0757\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0695\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0657\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.1058\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0962\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0792\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0967\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0723\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0943\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0880\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0535\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0811\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.1209\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.1087\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0715\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0904\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.1357\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0660\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0789\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0888\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.1211\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0817\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.1076\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0686\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0718\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0622\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0763\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0739\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0560\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0958\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0820\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0509\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0578\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.1064\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0807\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0873\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0995\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0721\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.1029\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0778\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0840\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0786\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0882\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0759\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     117/177 = 0.661017\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0608\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0748\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0793\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.1126\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0860\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0864\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0662\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0493\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0975\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.1265\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0754\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0790\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0897\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0433\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.1059\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0982\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0904\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.1266\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.1068\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0650\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0835\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0652\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0756\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0729\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0931\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0645\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.1008\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0614\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0709\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0964\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.1064\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0953\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.1058\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0927\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.1157\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0887\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0575\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.1418\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0942\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0904\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0550\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0713\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0881\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.1029\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0610\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0825\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0716\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0833\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0813\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0852\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.1165\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0447\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0687\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0527\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0789\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0833\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0975\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0719\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.1054\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0919\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0916\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0697\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0965\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0655\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0818\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0678\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.0685\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0987\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0780\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0898\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.0748\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.1010\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0616\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0771\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0862\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0788\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.0683\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.1004\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.0689\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0780\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_WKQT_db879"
      },
      "source": [
        "**Suboptimal performance - Object-Wise**  \n",
        "[10:41:40] {train_network3.py:243} INFO - network = grconvnet3, use-depth = 1, use-rgb = 1  \n",
        "[10:41:40] {train_network3.py:244} INFO - dropout prob = 0.10, channel size = 32  \n",
        "[10:41:40] {train_network3.py:245} INFO - split = 0.80, ds-rotate = 0.20, number of workers = 8, random seed = 123.00  \n",
        "[10:41:40] {train_network3.py:246} INFO - epochs = 30, **batch size = 8**, bacthes per epoch = 896, optimizer = adam, **learning rate = 0.001000**  \n",
        "**I haved tried another training, which is set as above, but require a suboptimum result 0.876**  \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210403_1041_training_cornell  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBYRQMpJjUUC"
      },
      "source": [
        "**2. Tranfer Learning ds-rotate =0.2, Object-Wise, batchsize=8, SGD, learning rate =0.0002, channel size 32, train_network_ot.py**  \n",
        "**Achieved 0.887 in Training, **\n",
        "****  \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210413_0927_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6U7rsoGjUk_",
        "outputId": "df5f886d-894b-49a7-b349-57f1d725a12d"
      },
      "source": [
        "!python train_network_ot.py --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210403_1041_training_cornell/epoch_06_iou_0.88 --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-rotate 0.2 --optim SGD --lr=0.0002 --augment 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla T4, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1, augment=1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.20, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = SGD, learning rate = 0.000200\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210413_0927_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1070\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1089\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1073\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0652\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0885\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0615\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1112\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0867\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0552\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0754\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0868\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1153\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.0589\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0698\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.0759\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.0812\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0812\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.1081\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0607\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0821\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0775\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0643\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0714\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1259\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.1229\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.0489\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.1143\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.1224\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0943\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0444\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0629\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.0718\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0756\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.0782\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0864\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0589\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.1367\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0954\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0661\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0545\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0583\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.1080\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0814\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.1262\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.0935\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0988\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.0890\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0612\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.0725\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0926\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0814\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.1150\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0914\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0943\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.1085\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.1163\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0804\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0627\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0939\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0436\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.1262\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.0678\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0960\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0765\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0522\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0838\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.1212\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0735\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0694\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0702\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0910\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0919\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0768\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0761\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0566\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1281\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.0498\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0624\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0811\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0885\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.0912\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0612\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0566\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0409\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0817\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.1209\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0928\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0566\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0612\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0650\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0868\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.1183\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0528\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0920\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0580\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0640\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0887\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.0734\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0716\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0619\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0933\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0924\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0669\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.1281\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0814\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0461\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0735\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0719\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.1077\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0939\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0975\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0835\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.1235\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0687\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0661\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0785\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0676\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0715\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0636\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0978\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.1065\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.1220\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.1104\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0582\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0836\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0554\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.1053\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0565\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0856\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0921\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.1014\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0709\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0765\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.1048\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0875\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0840\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0813\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0594\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.1031\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0460\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.1295\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0789\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0784\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0984\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0457\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0573\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0523\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0917\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0709\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.1064\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0908\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0911\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0959\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0651\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0498\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0788\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0747\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0868\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0423\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0887\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.1472\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0666\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0806\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0615\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0615\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0500\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.1483\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0528\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0697\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0660\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0851\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0537\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0713\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0737\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0592\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.1212\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0938\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0644\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.1010\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.1006\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.1037\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0893\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0685\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.1076\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0812\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0813\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0957\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0822\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0751\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0769\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0593\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.1107\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0835\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.1102\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.1248\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0889\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0736\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0916\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0455\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0617\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0493\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0942\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0894\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0597\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0671\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0828\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0907\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0594\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0725\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.1088\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0844\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0781\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.1047\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0659\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0676\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0728\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0826\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0518\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0650\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0785\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0747\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0718\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0609\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0804\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0761\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0864\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.1012\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0612\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0638\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.1011\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0609\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.0406\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0951\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0781\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0554\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.1317\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.1030\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.1009\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0502\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.1089\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0827\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.1652\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.1372\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0764\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0919\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0547\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0731\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0649\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.0769\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.1012\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0993\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0426\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0732\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0672\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0752\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.1219\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0503\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0567\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0546\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0895\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0736\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0941\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0983\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.0784\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0666\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.0865\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0533\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.0696\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.1076\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.0889\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0456\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0641\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.1501\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.1089\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0471\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0597\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0792\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0783\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0852\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0739\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.1795\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0529\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.1014\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0939\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0575\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0945\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0893\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0746\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0502\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0704\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.1117\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.1155\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0923\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0504\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DueQntWkeSy8"
      },
      "source": [
        "**Transfer Learning from Jacquard to Cornell**  \n",
        "original network: /content/drive/MyDrive/jacquard_logs/210412_0327_training_jacquard/epoch_01_iou_0.67\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb037XfqeSWD",
        "outputId": "ae5bfc84-b360-45d9-aabd-562a24b9b1fa"
      },
      "source": [
        "!python train_network_ot.py --network pretrained_net --pretrained-net-path /content/drive/MyDrive/jacquard_logs/210412_0327_training_jacquard/epoch_01_iou_0.67 --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-rotate 0.2  --lr=0.001 --augment 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1, augment=1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.20, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_0345_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1424\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0816\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1008\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0950\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0777\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1009\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1392\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1549\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0756\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0885\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.1694\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.0948\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.1930\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.1101\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.1156\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.0926\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0949\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     93/177 = 0.525424\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0790\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1318\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.1033\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1029\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.1159\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1192\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1141\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0824\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.1427\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0869\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.0676\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.1387\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0859\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.1343\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.1111\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0852\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.0595\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.1202\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0998\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0616\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0625\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1059\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0968\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0618\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.1010\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.1233\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0689\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.1080\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0987\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.0744\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.1093\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.1115\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0613\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0437\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     121/177 = 0.683616\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.1089\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1084\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0844\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0867\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0880\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0661\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.1426\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0571\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0759\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0592\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.0912\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.1034\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0988\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.1189\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.1063\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0513\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0892\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0553\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1549\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0937\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0652\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0997\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1315\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.1148\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0593\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.0962\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0986\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.1049\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0624\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.1190\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0671\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0990\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0669\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.1505\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     120/177 = 0.677966\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0636\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.1187\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0849\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0607\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.1256\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0745\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0513\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.1021\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0794\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0537\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0987\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0570\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.1274\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0411\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0681\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0650\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0564\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0725\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0860\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0789\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0904\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0922\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0619\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.1199\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0326\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0654\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0376\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0642\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0790\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0706\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0593\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0766\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0472\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0361\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0953\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0511\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.1204\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0992\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0815\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0898\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0593\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0547\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0849\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0620\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0648\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.1503\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.1068\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0390\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0856\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0985\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0669\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     86/177 = 0.485876\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0348\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0603\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0672\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0694\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.1301\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0855\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0498\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.1030\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.1504\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0525\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0698\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.1096\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.1511\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0806\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0518\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0911\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0524\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0414\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0905\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.1002\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0589\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0641\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.1413\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.1295\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0870\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.1018\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0778\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0846\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.1264\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0837\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0466\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0917\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0832\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.1083\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0942\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0775\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0797\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0990\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0821\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0654\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.1141\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0854\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.1165\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0547\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0707\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0827\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0881\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0822\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0898\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0792\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.1269\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0547\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.1058\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0791\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0891\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0728\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0634\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0704\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0382\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0553\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0785\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0958\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0839\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0889\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0635\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0731\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0751\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0493\n",
            "Traceback (most recent call last):\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0731\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0999\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0919\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0844\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0792\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0649\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0596\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0991\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.0637\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0839\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0567\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0819\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0962\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0923\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0769\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0848\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0468\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0990\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0805\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0783\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0953\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0950\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0508\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0892\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0671\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.1250\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.1392\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.0669\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0844\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0632\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0671\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.1081\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0798\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.0775\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0377\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0639\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0974\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0822\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0902\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0908\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0815\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0841\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0747\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0678\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.0719\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0463\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0751\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.1263\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.1223\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0631\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0475\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0678\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0576\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0806\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0555\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0575\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0460\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0429\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0932\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.1186\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0643\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.0712\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0783\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.0825\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0834\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.1070\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.1030\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0435\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0820\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0460\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.1131\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0508\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.1238\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0948\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0798\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0755\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.0430\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0553\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.0845\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0842\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0931\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0960\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0909\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0560\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0667\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0732\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0716\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0473\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0755\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.1241\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0720\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.1358\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0851\n",
            "root        : INFO     Epoch: 17, Batch: 450, Loss: 0.1027\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0938\n",
            "root        : INFO     Epoch: 17, Batch: 550, Loss: 0.1013\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0832\n",
            "root        : INFO     Epoch: 17, Batch: 650, Loss: 0.0818\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0912\n",
            "root        : INFO     Epoch: 17, Batch: 750, Loss: 0.0594\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0857\n",
            "root        : INFO     Epoch: 17, Batch: 850, Loss: 0.1164\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0727\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0958\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0556\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0745\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0859\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0543\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0647\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0657\n",
            "root        : INFO     Epoch: 18, Batch: 450, Loss: 0.0705\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0680\n",
            "root        : INFO     Epoch: 18, Batch: 550, Loss: 0.0710\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0433\n",
            "root        : INFO     Epoch: 18, Batch: 650, Loss: 0.0781\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.1175\n",
            "root        : INFO     Epoch: 18, Batch: 750, Loss: 0.0713\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0604\n",
            "root        : INFO     Epoch: 18, Batch: 850, Loss: 0.0608\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.1430\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0753\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0710\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0907\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0575\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.1193\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0669\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0922\n",
            "root        : INFO     Epoch: 19, Batch: 450, Loss: 0.0528\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0569\n",
            "root        : INFO     Epoch: 19, Batch: 550, Loss: 0.1011\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.0860\n",
            "root        : INFO     Epoch: 19, Batch: 650, Loss: 0.0747\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0560\n",
            "root        : INFO     Epoch: 19, Batch: 750, Loss: 0.0802\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0848\n",
            "root        : INFO     Epoch: 19, Batch: 850, Loss: 0.0680\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0591\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0929\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0474\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.1093\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0397\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0920\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0511\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0895\n",
            "root        : INFO     Epoch: 20, Batch: 450, Loss: 0.0485\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.0953\n",
            "root        : INFO     Epoch: 20, Batch: 550, Loss: 0.0761\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0648\n",
            "root        : INFO     Epoch: 20, Batch: 650, Loss: 0.1304\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.1133\n",
            "root        : INFO     Epoch: 20, Batch: 750, Loss: 0.0943\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.0926\n",
            "root        : INFO     Epoch: 20, Batch: 850, Loss: 0.0668\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0540\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.1474\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0556\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0866\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0912\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0486\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.1139\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0521\n",
            "root        : INFO     Epoch: 21, Batch: 450, Loss: 0.1013\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.0621\n",
            "root        : INFO     Epoch: 21, Batch: 550, Loss: 0.0769\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.0591\n",
            "root        : INFO     Epoch: 21, Batch: 650, Loss: 0.0800\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.0621\n",
            "root        : INFO     Epoch: 21, Batch: 750, Loss: 0.0543\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0746\n",
            "root        : INFO     Epoch: 21, Batch: 850, Loss: 0.0622\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.1048\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0346\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0713\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0659\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0801\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0825\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0647\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.1054\n",
            "root        : INFO     Epoch: 22, Batch: 450, Loss: 0.1058\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0947\n",
            "root        : INFO     Epoch: 22, Batch: 550, Loss: 0.0486\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.0816\n",
            "root        : INFO     Epoch: 22, Batch: 650, Loss: 0.0538\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.1045\n",
            "root        : INFO     Epoch: 22, Batch: 750, Loss: 0.1081\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.0751\n",
            "root        : INFO     Epoch: 22, Batch: 850, Loss: 0.1119\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0764\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0794\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0705\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0786\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0884\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0579\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0983\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0453\n",
            "root        : INFO     Epoch: 23, Batch: 450, Loss: 0.0496\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0461\n",
            "root        : INFO     Epoch: 23, Batch: 550, Loss: 0.1355\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0804\n",
            "root        : INFO     Epoch: 23, Batch: 650, Loss: 0.0477\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.0743\n",
            "root        : INFO     Epoch: 23, Batch: 750, Loss: 0.0860\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.0610\n",
            "root        : INFO     Epoch: 23, Batch: 850, Loss: 0.0484\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0606\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0488\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0885\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.1193\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0493\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0507\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0866\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0996\n",
            "root        : INFO     Epoch: 24, Batch: 450, Loss: 0.0745\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.0810\n",
            "root        : INFO     Epoch: 24, Batch: 550, Loss: 0.0608\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.0543\n",
            "root        : INFO     Epoch: 24, Batch: 650, Loss: 0.0493\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.0567\n",
            "root        : INFO     Epoch: 24, Batch: 750, Loss: 0.0523\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.1345\n",
            "root        : INFO     Epoch: 24, Batch: 850, Loss: 0.0380\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0725\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0913\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0982\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0854\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0696\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.1008\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0496\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0492\n",
            "root        : INFO     Epoch: 25, Batch: 450, Loss: 0.0551\n",
            "root        : INFO     Epoch: 25, Batch: 500, Loss: 0.0738\n",
            "root        : INFO     Epoch: 25, Batch: 550, Loss: 0.0706\n",
            "root        : INFO     Epoch: 25, Batch: 600, Loss: 0.0456\n",
            "root        : INFO     Epoch: 25, Batch: 650, Loss: 0.1019\n",
            "root        : INFO     Epoch: 25, Batch: 700, Loss: 0.0425\n",
            "root        : INFO     Epoch: 25, Batch: 750, Loss: 0.0869\n",
            "root        : INFO     Epoch: 25, Batch: 800, Loss: 0.0552\n",
            "root        : INFO     Epoch: 25, Batch: 850, Loss: 0.0837\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0562\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0693\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.1020\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0476\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0838\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0479\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0894\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0870\n",
            "root        : INFO     Epoch: 26, Batch: 450, Loss: 0.0638\n",
            "root        : INFO     Epoch: 26, Batch: 500, Loss: 0.0739\n",
            "root        : INFO     Epoch: 26, Batch: 550, Loss: 0.0528\n",
            "root        : INFO     Epoch: 26, Batch: 600, Loss: 0.1192\n",
            "root        : INFO     Epoch: 26, Batch: 650, Loss: 0.0500\n",
            "root        : INFO     Epoch: 26, Batch: 700, Loss: 0.0250\n",
            "root        : INFO     Epoch: 26, Batch: 750, Loss: 0.0934\n",
            "root        : INFO     Epoch: 26, Batch: 800, Loss: 0.0657\n",
            "root        : INFO     Epoch: 26, Batch: 850, Loss: 0.0797\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0703\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0867\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0604\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.1044\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.1389\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0646\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0625\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0601\n",
            "root        : INFO     Epoch: 27, Batch: 450, Loss: 0.0787\n",
            "root        : INFO     Epoch: 27, Batch: 500, Loss: 0.0757\n",
            "root        : INFO     Epoch: 27, Batch: 550, Loss: 0.0742\n",
            "root        : INFO     Epoch: 27, Batch: 600, Loss: 0.0462\n",
            "root        : INFO     Epoch: 27, Batch: 650, Loss: 0.0830\n",
            "root        : INFO     Epoch: 27, Batch: 700, Loss: 0.0543\n",
            "root        : INFO     Epoch: 27, Batch: 750, Loss: 0.1094\n",
            "root        : INFO     Epoch: 27, Batch: 800, Loss: 0.1082\n",
            "root        : INFO     Epoch: 27, Batch: 850, Loss: 0.0688\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0679\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0669\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.0692\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0996\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0732\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0693\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.0822\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0696\n",
            "root        : INFO     Epoch: 28, Batch: 450, Loss: 0.0657\n",
            "root        : INFO     Epoch: 28, Batch: 500, Loss: 0.0493\n",
            "root        : INFO     Epoch: 28, Batch: 550, Loss: 0.0537\n",
            "root        : INFO     Epoch: 28, Batch: 600, Loss: 0.0581\n",
            "root        : INFO     Epoch: 28, Batch: 650, Loss: 0.0809\n",
            "root        : INFO     Epoch: 28, Batch: 700, Loss: 0.0942\n",
            "root        : INFO     Epoch: 28, Batch: 750, Loss: 0.0623\n",
            "root        : INFO     Epoch: 28, Batch: 800, Loss: 0.0511\n",
            "root        : INFO     Epoch: 28, Batch: 850, Loss: 0.0423\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0856\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.1286\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0804\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0842\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.1017\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0490\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.0869\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0708\n",
            "root        : INFO     Epoch: 29, Batch: 450, Loss: 0.0772\n",
            "root        : INFO     Epoch: 29, Batch: 500, Loss: 0.1020\n",
            "root        : INFO     Epoch: 29, Batch: 550, Loss: 0.0948\n",
            "root        : INFO     Epoch: 29, Batch: 600, Loss: 0.0567\n",
            "root        : INFO     Epoch: 29, Batch: 650, Loss: 0.0731\n",
            "root        : INFO     Epoch: 29, Batch: 700, Loss: 0.0325\n",
            "root        : INFO     Epoch: 29, Batch: 750, Loss: 0.0493\n",
            "root        : INFO     Epoch: 29, Batch: 800, Loss: 0.0544\n",
            "root        : INFO     Epoch: 29, Batch: 850, Loss: 0.0476\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1138, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train_network_ot.py\", line 373, in <module>\n",
            "    run()\n",
            "  File \"train_network_ot.py\", line 345, in run\n",
            "    train_results = train(epoch, net, device, train_data, optimizer, args.batches_per_epoch, vis=args.vis)\n",
            "  File \"train_network_ot.py\", line 163, in train\n",
            "    for x, y, _, _, _ in train_data:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
            "    return data\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/profiler.py\", line 621, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w9wLw81X7Yb"
      },
      "source": [
        "**3. ds-rotate=0.4, Image-Wise, Using original code train_network.py to train the cornell dataset, , batch size=8, use rgbd, Adam 0.001, channel size =32**  \n",
        "**achieved 0.927**\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_0440_training_cornell  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtyIkD9yt2qJ"
      },
      "source": [
        "!python train_network.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8 --ds-shuffle --ds-rotate 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2s7ue3GcbOr"
      },
      "source": [
        "**3. ds-rotate =0.4, Object-Wise, batchsize=8, Adam, learning rate =0.001, channel size 32**  \n",
        "**Achieved 0.85**\n",
        "\n",
        "/content/drive/MyDrive/GR_ConvNet_Code/logs/210409_0226_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEisry_Gca-_",
        "outputId": "a839681d-fbeb-4843-9aeb-58fd06046c60"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.4 --lr=0.001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.40, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1472\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1414\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1033\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1703\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.1296\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1730\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1276\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1372\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.1245\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.1074\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.1032\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.0796\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.1190\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0808\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.1065\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1338\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0955\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     77/177 = 0.435028\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.1448\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0892\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0732\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1179\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.1249\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1117\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0889\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0915\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.1425\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0828\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.0812\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.1212\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0950\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0975\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.0785\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0877\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.0940\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     113/177 = 0.638418\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0870\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0960\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0756\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.1281\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0671\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0571\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.1548\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0740\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.1122\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.1014\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.1156\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.1271\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.1096\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.1092\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.0912\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0598\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0597\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0905\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0858\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0569\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0520\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.1455\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0830\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.1052\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.1033\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0867\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0642\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.1247\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0755\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0523\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0816\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0872\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.1028\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.1482\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0725\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1616\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0813\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0912\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.1147\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1128\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0583\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0641\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.1290\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0967\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0613\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0866\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.1030\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0678\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0549\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0418\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.1076\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0814\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0839\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0743\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0584\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.1154\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0644\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0886\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0729\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0904\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0842\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0502\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0521\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.0934\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.1250\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.1027\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.1049\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0685\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.1264\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0756\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0484\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0590\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.1005\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0407\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0759\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0933\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0654\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0764\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0418\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0797\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.1220\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.1123\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0541\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0826\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.1093\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.1165\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0781\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0716\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0622\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.1131\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.1153\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0851\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0940\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.1075\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0851\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0856\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0622\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0566\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.1041\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0646\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.1344\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.1113\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.1155\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0778\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0556\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0597\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0417\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0902\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0902\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.1158\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0915\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0987\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.1163\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0541\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0788\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0937\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.1097\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.1325\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0996\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0554\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0727\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0742\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1096\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0907\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0901\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0679\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0387\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.1009\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0934\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0608\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.1029\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0792\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0733\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0764\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0879\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0872\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0415\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0751\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.1050\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0891\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0816\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0922\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0620\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0929\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.0705\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0592\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0793\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0872\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0625\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0382\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0640\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0491\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0869\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     128/177 = 0.723164\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0664\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.1032\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0872\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0796\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0829\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0723\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.1190\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0911\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0756\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0590\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.1392\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0625\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0950\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0951\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0801\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0611\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0420\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.1670\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0686\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0591\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0786\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0904\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0942\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0634\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.1169\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.0659\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.1266\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.1100\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0774\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0855\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0736\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.1475\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0552\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0881\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0629\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0748\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.1145\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0662\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0720\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.1332\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0429\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.1388\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.0837\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0605\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.0931\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0609\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0696\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0678\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.0695\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0633\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.0660\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0762\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0869\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0614\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0729\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0821\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0418\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0390\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0674\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0452\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0733\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.0896\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0575\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.1028\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0745\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0960\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0465\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0888\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0836\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0773\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0457\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0950\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0627\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0911\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0728\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.1183\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.0609\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.1349\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.0801\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.1565\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.0639\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0847\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.0537\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0437\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0551\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0419\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0779\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0582\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0662\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0836\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0371\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0800\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0787\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.0531\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0757\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.0346\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0859\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0729\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0590\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0583\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0946\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0815\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0603\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0682\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0663\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0767\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0512\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0380\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0981\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0495\n",
            "root        : INFO     Epoch: 17, Batch: 450, Loss: 0.1144\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0367\n",
            "root        : INFO     Epoch: 17, Batch: 550, Loss: 0.0452\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0474\n",
            "root        : INFO     Epoch: 17, Batch: 650, Loss: 0.0882\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0660\n",
            "root        : INFO     Epoch: 17, Batch: 750, Loss: 0.0669\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0919\n",
            "root        : INFO     Epoch: 17, Batch: 850, Loss: 0.0703\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0715\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.1176\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0967\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0603\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0515\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0889\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.1139\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0600\n",
            "root        : INFO     Epoch: 18, Batch: 450, Loss: 0.0981\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0540\n",
            "root        : INFO     Epoch: 18, Batch: 550, Loss: 0.0586\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0469\n",
            "root        : INFO     Epoch: 18, Batch: 650, Loss: 0.0575\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.1172\n",
            "root        : INFO     Epoch: 18, Batch: 750, Loss: 0.0783\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0535\n",
            "root        : INFO     Epoch: 18, Batch: 850, Loss: 0.0780\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0710\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0547\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0733\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.1280\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0460\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0873\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0613\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.1073\n",
            "root        : INFO     Epoch: 19, Batch: 450, Loss: 0.1033\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0904\n",
            "root        : INFO     Epoch: 19, Batch: 550, Loss: 0.0668\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.0776\n",
            "root        : INFO     Epoch: 19, Batch: 650, Loss: 0.0758\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.1030\n",
            "root        : INFO     Epoch: 19, Batch: 750, Loss: 0.0792\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0961\n",
            "root        : INFO     Epoch: 19, Batch: 850, Loss: 0.0956\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0950\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0802\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0646\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.1205\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0753\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0521\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0710\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0932\n",
            "root        : INFO     Epoch: 20, Batch: 450, Loss: 0.0814\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.0795\n",
            "root        : INFO     Epoch: 20, Batch: 550, Loss: 0.0408\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0811\n",
            "root        : INFO     Epoch: 20, Batch: 650, Loss: 0.0804\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.0968\n",
            "root        : INFO     Epoch: 20, Batch: 750, Loss: 0.0508\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.0866\n",
            "root        : INFO     Epoch: 20, Batch: 850, Loss: 0.0852\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0785\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.1456\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0623\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.1118\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0650\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0740\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0780\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0687\n",
            "root        : INFO     Epoch: 21, Batch: 450, Loss: 0.0456\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.0808\n",
            "root        : INFO     Epoch: 21, Batch: 550, Loss: 0.1122\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.1031\n",
            "root        : INFO     Epoch: 21, Batch: 650, Loss: 0.1118\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.0474\n",
            "root        : INFO     Epoch: 21, Batch: 750, Loss: 0.0612\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0644\n",
            "root        : INFO     Epoch: 21, Batch: 850, Loss: 0.0621\n",
            "Traceback (most recent call last):\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.1052\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0661\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0631\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0574\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0697\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0549\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0706\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.1003\n",
            "root        : INFO     Epoch: 22, Batch: 450, Loss: 0.0863\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0822\n",
            "root        : INFO     Epoch: 22, Batch: 550, Loss: 0.0640\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.0980\n",
            "root        : INFO     Epoch: 22, Batch: 650, Loss: 0.0494\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.0763\n",
            "root        : INFO     Epoch: 22, Batch: 750, Loss: 0.0818\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.0442\n",
            "root        : INFO     Epoch: 22, Batch: 850, Loss: 0.0787\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0736\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0799\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0742\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0818\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0829\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0636\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0386\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.1061\n",
            "root        : INFO     Epoch: 23, Batch: 450, Loss: 0.0950\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0737\n",
            "root        : INFO     Epoch: 23, Batch: 550, Loss: 0.0958\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0814\n",
            "root        : INFO     Epoch: 23, Batch: 650, Loss: 0.0544\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.0610\n",
            "root        : INFO     Epoch: 23, Batch: 750, Loss: 0.1271\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.0514\n",
            "root        : INFO     Epoch: 23, Batch: 850, Loss: 0.0933\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0629\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0514\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.1113\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0873\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0873\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0797\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0589\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0546\n",
            "root        : INFO     Epoch: 24, Batch: 450, Loss: 0.0873\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.1174\n",
            "root        : INFO     Epoch: 24, Batch: 550, Loss: 0.0403\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.0965\n",
            "root        : INFO     Epoch: 24, Batch: 650, Loss: 0.1284\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.0606\n",
            "root        : INFO     Epoch: 24, Batch: 750, Loss: 0.0914\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.0969\n",
            "root        : INFO     Epoch: 24, Batch: 850, Loss: 0.0493\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0940\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.1159\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0977\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0722\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0639\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0521\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.1195\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0336\n",
            "root        : INFO     Epoch: 25, Batch: 450, Loss: 0.0856\n",
            "root        : INFO     Epoch: 25, Batch: 500, Loss: 0.1033\n",
            "root        : INFO     Epoch: 25, Batch: 550, Loss: 0.0662\n",
            "root        : INFO     Epoch: 25, Batch: 600, Loss: 0.0871\n",
            "root        : INFO     Epoch: 25, Batch: 650, Loss: 0.1015\n",
            "root        : INFO     Epoch: 25, Batch: 700, Loss: 0.0979\n",
            "root        : INFO     Epoch: 25, Batch: 750, Loss: 0.0992\n",
            "root        : INFO     Epoch: 25, Batch: 800, Loss: 0.0556\n",
            "root        : INFO     Epoch: 25, Batch: 850, Loss: 0.0799\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.1182\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0995\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.1255\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0360\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0896\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0692\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0490\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0575\n",
            "root        : INFO     Epoch: 26, Batch: 450, Loss: 0.0738\n",
            "root        : INFO     Epoch: 26, Batch: 500, Loss: 0.0490\n",
            "root        : INFO     Epoch: 26, Batch: 550, Loss: 0.1250\n",
            "root        : INFO     Epoch: 26, Batch: 600, Loss: 0.0579\n",
            "root        : INFO     Epoch: 26, Batch: 650, Loss: 0.0525\n",
            "root        : INFO     Epoch: 26, Batch: 700, Loss: 0.0440\n",
            "root        : INFO     Epoch: 26, Batch: 750, Loss: 0.0395\n",
            "root        : INFO     Epoch: 26, Batch: 800, Loss: 0.0592\n",
            "root        : INFO     Epoch: 26, Batch: 850, Loss: 0.0399\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.1201\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0680\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0757\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0721\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0618\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0654\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0492\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0687\n",
            "root        : INFO     Epoch: 27, Batch: 450, Loss: 0.0674\n",
            "root        : INFO     Epoch: 27, Batch: 500, Loss: 0.0976\n",
            "root        : INFO     Epoch: 27, Batch: 550, Loss: 0.1093\n",
            "root        : INFO     Epoch: 27, Batch: 600, Loss: 0.0887\n",
            "root        : INFO     Epoch: 27, Batch: 650, Loss: 0.0679\n",
            "root        : INFO     Epoch: 27, Batch: 700, Loss: 0.0745\n",
            "root        : INFO     Epoch: 27, Batch: 750, Loss: 0.0811\n",
            "root        : INFO     Epoch: 27, Batch: 800, Loss: 0.0649\n",
            "root        : INFO     Epoch: 27, Batch: 850, Loss: 0.1251\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0903\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0343\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.0866\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0850\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0952\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0827\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.0644\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0377\n",
            "root        : INFO     Epoch: 28, Batch: 450, Loss: 0.0671\n",
            "root        : INFO     Epoch: 28, Batch: 500, Loss: 0.0514\n",
            "root        : INFO     Epoch: 28, Batch: 550, Loss: 0.0543\n",
            "root        : INFO     Epoch: 28, Batch: 600, Loss: 0.0450\n",
            "root        : INFO     Epoch: 28, Batch: 650, Loss: 0.0666\n",
            "root        : INFO     Epoch: 28, Batch: 700, Loss: 0.0924\n",
            "root        : INFO     Epoch: 28, Batch: 750, Loss: 0.0960\n",
            "root        : INFO     Epoch: 28, Batch: 800, Loss: 0.0744\n",
            "root        : INFO     Epoch: 28, Batch: 850, Loss: 0.0549\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0713\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0496\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0653\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0384\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.0953\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0990\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.0481\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0716\n",
            "root        : INFO     Epoch: 29, Batch: 450, Loss: 0.0351\n",
            "root        : INFO     Epoch: 29, Batch: 500, Loss: 0.0719\n",
            "root        : INFO     Epoch: 29, Batch: 550, Loss: 0.0982\n",
            "root        : INFO     Epoch: 29, Batch: 600, Loss: 0.0666\n",
            "root        : INFO     Epoch: 29, Batch: 650, Loss: 0.0806\n",
            "root        : INFO     Epoch: 29, Batch: 700, Loss: 0.0519\n",
            "root        : INFO     Epoch: 29, Batch: 750, Loss: 0.0560\n",
            "root        : INFO     Epoch: 29, Batch: 800, Loss: 0.0887\n",
            "root        : INFO     Epoch: 29, Batch: 850, Loss: 0.0798\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOlPaRCVTgFG"
      },
      "source": [
        "**Transfer Learning**  \n",
        "train_network_t.py is applied for transfer learning    \n",
        "**3. ds-rotate =0.4, Object-Wise, batchsize=8, learning rate =0.001, channel size 32**   \n",
        "**Achieved 0.876**  \n",
        "Results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210404_1451_training_cornell  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9U-P4KFsAMo",
        "outputId": "7eb44357-e69c-4251-b1c9-db3dcf349ab0"
      },
      "source": [
        "!python train_network_t.py --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210321_0850_training_cornell/epoch_13_iou_0.97  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.4 --lr=0.001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.40, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0674\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1079\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1327\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0387\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0699\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0920\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1106\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0897\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0440\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0629\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0800\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.0778\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.0762\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0947\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.1000\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.0907\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0995\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0633\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0732\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0749\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0937\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0394\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0840\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0615\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0777\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.0569\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0917\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.1051\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0515\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0453\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0455\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.0937\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0377\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.1169\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     107/177 = 0.604520\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.1274\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1337\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0594\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0689\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0730\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0373\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.1141\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0960\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.1288\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.1108\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.0587\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0807\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.0526\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0752\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.0955\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0801\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.1179\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0582\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0853\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.1084\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0595\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0908\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.1190\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.1040\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0556\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0467\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0673\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.0950\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0611\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0686\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0600\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0725\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0658\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0929\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0671\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1358\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0828\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.1245\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0438\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0608\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0606\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1030\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.1171\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0479\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0668\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0725\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.0499\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0982\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0736\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0674\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0714\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0630\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0883\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0584\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0663\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0738\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0879\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0904\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0933\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0640\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0855\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.1075\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0614\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.1452\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0655\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0781\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.1075\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0402\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0684\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0819\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0638\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0715\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0970\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0790\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0966\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0626\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0695\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.1217\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0790\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.1016\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.1144\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0661\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0899\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0547\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0906\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0674\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0631\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0959\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0974\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0680\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0408\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0802\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0571\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0314\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0543\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0762\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0658\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0799\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0995\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.1106\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0616\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0452\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0922\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0949\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0401\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0693\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0692\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0805\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0609\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0513\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0918\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.1396\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0537\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.1173\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0564\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0656\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0599\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.1316\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0379\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0441\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0651\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0816\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0842\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0704\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0659\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0522\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0848\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0454\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0849\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0584\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0431\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0587\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0695\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0946\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.1119\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0584\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0706\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0611\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0590\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0656\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0529\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0744\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0901\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0532\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.0931\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0673\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0630\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0988\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.1132\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0579\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.1087\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.1038\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0827\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     117/177 = 0.661017\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0938\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0459\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0799\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0461\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0625\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0334\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0551\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0533\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0843\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0487\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0764\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.1038\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0921\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0575\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.1000\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0722\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0575\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0726\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0698\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0437\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0617\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0797\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0679\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0966\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0627\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.0754\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0486\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0679\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0857\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0584\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0675\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0559\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0670\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0714\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0622\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.1443\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0475\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0705\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0483\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0345\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.1339\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0556\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.0618\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0677\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.0617\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0524\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0430\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.1012\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.0375\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0850\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.0445\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0760\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0328\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0543\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0668\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0762\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0881\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0662\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0490\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0617\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.1250\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.0933\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0609\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0792\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.1020\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0970\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0665\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.1422\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0526\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0958\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0585\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0635\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0525\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0557\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0473\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.1316\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.0877\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.1062\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.0803\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0341\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.0482\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0544\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.0843\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0938\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0883\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0397\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0861\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0712\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0637\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0987\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0519\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0553\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0849\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.0578\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0456\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.0577\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0908\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0585\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0755\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0512\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0997\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0535\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0746\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0548\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0905\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0452\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0773\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0558\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0555\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0932\n",
            "root        : INFO     Epoch: 17, Batch: 450, Loss: 0.0357\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0543\n",
            "root        : INFO     Epoch: 17, Batch: 550, Loss: 0.0588\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0463\n",
            "root        : INFO     Epoch: 17, Batch: 650, Loss: 0.0586\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0929\n",
            "root        : INFO     Epoch: 17, Batch: 750, Loss: 0.0507\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.1043\n",
            "root        : INFO     Epoch: 17, Batch: 850, Loss: 0.0421\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0793\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0880\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0697\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0435\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0782\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0679\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0874\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0930\n",
            "root        : INFO     Epoch: 18, Batch: 450, Loss: 0.0710\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0511\n",
            "root        : INFO     Epoch: 18, Batch: 550, Loss: 0.0677\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0467\n",
            "root        : INFO     Epoch: 18, Batch: 650, Loss: 0.0519\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.0523\n",
            "root        : INFO     Epoch: 18, Batch: 750, Loss: 0.0547\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0878\n",
            "root        : INFO     Epoch: 18, Batch: 850, Loss: 0.0853\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0784\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0553\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.1187\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0653\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0541\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0802\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0591\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.1046\n",
            "root        : INFO     Epoch: 19, Batch: 450, Loss: 0.0585\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0493\n",
            "root        : INFO     Epoch: 19, Batch: 550, Loss: 0.1041\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.0423\n",
            "root        : INFO     Epoch: 19, Batch: 650, Loss: 0.0793\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0464\n",
            "root        : INFO     Epoch: 19, Batch: 750, Loss: 0.1007\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0354\n",
            "root        : INFO     Epoch: 19, Batch: 850, Loss: 0.0451\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0668\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0743\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0731\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0598\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0931\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0890\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0882\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0906\n",
            "root        : INFO     Epoch: 20, Batch: 450, Loss: 0.0541\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.0585\n",
            "root        : INFO     Epoch: 20, Batch: 550, Loss: 0.0808\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0472\n",
            "root        : INFO     Epoch: 20, Batch: 650, Loss: 0.0712\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.0630\n",
            "root        : INFO     Epoch: 20, Batch: 750, Loss: 0.0644\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.0770\n",
            "root        : INFO     Epoch: 20, Batch: 850, Loss: 0.0758\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0791\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.1276\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0717\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0751\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0683\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0852\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0636\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0872\n",
            "root        : INFO     Epoch: 21, Batch: 450, Loss: 0.0567\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.0756\n",
            "root        : INFO     Epoch: 21, Batch: 550, Loss: 0.1316\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.0559\n",
            "root        : INFO     Epoch: 21, Batch: 650, Loss: 0.0731\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.0700\n",
            "root        : INFO     Epoch: 21, Batch: 750, Loss: 0.1211\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0695\n",
            "root        : INFO     Epoch: 21, Batch: 850, Loss: 0.0751\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0426\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0669\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0286\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0779\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0835\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0628\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0692\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0773\n",
            "root        : INFO     Epoch: 22, Batch: 450, Loss: 0.0498\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0339\n",
            "root        : INFO     Epoch: 22, Batch: 550, Loss: 0.0446\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.1161\n",
            "root        : INFO     Epoch: 22, Batch: 650, Loss: 0.0900\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.0481\n",
            "root        : INFO     Epoch: 22, Batch: 750, Loss: 0.0599\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.1109\n",
            "root        : INFO     Epoch: 22, Batch: 850, Loss: 0.1140\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0871\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0639\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0466\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0974\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0537\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0860\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0871\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0495\n",
            "root        : INFO     Epoch: 23, Batch: 450, Loss: 0.1140\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0344\n",
            "root        : INFO     Epoch: 23, Batch: 550, Loss: 0.0413\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0559\n",
            "root        : INFO     Epoch: 23, Batch: 650, Loss: 0.0505\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.1049\n",
            "root        : INFO     Epoch: 23, Batch: 750, Loss: 0.0564\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.0541\n",
            "root        : INFO     Epoch: 23, Batch: 850, Loss: 0.0685\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     119/177 = 0.672316\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0610\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0786\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0361\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0356\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0570\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0790\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0746\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0791\n",
            "root        : INFO     Epoch: 24, Batch: 450, Loss: 0.0587\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.0456\n",
            "root        : INFO     Epoch: 24, Batch: 550, Loss: 0.0933\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.0594\n",
            "root        : INFO     Epoch: 24, Batch: 650, Loss: 0.0796\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.1037\n",
            "root        : INFO     Epoch: 24, Batch: 750, Loss: 0.0623\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.0502\n",
            "root        : INFO     Epoch: 24, Batch: 850, Loss: 0.0787\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.1200\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0620\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0477\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0746\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0923\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0750\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0919\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0505\n",
            "root        : INFO     Epoch: 25, Batch: 450, Loss: 0.0662\n",
            "root        : INFO     Epoch: 25, Batch: 500, Loss: 0.0593\n",
            "root        : INFO     Epoch: 25, Batch: 550, Loss: 0.0595\n",
            "root        : INFO     Epoch: 25, Batch: 600, Loss: 0.0767\n",
            "root        : INFO     Epoch: 25, Batch: 650, Loss: 0.0726\n",
            "root        : INFO     Epoch: 25, Batch: 700, Loss: 0.0851\n",
            "root        : INFO     Epoch: 25, Batch: 750, Loss: 0.0888\n",
            "root        : INFO     Epoch: 25, Batch: 800, Loss: 0.0609\n",
            "root        : INFO     Epoch: 25, Batch: 850, Loss: 0.0741\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0681\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0842\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.0427\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0569\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0475\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0604\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0640\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0750\n",
            "root        : INFO     Epoch: 26, Batch: 450, Loss: 0.0594\n",
            "root        : INFO     Epoch: 26, Batch: 500, Loss: 0.0620\n",
            "root        : INFO     Epoch: 26, Batch: 550, Loss: 0.0722\n",
            "root        : INFO     Epoch: 26, Batch: 600, Loss: 0.0504\n",
            "root        : INFO     Epoch: 26, Batch: 650, Loss: 0.0883\n",
            "root        : INFO     Epoch: 26, Batch: 700, Loss: 0.0506\n",
            "root        : INFO     Epoch: 26, Batch: 750, Loss: 0.0909\n",
            "root        : INFO     Epoch: 26, Batch: 800, Loss: 0.0825\n",
            "root        : INFO     Epoch: 26, Batch: 850, Loss: 0.0661\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0516\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0413\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0714\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0672\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0799\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0858\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0510\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0399\n",
            "root        : INFO     Epoch: 27, Batch: 450, Loss: 0.0369\n",
            "root        : INFO     Epoch: 27, Batch: 500, Loss: 0.0649\n",
            "root        : INFO     Epoch: 27, Batch: 550, Loss: 0.0344\n",
            "root        : INFO     Epoch: 27, Batch: 600, Loss: 0.0906\n",
            "root        : INFO     Epoch: 27, Batch: 650, Loss: 0.0434\n",
            "root        : INFO     Epoch: 27, Batch: 700, Loss: 0.0890\n",
            "root        : INFO     Epoch: 27, Batch: 750, Loss: 0.0973\n",
            "root        : INFO     Epoch: 27, Batch: 800, Loss: 0.0539\n",
            "root        : INFO     Epoch: 27, Batch: 850, Loss: 0.0548\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     130/177 = 0.734463\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0671\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0542\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.0517\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0522\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0302\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0498\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.0337\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0626\n",
            "root        : INFO     Epoch: 28, Batch: 450, Loss: 0.0418\n",
            "root        : INFO     Epoch: 28, Batch: 500, Loss: 0.0784\n",
            "root        : INFO     Epoch: 28, Batch: 550, Loss: 0.0458\n",
            "root        : INFO     Epoch: 28, Batch: 600, Loss: 0.0379\n",
            "root        : INFO     Epoch: 28, Batch: 650, Loss: 0.0678\n",
            "root        : INFO     Epoch: 28, Batch: 700, Loss: 0.0891\n",
            "root        : INFO     Epoch: 28, Batch: 750, Loss: 0.0574\n",
            "root        : INFO     Epoch: 28, Batch: 800, Loss: 0.0656\n",
            "root        : INFO     Epoch: 28, Batch: 850, Loss: 0.0963\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0657\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0438\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0690\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0498\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.0489\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0780\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.0712\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0756\n",
            "root        : INFO     Epoch: 29, Batch: 450, Loss: 0.0732\n",
            "root        : INFO     Epoch: 29, Batch: 500, Loss: 0.0509\n",
            "root        : INFO     Epoch: 29, Batch: 550, Loss: 0.0547\n",
            "root        : INFO     Epoch: 29, Batch: 600, Loss: 0.0635\n",
            "root        : INFO     Epoch: 29, Batch: 650, Loss: 0.0798\n",
            "root        : INFO     Epoch: 29, Batch: 700, Loss: 0.0389\n",
            "root        : INFO     Epoch: 29, Batch: 750, Loss: 0.0508\n",
            "root        : INFO     Epoch: 29, Batch: 800, Loss: 0.0329\n",
            "root        : INFO     Epoch: 29, Batch: 850, Loss: 0.0571\n",
            "Traceback (most recent call last):\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     130/177 = 0.734463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRPmq9BLSLJ9"
      },
      "source": [
        "**3. ds-rotate =0.4, Object-Wise, batchsize=16, learning rate =0.002, channel size 16, epoch=100**  \n",
        "**0.87**\n",
        "/content/drive/MyDrive/GR_ConvNet_Code/logs/210407_0321_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv7IrodpRdu-",
        "outputId": "211c99c3-2b73-436c-a49e-1b9f00f7a716"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-shuffle --ds-rotate 0.4 --lr=0.002 --epochs 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 16\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.40, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 100, batch size = 16, bacthes per epoch = 448, optimizer = adam, learning rate = 0.002000\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]           5,200\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "            Conv2d-3         [-1, 32, 112, 112]           8,224\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            "            Conv2d-5           [-1, 64, 56, 56]          32,832\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "            Conv2d-7           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "           Conv2d-24           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "           Conv2d-29           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-31           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 32, 113, 113]          32,800\n",
            "      BatchNorm2d-33         [-1, 32, 113, 113]              64\n",
            "  ConvTranspose2d-34         [-1, 16, 225, 225]           8,208\n",
            "      BatchNorm2d-35         [-1, 16, 225, 225]              32\n",
            "  ConvTranspose2d-36         [-1, 16, 225, 225]          20,752\n",
            "          Dropout-37         [-1, 16, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]              65\n",
            "          Dropout-39         [-1, 16, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]              65\n",
            "          Dropout-41         [-1, 16, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]              65\n",
            "          Dropout-43         [-1, 16, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 479,156\n",
            "Trainable params: 479,156\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 110.74\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 113.34\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1506\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1141\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1195\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1404\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.1383\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1429\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1015\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1235\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     66/177 = 0.372881\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.1416\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1036\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0831\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1299\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0982\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1248\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1257\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0863\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     88/177 = 0.497175\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0989\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1636\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.1150\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0834\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1175\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0958\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0791\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0814\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     112/177 = 0.632768\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.1025\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0783\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.1037\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0990\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0806\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0862\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0905\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0644\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0926\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0522\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.1122\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0832\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0990\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0940\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.1044\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0832\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0675\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0992\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0911\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0735\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0692\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.1114\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0639\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0442\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0785\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0962\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0898\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0721\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0985\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0828\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0899\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0973\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0776\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0961\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0753\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0999\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0761\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0718\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0625\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0840\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0977\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.1034\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0895\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0847\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0904\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0790\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0770\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.1051\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0734\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0665\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0818\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0887\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0843\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0931\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0498\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0732\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0671\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0695\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0538\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0813\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0650\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0926\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0968\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0813\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0658\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0721\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0769\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0734\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.1056\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.1017\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.1255\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0856\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0821\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0706\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0797\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0649\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0681\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0914\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0676\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0707\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0650\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.1114\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0778\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0709\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0961\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0688\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0572\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.1003\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0495\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0646\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0483\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0687\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0858\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0734\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0794\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0884\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.1063\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0817\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0811\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0663\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0557\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0747\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0543\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0661\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0654\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0582\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0605\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0992\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0814\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.1276\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0752\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.1000\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0634\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0873\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0603\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0832\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0596\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0614\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0649\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0734\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0879\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.1110\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.1057\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0575\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0618\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0983\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0555\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0845\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0591\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0831\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.1132\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0811\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.1053\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0806\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.1071\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.1058\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0525\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0633\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0422\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0598\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0759\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0916\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0932\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0879\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.1011\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.1303\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0999\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0813\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0976\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.1044\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0948\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0846\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.1053\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0598\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0796\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0865\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0760\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.1227\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0602\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0847\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0672\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0949\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.1101\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0766\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0917\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.1390\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0591\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0662\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0957\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0643\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.1130\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0749\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0565\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0530\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0709\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0759\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0712\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.1032\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0801\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.1072\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0546\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0732\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.1245\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0653\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0425\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0766\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.0848\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0609\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.1268\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0856\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0774\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0722\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0604\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0834\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0823\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0633\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0800\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0748\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0709\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0624\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0571\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0623\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.0797\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0465\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0824\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0561\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.1226\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0952\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0647\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0783\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0641\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0529\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.0608\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0678\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.0694\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0956\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 50, Loss: 0.0455\n",
            "root        : INFO     Epoch: 30, Batch: 100, Loss: 0.0632\n",
            "root        : INFO     Epoch: 30, Batch: 150, Loss: 0.0573\n",
            "root        : INFO     Epoch: 30, Batch: 200, Loss: 0.0774\n",
            "root        : INFO     Epoch: 30, Batch: 250, Loss: 0.0768\n",
            "root        : INFO     Epoch: 30, Batch: 300, Loss: 0.1052\n",
            "root        : INFO     Epoch: 30, Batch: 350, Loss: 0.0675\n",
            "root        : INFO     Epoch: 30, Batch: 400, Loss: 0.0639\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 50, Loss: 0.0678\n",
            "root        : INFO     Epoch: 31, Batch: 100, Loss: 0.0912\n",
            "root        : INFO     Epoch: 31, Batch: 150, Loss: 0.0813\n",
            "root        : INFO     Epoch: 31, Batch: 200, Loss: 0.0553\n",
            "root        : INFO     Epoch: 31, Batch: 250, Loss: 0.0705\n",
            "root        : INFO     Epoch: 31, Batch: 300, Loss: 0.0974\n",
            "root        : INFO     Epoch: 31, Batch: 350, Loss: 0.0394\n",
            "root        : INFO     Epoch: 31, Batch: 400, Loss: 0.0498\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 50, Loss: 0.0645\n",
            "root        : INFO     Epoch: 32, Batch: 100, Loss: 0.0701\n",
            "root        : INFO     Epoch: 32, Batch: 150, Loss: 0.0589\n",
            "root        : INFO     Epoch: 32, Batch: 200, Loss: 0.0562\n",
            "root        : INFO     Epoch: 32, Batch: 250, Loss: 0.0842\n",
            "root        : INFO     Epoch: 32, Batch: 300, Loss: 0.1044\n",
            "root        : INFO     Epoch: 32, Batch: 350, Loss: 0.0553\n",
            "root        : INFO     Epoch: 32, Batch: 400, Loss: 0.0780\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 50, Loss: 0.0603\n",
            "root        : INFO     Epoch: 33, Batch: 100, Loss: 0.0793\n",
            "root        : INFO     Epoch: 33, Batch: 150, Loss: 0.0722\n",
            "root        : INFO     Epoch: 33, Batch: 200, Loss: 0.0639\n",
            "root        : INFO     Epoch: 33, Batch: 250, Loss: 0.0497\n",
            "root        : INFO     Epoch: 33, Batch: 300, Loss: 0.0551\n",
            "root        : INFO     Epoch: 33, Batch: 350, Loss: 0.0449\n",
            "root        : INFO     Epoch: 33, Batch: 400, Loss: 0.0896\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 50, Loss: 0.1091\n",
            "root        : INFO     Epoch: 34, Batch: 100, Loss: 0.0583\n",
            "root        : INFO     Epoch: 34, Batch: 150, Loss: 0.0644\n",
            "root        : INFO     Epoch: 34, Batch: 200, Loss: 0.0625\n",
            "root        : INFO     Epoch: 34, Batch: 250, Loss: 0.0658\n",
            "root        : INFO     Epoch: 34, Batch: 300, Loss: 0.0635\n",
            "root        : INFO     Epoch: 34, Batch: 350, Loss: 0.0315\n",
            "root        : INFO     Epoch: 34, Batch: 400, Loss: 0.0432\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 50, Loss: 0.0443\n",
            "root        : INFO     Epoch: 35, Batch: 100, Loss: 0.0618\n",
            "root        : INFO     Epoch: 35, Batch: 150, Loss: 0.0657\n",
            "root        : INFO     Epoch: 35, Batch: 200, Loss: 0.0846\n",
            "root        : INFO     Epoch: 35, Batch: 250, Loss: 0.0888\n",
            "root        : INFO     Epoch: 35, Batch: 300, Loss: 0.0534\n",
            "root        : INFO     Epoch: 35, Batch: 350, Loss: 0.0566\n",
            "root        : INFO     Epoch: 35, Batch: 400, Loss: 0.0442\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 50, Loss: 0.0665\n",
            "root        : INFO     Epoch: 36, Batch: 100, Loss: 0.0786\n",
            "root        : INFO     Epoch: 36, Batch: 150, Loss: 0.0870\n",
            "root        : INFO     Epoch: 36, Batch: 200, Loss: 0.0643\n",
            "root        : INFO     Epoch: 36, Batch: 250, Loss: 0.0706\n",
            "root        : INFO     Epoch: 36, Batch: 300, Loss: 0.0432\n",
            "root        : INFO     Epoch: 36, Batch: 350, Loss: 0.0774\n",
            "root        : INFO     Epoch: 36, Batch: 400, Loss: 0.0574\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 50, Loss: 0.0851\n",
            "root        : INFO     Epoch: 37, Batch: 100, Loss: 0.0660\n",
            "root        : INFO     Epoch: 37, Batch: 150, Loss: 0.0872\n",
            "root        : INFO     Epoch: 37, Batch: 200, Loss: 0.0815\n",
            "root        : INFO     Epoch: 37, Batch: 250, Loss: 0.0851\n",
            "root        : INFO     Epoch: 37, Batch: 300, Loss: 0.0797\n",
            "root        : INFO     Epoch: 37, Batch: 350, Loss: 0.0638\n",
            "root        : INFO     Epoch: 37, Batch: 400, Loss: 0.0472\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 50, Loss: 0.0786\n",
            "root        : INFO     Epoch: 38, Batch: 100, Loss: 0.0588\n",
            "root        : INFO     Epoch: 38, Batch: 150, Loss: 0.0776\n",
            "root        : INFO     Epoch: 38, Batch: 200, Loss: 0.0706\n",
            "root        : INFO     Epoch: 38, Batch: 250, Loss: 0.0906\n",
            "root        : INFO     Epoch: 38, Batch: 300, Loss: 0.0621\n",
            "root        : INFO     Epoch: 38, Batch: 350, Loss: 0.0604\n",
            "root        : INFO     Epoch: 38, Batch: 400, Loss: 0.0835\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 50, Loss: 0.0694\n",
            "root        : INFO     Epoch: 39, Batch: 100, Loss: 0.0981\n",
            "root        : INFO     Epoch: 39, Batch: 150, Loss: 0.0903\n",
            "root        : INFO     Epoch: 39, Batch: 200, Loss: 0.0761\n",
            "root        : INFO     Epoch: 39, Batch: 250, Loss: 0.0470\n",
            "root        : INFO     Epoch: 39, Batch: 300, Loss: 0.0540\n",
            "root        : INFO     Epoch: 39, Batch: 350, Loss: 0.0691\n",
            "root        : INFO     Epoch: 39, Batch: 400, Loss: 0.0682\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 50, Loss: 0.0846\n",
            "root        : INFO     Epoch: 40, Batch: 100, Loss: 0.0674\n",
            "root        : INFO     Epoch: 40, Batch: 150, Loss: 0.0761\n",
            "root        : INFO     Epoch: 40, Batch: 200, Loss: 0.0781\n",
            "root        : INFO     Epoch: 40, Batch: 250, Loss: 0.0784\n",
            "root        : INFO     Epoch: 40, Batch: 300, Loss: 0.0622\n",
            "root        : INFO     Epoch: 40, Batch: 350, Loss: 0.0589\n",
            "root        : INFO     Epoch: 40, Batch: 400, Loss: 0.0519\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 50, Loss: 0.0575\n",
            "root        : INFO     Epoch: 41, Batch: 100, Loss: 0.0647\n",
            "root        : INFO     Epoch: 41, Batch: 150, Loss: 0.0712\n",
            "root        : INFO     Epoch: 41, Batch: 200, Loss: 0.0560\n",
            "root        : INFO     Epoch: 41, Batch: 250, Loss: 0.0772\n",
            "root        : INFO     Epoch: 41, Batch: 300, Loss: 0.0997\n",
            "root        : INFO     Epoch: 41, Batch: 350, Loss: 0.0640\n",
            "root        : INFO     Epoch: 41, Batch: 400, Loss: 0.0759\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 50, Loss: 0.0758\n",
            "root        : INFO     Epoch: 42, Batch: 100, Loss: 0.0540\n",
            "root        : INFO     Epoch: 42, Batch: 150, Loss: 0.0649\n",
            "root        : INFO     Epoch: 42, Batch: 200, Loss: 0.0615\n",
            "root        : INFO     Epoch: 42, Batch: 250, Loss: 0.0813\n",
            "root        : INFO     Epoch: 42, Batch: 300, Loss: 0.0921\n",
            "root        : INFO     Epoch: 42, Batch: 350, Loss: 0.0645\n",
            "root        : INFO     Epoch: 42, Batch: 400, Loss: 0.0776\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 50, Loss: 0.0832\n",
            "root        : INFO     Epoch: 43, Batch: 100, Loss: 0.0573\n",
            "root        : INFO     Epoch: 43, Batch: 150, Loss: 0.0626\n",
            "root        : INFO     Epoch: 43, Batch: 200, Loss: 0.0802\n",
            "root        : INFO     Epoch: 43, Batch: 250, Loss: 0.0420\n",
            "root        : INFO     Epoch: 43, Batch: 300, Loss: 0.0653\n",
            "root        : INFO     Epoch: 43, Batch: 350, Loss: 0.0522\n",
            "root        : INFO     Epoch: 43, Batch: 400, Loss: 0.0548\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 50, Loss: 0.0680\n",
            "root        : INFO     Epoch: 44, Batch: 100, Loss: 0.0745\n",
            "root        : INFO     Epoch: 44, Batch: 150, Loss: 0.0827\n",
            "root        : INFO     Epoch: 44, Batch: 200, Loss: 0.0599\n",
            "root        : INFO     Epoch: 44, Batch: 250, Loss: 0.0688\n",
            "root        : INFO     Epoch: 44, Batch: 300, Loss: 0.0785\n",
            "root        : INFO     Epoch: 44, Batch: 350, Loss: 0.0912\n",
            "root        : INFO     Epoch: 44, Batch: 400, Loss: 0.0512\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 50, Loss: 0.0727\n",
            "root        : INFO     Epoch: 45, Batch: 100, Loss: 0.0726\n",
            "root        : INFO     Epoch: 45, Batch: 150, Loss: 0.0813\n",
            "root        : INFO     Epoch: 45, Batch: 200, Loss: 0.0618\n",
            "root        : INFO     Epoch: 45, Batch: 250, Loss: 0.0787\n",
            "root        : INFO     Epoch: 45, Batch: 300, Loss: 0.0547\n",
            "root        : INFO     Epoch: 45, Batch: 350, Loss: 0.0837\n",
            "root        : INFO     Epoch: 45, Batch: 400, Loss: 0.0880\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 50, Loss: 0.0887\n",
            "root        : INFO     Epoch: 46, Batch: 100, Loss: 0.0732\n",
            "root        : INFO     Epoch: 46, Batch: 150, Loss: 0.0626\n",
            "root        : INFO     Epoch: 46, Batch: 200, Loss: 0.0663\n",
            "root        : INFO     Epoch: 46, Batch: 250, Loss: 0.0414\n",
            "root        : INFO     Epoch: 46, Batch: 300, Loss: 0.0607\n",
            "root        : INFO     Epoch: 46, Batch: 350, Loss: 0.0685\n",
            "root        : INFO     Epoch: 46, Batch: 400, Loss: 0.0885\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 50, Loss: 0.0671\n",
            "root        : INFO     Epoch: 47, Batch: 100, Loss: 0.1076\n",
            "root        : INFO     Epoch: 47, Batch: 150, Loss: 0.0623\n",
            "root        : INFO     Epoch: 47, Batch: 200, Loss: 0.0661\n",
            "root        : INFO     Epoch: 47, Batch: 250, Loss: 0.0612\n",
            "root        : INFO     Epoch: 47, Batch: 300, Loss: 0.0512\n",
            "root        : INFO     Epoch: 47, Batch: 350, Loss: 0.0678\n",
            "root        : INFO     Epoch: 47, Batch: 400, Loss: 0.0899\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 50, Loss: 0.0591\n",
            "root        : INFO     Epoch: 48, Batch: 100, Loss: 0.0704\n",
            "root        : INFO     Epoch: 48, Batch: 150, Loss: 0.0922\n",
            "root        : INFO     Epoch: 48, Batch: 200, Loss: 0.0632\n",
            "root        : INFO     Epoch: 48, Batch: 250, Loss: 0.0513\n",
            "root        : INFO     Epoch: 48, Batch: 300, Loss: 0.0627\n",
            "root        : INFO     Epoch: 48, Batch: 350, Loss: 0.0453\n",
            "root        : INFO     Epoch: 48, Batch: 400, Loss: 0.0555\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 50, Loss: 0.0558\n",
            "root        : INFO     Epoch: 49, Batch: 100, Loss: 0.0624\n",
            "root        : INFO     Epoch: 49, Batch: 150, Loss: 0.0637\n",
            "root        : INFO     Epoch: 49, Batch: 200, Loss: 0.0587\n",
            "root        : INFO     Epoch: 49, Batch: 250, Loss: 0.0525\n",
            "root        : INFO     Epoch: 49, Batch: 300, Loss: 0.0396\n",
            "root        : INFO     Epoch: 49, Batch: 350, Loss: 0.0733\n",
            "root        : INFO     Epoch: 49, Batch: 400, Loss: 0.0875\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 50\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 50, Batch: 50, Loss: 0.0602\n",
            "root        : INFO     Epoch: 50, Batch: 100, Loss: 0.0969\n",
            "root        : INFO     Epoch: 50, Batch: 150, Loss: 0.0671\n",
            "root        : INFO     Epoch: 50, Batch: 200, Loss: 0.1008\n",
            "root        : INFO     Epoch: 50, Batch: 250, Loss: 0.0903\n",
            "root        : INFO     Epoch: 50, Batch: 300, Loss: 0.1019\n",
            "root        : INFO     Epoch: 50, Batch: 350, Loss: 0.0803\n",
            "root        : INFO     Epoch: 50, Batch: 400, Loss: 0.0613\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 51\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 51, Batch: 50, Loss: 0.0698\n",
            "root        : INFO     Epoch: 51, Batch: 100, Loss: 0.0763\n",
            "root        : INFO     Epoch: 51, Batch: 150, Loss: 0.0833\n",
            "root        : INFO     Epoch: 51, Batch: 200, Loss: 0.0530\n",
            "root        : INFO     Epoch: 51, Batch: 250, Loss: 0.0632\n",
            "root        : INFO     Epoch: 51, Batch: 300, Loss: 0.0662\n",
            "root        : INFO     Epoch: 51, Batch: 350, Loss: 0.0515\n",
            "root        : INFO     Epoch: 51, Batch: 400, Loss: 0.0636\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 52\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 52, Batch: 50, Loss: 0.0607\n",
            "root        : INFO     Epoch: 52, Batch: 100, Loss: 0.0403\n",
            "root        : INFO     Epoch: 52, Batch: 150, Loss: 0.0359\n",
            "root        : INFO     Epoch: 52, Batch: 200, Loss: 0.0610\n",
            "root        : INFO     Epoch: 52, Batch: 250, Loss: 0.0694\n",
            "root        : INFO     Epoch: 52, Batch: 300, Loss: 0.0499\n",
            "root        : INFO     Epoch: 52, Batch: 350, Loss: 0.0503\n",
            "root        : INFO     Epoch: 52, Batch: 400, Loss: 0.0726\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 53\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 53, Batch: 50, Loss: 0.0686\n",
            "root        : INFO     Epoch: 53, Batch: 100, Loss: 0.0890\n",
            "root        : INFO     Epoch: 53, Batch: 150, Loss: 0.0821\n",
            "root        : INFO     Epoch: 53, Batch: 200, Loss: 0.0895\n",
            "root        : INFO     Epoch: 53, Batch: 250, Loss: 0.0833\n",
            "root        : INFO     Epoch: 53, Batch: 300, Loss: 0.0569\n",
            "root        : INFO     Epoch: 53, Batch: 350, Loss: 0.0865\n",
            "root        : INFO     Epoch: 53, Batch: 400, Loss: 0.0951\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 54\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 54, Batch: 50, Loss: 0.0696\n",
            "root        : INFO     Epoch: 54, Batch: 100, Loss: 0.0670\n",
            "root        : INFO     Epoch: 54, Batch: 150, Loss: 0.0420\n",
            "root        : INFO     Epoch: 54, Batch: 200, Loss: 0.0560\n",
            "root        : INFO     Epoch: 54, Batch: 250, Loss: 0.0869\n",
            "root        : INFO     Epoch: 54, Batch: 300, Loss: 0.0576\n",
            "root        : INFO     Epoch: 54, Batch: 350, Loss: 0.0610\n",
            "root        : INFO     Epoch: 54, Batch: 400, Loss: 0.0775\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 55\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 55, Batch: 50, Loss: 0.0509\n",
            "root        : INFO     Epoch: 55, Batch: 100, Loss: 0.0652\n",
            "root        : INFO     Epoch: 55, Batch: 150, Loss: 0.0666\n",
            "root        : INFO     Epoch: 55, Batch: 200, Loss: 0.0444\n",
            "root        : INFO     Epoch: 55, Batch: 250, Loss: 0.0700\n",
            "root        : INFO     Epoch: 55, Batch: 300, Loss: 0.0726\n",
            "root        : INFO     Epoch: 55, Batch: 350, Loss: 0.0627\n",
            "root        : INFO     Epoch: 55, Batch: 400, Loss: 0.0712\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 56\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 56, Batch: 50, Loss: 0.0671\n",
            "root        : INFO     Epoch: 56, Batch: 100, Loss: 0.0617\n",
            "root        : INFO     Epoch: 56, Batch: 150, Loss: 0.0666\n",
            "root        : INFO     Epoch: 56, Batch: 200, Loss: 0.0696\n",
            "root        : INFO     Epoch: 56, Batch: 250, Loss: 0.0528\n",
            "root        : INFO     Epoch: 56, Batch: 300, Loss: 0.0636\n",
            "root        : INFO     Epoch: 56, Batch: 350, Loss: 0.0627\n",
            "root        : INFO     Epoch: 56, Batch: 400, Loss: 0.0676\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 57\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 57, Batch: 50, Loss: 0.0670\n",
            "root        : INFO     Epoch: 57, Batch: 100, Loss: 0.0605\n",
            "root        : INFO     Epoch: 57, Batch: 150, Loss: 0.0556\n",
            "root        : INFO     Epoch: 57, Batch: 200, Loss: 0.0992\n",
            "root        : INFO     Epoch: 57, Batch: 250, Loss: 0.0634\n",
            "root        : INFO     Epoch: 57, Batch: 300, Loss: 0.0773\n",
            "root        : INFO     Epoch: 57, Batch: 350, Loss: 0.0620\n",
            "root        : INFO     Epoch: 57, Batch: 400, Loss: 0.1027\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 58\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 58, Batch: 50, Loss: 0.0631\n",
            "root        : INFO     Epoch: 58, Batch: 100, Loss: 0.0487\n",
            "root        : INFO     Epoch: 58, Batch: 150, Loss: 0.0433\n",
            "root        : INFO     Epoch: 58, Batch: 200, Loss: 0.0630\n",
            "root        : INFO     Epoch: 58, Batch: 250, Loss: 0.0581\n",
            "root        : INFO     Epoch: 58, Batch: 300, Loss: 0.0585\n",
            "root        : INFO     Epoch: 58, Batch: 350, Loss: 0.0683\n",
            "root        : INFO     Epoch: 58, Batch: 400, Loss: 0.0861\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 59\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 59, Batch: 50, Loss: 0.0739\n",
            "root        : INFO     Epoch: 59, Batch: 100, Loss: 0.0788\n",
            "root        : INFO     Epoch: 59, Batch: 150, Loss: 0.0872\n",
            "root        : INFO     Epoch: 59, Batch: 200, Loss: 0.0796\n",
            "root        : INFO     Epoch: 59, Batch: 250, Loss: 0.0816\n",
            "root        : INFO     Epoch: 59, Batch: 300, Loss: 0.0713\n",
            "root        : INFO     Epoch: 59, Batch: 350, Loss: 0.0526\n",
            "root        : INFO     Epoch: 59, Batch: 400, Loss: 0.0808\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 60\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 60, Batch: 50, Loss: 0.0629\n",
            "root        : INFO     Epoch: 60, Batch: 100, Loss: 0.0591\n",
            "root        : INFO     Epoch: 60, Batch: 150, Loss: 0.0621\n",
            "root        : INFO     Epoch: 60, Batch: 200, Loss: 0.0584\n",
            "root        : INFO     Epoch: 60, Batch: 250, Loss: 0.0401\n",
            "root        : INFO     Epoch: 60, Batch: 300, Loss: 0.0765\n",
            "root        : INFO     Epoch: 60, Batch: 350, Loss: 0.0470\n",
            "root        : INFO     Epoch: 60, Batch: 400, Loss: 0.0659\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 61\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 61, Batch: 50, Loss: 0.0644\n",
            "root        : INFO     Epoch: 61, Batch: 100, Loss: 0.0381\n",
            "root        : INFO     Epoch: 61, Batch: 150, Loss: 0.0507\n",
            "root        : INFO     Epoch: 61, Batch: 200, Loss: 0.0593\n",
            "root        : INFO     Epoch: 61, Batch: 250, Loss: 0.0501\n",
            "root        : INFO     Epoch: 61, Batch: 300, Loss: 0.0536\n",
            "root        : INFO     Epoch: 61, Batch: 350, Loss: 0.0678\n",
            "root        : INFO     Epoch: 61, Batch: 400, Loss: 0.0469\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 62\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 62, Batch: 50, Loss: 0.0668\n",
            "root        : INFO     Epoch: 62, Batch: 100, Loss: 0.0634\n",
            "root        : INFO     Epoch: 62, Batch: 150, Loss: 0.0679\n",
            "root        : INFO     Epoch: 62, Batch: 200, Loss: 0.0576\n",
            "root        : INFO     Epoch: 62, Batch: 250, Loss: 0.0516\n",
            "root        : INFO     Epoch: 62, Batch: 300, Loss: 0.0555\n",
            "root        : INFO     Epoch: 62, Batch: 350, Loss: 0.0719\n",
            "root        : INFO     Epoch: 62, Batch: 400, Loss: 0.1209\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 63\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 63, Batch: 50, Loss: 0.0677\n",
            "root        : INFO     Epoch: 63, Batch: 100, Loss: 0.0539\n",
            "root        : INFO     Epoch: 63, Batch: 150, Loss: 0.0390\n",
            "root        : INFO     Epoch: 63, Batch: 200, Loss: 0.0507\n",
            "root        : INFO     Epoch: 63, Batch: 250, Loss: 0.0664\n",
            "root        : INFO     Epoch: 63, Batch: 300, Loss: 0.0657\n",
            "root        : INFO     Epoch: 63, Batch: 350, Loss: 0.0606\n",
            "root        : INFO     Epoch: 63, Batch: 400, Loss: 0.0334\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 64\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 64, Batch: 50, Loss: 0.0653\n",
            "root        : INFO     Epoch: 64, Batch: 100, Loss: 0.0713\n",
            "root        : INFO     Epoch: 64, Batch: 150, Loss: 0.0475\n",
            "root        : INFO     Epoch: 64, Batch: 200, Loss: 0.0392\n",
            "root        : INFO     Epoch: 64, Batch: 250, Loss: 0.0597\n",
            "root        : INFO     Epoch: 64, Batch: 300, Loss: 0.0706\n",
            "root        : INFO     Epoch: 64, Batch: 350, Loss: 0.0581\n",
            "root        : INFO     Epoch: 64, Batch: 400, Loss: 0.1008\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 65\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 65, Batch: 50, Loss: 0.0647\n",
            "root        : INFO     Epoch: 65, Batch: 100, Loss: 0.0516\n",
            "root        : INFO     Epoch: 65, Batch: 150, Loss: 0.0324\n",
            "root        : INFO     Epoch: 65, Batch: 200, Loss: 0.0634\n",
            "root        : INFO     Epoch: 65, Batch: 250, Loss: 0.0539\n",
            "root        : INFO     Epoch: 65, Batch: 300, Loss: 0.0447\n",
            "root        : INFO     Epoch: 65, Batch: 350, Loss: 0.0552\n",
            "root        : INFO     Epoch: 65, Batch: 400, Loss: 0.0802\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 66\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 66, Batch: 50, Loss: 0.0637\n",
            "root        : INFO     Epoch: 66, Batch: 100, Loss: 0.0562\n",
            "root        : INFO     Epoch: 66, Batch: 150, Loss: 0.0580\n",
            "root        : INFO     Epoch: 66, Batch: 200, Loss: 0.0687\n",
            "root        : INFO     Epoch: 66, Batch: 250, Loss: 0.0597\n",
            "root        : INFO     Epoch: 66, Batch: 300, Loss: 0.0504\n",
            "root        : INFO     Epoch: 66, Batch: 350, Loss: 0.0726\n",
            "root        : INFO     Epoch: 66, Batch: 400, Loss: 0.0367\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 67\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 67, Batch: 50, Loss: 0.0483\n",
            "root        : INFO     Epoch: 67, Batch: 100, Loss: 0.0693\n",
            "root        : INFO     Epoch: 67, Batch: 150, Loss: 0.0644\n",
            "root        : INFO     Epoch: 67, Batch: 200, Loss: 0.0713\n",
            "root        : INFO     Epoch: 67, Batch: 250, Loss: 0.0769\n",
            "root        : INFO     Epoch: 67, Batch: 300, Loss: 0.0778\n",
            "root        : INFO     Epoch: 67, Batch: 350, Loss: 0.0587\n",
            "root        : INFO     Epoch: 67, Batch: 400, Loss: 0.0858\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 68\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 68, Batch: 50, Loss: 0.0437\n",
            "root        : INFO     Epoch: 68, Batch: 100, Loss: 0.0749\n",
            "root        : INFO     Epoch: 68, Batch: 150, Loss: 0.0600\n",
            "root        : INFO     Epoch: 68, Batch: 200, Loss: 0.0800\n",
            "root        : INFO     Epoch: 68, Batch: 250, Loss: 0.0613\n",
            "root        : INFO     Epoch: 68, Batch: 300, Loss: 0.0699\n",
            "root        : INFO     Epoch: 68, Batch: 350, Loss: 0.0754\n",
            "root        : INFO     Epoch: 68, Batch: 400, Loss: 0.0643\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 69\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 69, Batch: 50, Loss: 0.0774\n",
            "root        : INFO     Epoch: 69, Batch: 100, Loss: 0.0759\n",
            "root        : INFO     Epoch: 69, Batch: 150, Loss: 0.0752\n",
            "root        : INFO     Epoch: 69, Batch: 200, Loss: 0.0750\n",
            "root        : INFO     Epoch: 69, Batch: 250, Loss: 0.0745\n",
            "root        : INFO     Epoch: 69, Batch: 300, Loss: 0.0877\n",
            "root        : INFO     Epoch: 69, Batch: 350, Loss: 0.0494\n",
            "root        : INFO     Epoch: 69, Batch: 400, Loss: 0.0724\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 70\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 70, Batch: 50, Loss: 0.0670\n",
            "root        : INFO     Epoch: 70, Batch: 100, Loss: 0.0747\n",
            "root        : INFO     Epoch: 70, Batch: 150, Loss: 0.0528\n",
            "root        : INFO     Epoch: 70, Batch: 200, Loss: 0.0646\n",
            "root        : INFO     Epoch: 70, Batch: 250, Loss: 0.0514\n",
            "root        : INFO     Epoch: 70, Batch: 300, Loss: 0.0436\n",
            "root        : INFO     Epoch: 70, Batch: 350, Loss: 0.0853\n",
            "root        : INFO     Epoch: 70, Batch: 400, Loss: 0.0754\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 71\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 71, Batch: 50, Loss: 0.0680\n",
            "root        : INFO     Epoch: 71, Batch: 100, Loss: 0.0659\n",
            "root        : INFO     Epoch: 71, Batch: 150, Loss: 0.0583\n",
            "root        : INFO     Epoch: 71, Batch: 200, Loss: 0.0689\n",
            "root        : INFO     Epoch: 71, Batch: 250, Loss: 0.0605\n",
            "root        : INFO     Epoch: 71, Batch: 300, Loss: 0.0651\n",
            "root        : INFO     Epoch: 71, Batch: 350, Loss: 0.0358\n",
            "root        : INFO     Epoch: 71, Batch: 400, Loss: 0.0755\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 72\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 72, Batch: 50, Loss: 0.0546\n",
            "root        : INFO     Epoch: 72, Batch: 100, Loss: 0.0498\n",
            "root        : INFO     Epoch: 72, Batch: 150, Loss: 0.0761\n",
            "root        : INFO     Epoch: 72, Batch: 200, Loss: 0.0568\n",
            "root        : INFO     Epoch: 72, Batch: 250, Loss: 0.0624\n",
            "root        : INFO     Epoch: 72, Batch: 300, Loss: 0.0545\n",
            "root        : INFO     Epoch: 72, Batch: 350, Loss: 0.0652\n",
            "root        : INFO     Epoch: 72, Batch: 400, Loss: 0.0510\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 73\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 73, Batch: 50, Loss: 0.0540\n",
            "root        : INFO     Epoch: 73, Batch: 100, Loss: 0.0742\n",
            "root        : INFO     Epoch: 73, Batch: 150, Loss: 0.0730\n",
            "root        : INFO     Epoch: 73, Batch: 200, Loss: 0.0727\n",
            "root        : INFO     Epoch: 73, Batch: 250, Loss: 0.0608\n",
            "root        : INFO     Epoch: 73, Batch: 300, Loss: 0.0558\n",
            "root        : INFO     Epoch: 73, Batch: 350, Loss: 0.0415\n",
            "root        : INFO     Epoch: 73, Batch: 400, Loss: 0.0436\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 74\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 74, Batch: 50, Loss: 0.0837\n",
            "root        : INFO     Epoch: 74, Batch: 100, Loss: 0.0596\n",
            "root        : INFO     Epoch: 74, Batch: 150, Loss: 0.0687\n",
            "root        : INFO     Epoch: 74, Batch: 200, Loss: 0.0602\n",
            "root        : INFO     Epoch: 74, Batch: 250, Loss: 0.0739\n",
            "root        : INFO     Epoch: 74, Batch: 300, Loss: 0.0696\n",
            "root        : INFO     Epoch: 74, Batch: 350, Loss: 0.0531\n",
            "root        : INFO     Epoch: 74, Batch: 400, Loss: 0.0618\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 75\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 75, Batch: 50, Loss: 0.0858\n",
            "root        : INFO     Epoch: 75, Batch: 100, Loss: 0.0404\n",
            "root        : INFO     Epoch: 75, Batch: 150, Loss: 0.0741\n",
            "root        : INFO     Epoch: 75, Batch: 200, Loss: 0.0800\n",
            "root        : INFO     Epoch: 75, Batch: 250, Loss: 0.0592\n",
            "root        : INFO     Epoch: 75, Batch: 300, Loss: 0.0363\n",
            "root        : INFO     Epoch: 75, Batch: 350, Loss: 0.0629\n",
            "root        : INFO     Epoch: 75, Batch: 400, Loss: 0.0559\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 76\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 76, Batch: 50, Loss: 0.0373\n",
            "root        : INFO     Epoch: 76, Batch: 100, Loss: 0.0558\n",
            "root        : INFO     Epoch: 76, Batch: 150, Loss: 0.0457\n",
            "root        : INFO     Epoch: 76, Batch: 200, Loss: 0.0566\n",
            "root        : INFO     Epoch: 76, Batch: 250, Loss: 0.0405\n",
            "root        : INFO     Epoch: 76, Batch: 300, Loss: 0.0707\n",
            "root        : INFO     Epoch: 76, Batch: 350, Loss: 0.0671\n",
            "root        : INFO     Epoch: 76, Batch: 400, Loss: 0.0743\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 77\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 77, Batch: 50, Loss: 0.0490\n",
            "root        : INFO     Epoch: 77, Batch: 100, Loss: 0.0603\n",
            "root        : INFO     Epoch: 77, Batch: 150, Loss: 0.0545\n",
            "root        : INFO     Epoch: 77, Batch: 200, Loss: 0.0484\n",
            "root        : INFO     Epoch: 77, Batch: 250, Loss: 0.0416\n",
            "root        : INFO     Epoch: 77, Batch: 300, Loss: 0.0594\n",
            "root        : INFO     Epoch: 77, Batch: 350, Loss: 0.0579\n",
            "root        : INFO     Epoch: 77, Batch: 400, Loss: 0.0577\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 78\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 78, Batch: 50, Loss: 0.0435\n",
            "root        : INFO     Epoch: 78, Batch: 100, Loss: 0.0813\n",
            "root        : INFO     Epoch: 78, Batch: 150, Loss: 0.0529\n",
            "root        : INFO     Epoch: 78, Batch: 200, Loss: 0.0531\n",
            "root        : INFO     Epoch: 78, Batch: 250, Loss: 0.0483\n",
            "root        : INFO     Epoch: 78, Batch: 300, Loss: 0.0660\n",
            "root        : INFO     Epoch: 78, Batch: 350, Loss: 0.0455\n",
            "root        : INFO     Epoch: 78, Batch: 400, Loss: 0.0614\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 79\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 79, Batch: 50, Loss: 0.0516\n",
            "root        : INFO     Epoch: 79, Batch: 100, Loss: 0.0450\n",
            "root        : INFO     Epoch: 79, Batch: 150, Loss: 0.0451\n",
            "root        : INFO     Epoch: 79, Batch: 200, Loss: 0.0527\n",
            "root        : INFO     Epoch: 79, Batch: 250, Loss: 0.0582\n",
            "root        : INFO     Epoch: 79, Batch: 300, Loss: 0.0536\n",
            "root        : INFO     Epoch: 79, Batch: 350, Loss: 0.0627\n",
            "root        : INFO     Epoch: 79, Batch: 400, Loss: 0.0744\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 80\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 80, Batch: 50, Loss: 0.0530\n",
            "root        : INFO     Epoch: 80, Batch: 100, Loss: 0.0494\n",
            "root        : INFO     Epoch: 80, Batch: 150, Loss: 0.0327\n",
            "root        : INFO     Epoch: 80, Batch: 200, Loss: 0.0666\n",
            "root        : INFO     Epoch: 80, Batch: 250, Loss: 0.0690\n",
            "root        : INFO     Epoch: 80, Batch: 300, Loss: 0.0646\n",
            "root        : INFO     Epoch: 80, Batch: 350, Loss: 0.0548\n",
            "root        : INFO     Epoch: 80, Batch: 400, Loss: 0.0742\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 81\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 81, Batch: 50, Loss: 0.0519\n",
            "root        : INFO     Epoch: 81, Batch: 100, Loss: 0.0483\n",
            "root        : INFO     Epoch: 81, Batch: 150, Loss: 0.0519\n",
            "root        : INFO     Epoch: 81, Batch: 200, Loss: 0.0625\n",
            "root        : INFO     Epoch: 81, Batch: 250, Loss: 0.0445\n",
            "root        : INFO     Epoch: 81, Batch: 300, Loss: 0.0636\n",
            "root        : INFO     Epoch: 81, Batch: 350, Loss: 0.0626\n",
            "root        : INFO     Epoch: 81, Batch: 400, Loss: 0.0657\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 82\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 82, Batch: 50, Loss: 0.0617\n",
            "root        : INFO     Epoch: 82, Batch: 100, Loss: 0.0605\n",
            "root        : INFO     Epoch: 82, Batch: 150, Loss: 0.0455\n",
            "root        : INFO     Epoch: 82, Batch: 200, Loss: 0.0551\n",
            "root        : INFO     Epoch: 82, Batch: 250, Loss: 0.0688\n",
            "root        : INFO     Epoch: 82, Batch: 300, Loss: 0.0689\n",
            "root        : INFO     Epoch: 82, Batch: 350, Loss: 0.0642\n",
            "root        : INFO     Epoch: 82, Batch: 400, Loss: 0.0495\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 83\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 83, Batch: 50, Loss: 0.0706\n",
            "root        : INFO     Epoch: 83, Batch: 100, Loss: 0.0658\n",
            "root        : INFO     Epoch: 83, Batch: 150, Loss: 0.0552\n",
            "root        : INFO     Epoch: 83, Batch: 200, Loss: 0.0564\n",
            "root        : INFO     Epoch: 83, Batch: 250, Loss: 0.0436\n",
            "root        : INFO     Epoch: 83, Batch: 300, Loss: 0.0411\n",
            "root        : INFO     Epoch: 83, Batch: 350, Loss: 0.0588\n",
            "root        : INFO     Epoch: 83, Batch: 400, Loss: 0.0540\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 84\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 84, Batch: 50, Loss: 0.0664\n",
            "root        : INFO     Epoch: 84, Batch: 100, Loss: 0.0526\n",
            "root        : INFO     Epoch: 84, Batch: 150, Loss: 0.0494\n",
            "root        : INFO     Epoch: 84, Batch: 200, Loss: 0.0603\n",
            "root        : INFO     Epoch: 84, Batch: 250, Loss: 0.0802\n",
            "root        : INFO     Epoch: 84, Batch: 300, Loss: 0.0760\n",
            "root        : INFO     Epoch: 84, Batch: 350, Loss: 0.0544\n",
            "root        : INFO     Epoch: 84, Batch: 400, Loss: 0.0595\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 85\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 85, Batch: 50, Loss: 0.0739\n",
            "root        : INFO     Epoch: 85, Batch: 100, Loss: 0.0759\n",
            "root        : INFO     Epoch: 85, Batch: 150, Loss: 0.0532\n",
            "root        : INFO     Epoch: 85, Batch: 200, Loss: 0.0430\n",
            "root        : INFO     Epoch: 85, Batch: 250, Loss: 0.0565\n",
            "root        : INFO     Epoch: 85, Batch: 300, Loss: 0.0535\n",
            "root        : INFO     Epoch: 85, Batch: 350, Loss: 0.0659\n",
            "root        : INFO     Epoch: 85, Batch: 400, Loss: 0.0541\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 86\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 86, Batch: 50, Loss: 0.0522\n",
            "root        : INFO     Epoch: 86, Batch: 100, Loss: 0.0512\n",
            "root        : INFO     Epoch: 86, Batch: 150, Loss: 0.0539\n",
            "root        : INFO     Epoch: 86, Batch: 200, Loss: 0.0462\n",
            "root        : INFO     Epoch: 86, Batch: 250, Loss: 0.0618\n",
            "root        : INFO     Epoch: 86, Batch: 300, Loss: 0.0651\n",
            "root        : INFO     Epoch: 86, Batch: 350, Loss: 0.0516\n",
            "root        : INFO     Epoch: 86, Batch: 400, Loss: 0.0433\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 87\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 87, Batch: 50, Loss: 0.0631\n",
            "root        : INFO     Epoch: 87, Batch: 100, Loss: 0.0364\n",
            "root        : INFO     Epoch: 87, Batch: 150, Loss: 0.0476\n",
            "root        : INFO     Epoch: 87, Batch: 200, Loss: 0.0467\n",
            "root        : INFO     Epoch: 87, Batch: 250, Loss: 0.0498\n",
            "root        : INFO     Epoch: 87, Batch: 300, Loss: 0.0488\n",
            "root        : INFO     Epoch: 87, Batch: 350, Loss: 0.0807\n",
            "root        : INFO     Epoch: 87, Batch: 400, Loss: 0.0568\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 88\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 88, Batch: 50, Loss: 0.0535\n",
            "root        : INFO     Epoch: 88, Batch: 100, Loss: 0.0443\n",
            "root        : INFO     Epoch: 88, Batch: 150, Loss: 0.0437\n",
            "root        : INFO     Epoch: 88, Batch: 200, Loss: 0.0448\n",
            "root        : INFO     Epoch: 88, Batch: 250, Loss: 0.0617\n",
            "root        : INFO     Epoch: 88, Batch: 300, Loss: 0.0449\n",
            "root        : INFO     Epoch: 88, Batch: 350, Loss: 0.0520\n",
            "root        : INFO     Epoch: 88, Batch: 400, Loss: 0.0430\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     114/177 = 0.644068\n",
            "root        : INFO     Beginning Epoch 89\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "Traceback (most recent call last):\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mkGxoG16dI29",
        "outputId": "580afb22-63ce-499d-8618-ad4262b80bbe"
      },
      "source": [
        "!python evaluate_save.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_00_iou_0.97  --dataset cornell --dataset-path /content/cornell_dataset --num-workers 4 --split 0.0 --ds-rotate 0.0 --iou-eval --augment --vis "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"evaluate_save.py\", line 88, in <module>\n",
            "    include_rgb=args.use_rgb)\n",
            "  File \"/content/drive/My Drive/GR_ConvNet_Code/utils/data/cornell_data.py\", line 26, in __init__\n",
            "    raise FileNotFoundError('No dataset files found. Check path: {}'.format(file_path))\n",
            "FileNotFoundError: No dataset files found. Check path: /content/ad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l_tbhG-a2RK"
      },
      "source": [
        "**手动学习率衰减, Object-Wise, learning rate =0.001 → 0.0005**  \n",
        "**0.881 in training validation and 0.915 in evaluation**\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_0259_training_cornell  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbXYGYaeY2ne",
        "outputId": "fad48e28-5d0c-45d4-849c-2bf1a9232982"
      },
      "source": [
        "!python train_network_t.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_1556_training_cornell/epoch_17_iou_0.87 --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-shuffle --ds-rotate 0.4 --lr=0.0005 --epochs 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 16\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.40, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 16, bacthes per epoch = 448, optimizer = adam, learning rate = 0.000500\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]           5,200\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "            Conv2d-3         [-1, 32, 112, 112]           8,224\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            "            Conv2d-5           [-1, 64, 56, 56]          32,832\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "            Conv2d-7           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "           Conv2d-24           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "           Conv2d-29           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-31           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 32, 113, 113]          32,800\n",
            "      BatchNorm2d-33         [-1, 32, 113, 113]              64\n",
            "  ConvTranspose2d-34         [-1, 16, 225, 225]           8,208\n",
            "      BatchNorm2d-35         [-1, 16, 225, 225]              32\n",
            "  ConvTranspose2d-36         [-1, 16, 225, 225]          20,752\n",
            "          Dropout-37         [-1, 16, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]              65\n",
            "          Dropout-39         [-1, 16, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]              65\n",
            "          Dropout-41         [-1, 16, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]              65\n",
            "          Dropout-43         [-1, 16, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 479,156\n",
            "Trainable params: 479,156\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 110.74\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 113.34\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0547\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0690\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.0776\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0820\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0810\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0509\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0626\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0776\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0790\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0874\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0607\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1038\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0988\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0697\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0734\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0537\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0797\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1143\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.1060\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0789\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0939\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0685\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0571\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0593\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0638\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0816\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0586\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0409\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0736\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0643\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0715\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0809\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.1109\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0913\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0698\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0561\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0890\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0732\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0513\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0495\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0752\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0627\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0594\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.1034\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0639\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0902\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0760\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.1049\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0579\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0702\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0965\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0576\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.1148\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0861\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0508\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0591\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/177 = 0.774011\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.1018\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0797\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0476\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0576\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0812\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0748\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.1114\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0629\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0693\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0745\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0706\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0709\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0529\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0426\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0783\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0639\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0901\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0670\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0611\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0772\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0592\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0610\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.1032\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0860\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0671\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0870\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0538\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0827\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0715\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0860\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0637\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0579\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0686\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0489\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0695\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0781\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0494\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0525\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0688\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0672\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0722\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0401\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0767\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0819\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0557\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0513\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0546\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0756\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0387\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0734\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0831\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0369\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0736\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0876\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0853\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0630\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0717\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0465\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0659\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0587\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0680\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0848\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0555\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0729\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0621\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0680\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0610\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0659\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0496\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0530\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0981\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0812\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0521\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0481\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0362\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0498\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0669\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0765\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0707\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0784\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.1044\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0506\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0740\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0844\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0659\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0534\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0454\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0646\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0584\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0756\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0546\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0484\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0866\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0698\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0676\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0453\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0600\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.1177\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0893\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0766\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0742\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0630\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0711\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0351\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0642\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0617\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0718\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0659\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0664\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0454\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0816\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0739\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0805\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0811\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0996\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0399\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0636\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0714\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0579\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0479\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0652\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0454\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0571\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0379\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0968\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0822\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0622\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0784\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0650\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0589\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0677\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0791\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0906\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0566\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0518\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0634\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     132/177 = 0.745763\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0893\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0510\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0417\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0687\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0806\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0727\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0548\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0660\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0502\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0833\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0403\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0550\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0537\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0482\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0746\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0819\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     130/177 = 0.734463\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0576\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0725\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.0525\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0447\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1138, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train_network_t.py\", line 371, in <module>\n",
            "    run()\n",
            "  File \"train_network_t.py\", line 343, in run\n",
            "    train_results = train(epoch, net, device, train_data, optimizer, args.batches_per_epoch, vis=args.vis)\n",
            "  File \"train_network_t.py\", line 161, in train\n",
            "    for x, y, _, _, _ in train_data:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
            "    return data\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/profiler.py\", line 621, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awd9UChvYzUt",
        "outputId": "3c65ae4d-7e3a-4e9b-df9f-9976b4385a54"
      },
      "source": [
        "!python evaluate2.py --network  /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_1556_training_cornell/epoch_17_iou_0.87  /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_0259_training_cornell/epoch_07_iou_0.88   --dataset cornell --dataset-path /content/cornell_dataset --num-workers 8 --split 0.8 --ds-rotate 0.4 --iou-eval --ds-shuffle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 177\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_1556_training_cornell/epoch_17_iou_0.87\n",
            "INFO:root:Average evaluation time per image: 103.66016457983329ms\n",
            "INFO:root:IOU Results: 155/177 = 0.875706\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_0259_training_cornell/epoch_07_iou_0.88\n",
            "INFO:root:Average evaluation time per image: 104.33744710717498ms\n",
            "INFO:root:IOU Results: 162/177 = 0.915254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vpNdI9kh5-m"
      },
      "source": [
        "**3. Tranfer Learning ds-rotate =0.4, Object-Wise, batchsize=16, SGD, learning rate =0.0002, channel size 32, train_network_ot.py**  \n",
        "**Achieved 0. in Training, **\n",
        "****  \n",
        "network  /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_0321_training_cornell/epoch_26_iou_0.87\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210413_0922_training_cornell\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JDuQwWyh5We",
        "outputId": "5fb9ab2e-8314-4f6e-e902-7b508a605013"
      },
      "source": [
        "!python train_network_ot.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_0321_training_cornell/epoch_26_iou_0.87 --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-rotate 0.4 --optim SGD --lr=0.0002 --epochs 30 --augment 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1, augment=1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 16\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.40, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 16, bacthes per epoch = 448, optimizer = SGD, learning rate = 0.000200\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210413_0922_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]           5,200\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "            Conv2d-3         [-1, 32, 112, 112]           8,224\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            "            Conv2d-5           [-1, 64, 56, 56]          32,832\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "            Conv2d-7           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "           Conv2d-24           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "           Conv2d-29           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-31           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 32, 113, 113]          32,800\n",
            "      BatchNorm2d-33         [-1, 32, 113, 113]              64\n",
            "  ConvTranspose2d-34         [-1, 16, 225, 225]           8,208\n",
            "      BatchNorm2d-35         [-1, 16, 225, 225]              32\n",
            "  ConvTranspose2d-36         [-1, 16, 225, 225]          20,752\n",
            "          Dropout-37         [-1, 16, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]              65\n",
            "          Dropout-39         [-1, 16, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]              65\n",
            "          Dropout-41         [-1, 16, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]              65\n",
            "          Dropout-43         [-1, 16, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 479,156\n",
            "Trainable params: 479,156\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 110.74\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 113.34\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0725\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0841\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.0601\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0750\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0642\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0820\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0728\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0517\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0843\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0812\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0515\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0864\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0698\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0831\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0518\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0894\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0560\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0891\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0775\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0823\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0644\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0766\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0786\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0750\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.1037\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0666\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0785\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0882\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0646\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0605\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0869\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0880\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0572\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0569\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0623\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0935\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.1004\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0830\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0867\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1061\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0822\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0453\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0542\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0647\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0954\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.1046\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0846\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0785\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0754\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0874\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0738\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0680\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0821\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0637\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0887\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0975\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0724\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0750\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0969\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0622\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0794\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0829\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0668\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0668\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0547\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0537\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0980\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0771\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0438\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0397\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0618\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0660\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0443\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0636\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0735\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1088\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0981\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0906\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0652\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0492\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0421\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0739\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0674\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0653\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0706\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0757\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0701\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0489\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0869\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0722\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0535\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0899\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0652\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0688\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0804\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0741\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0363\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0903\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0751\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0823\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0739\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0696\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0604\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0764\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0724\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0874\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0706\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0737\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0617\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0666\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0616\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0722\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0564\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0671\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0678\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0871\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0576\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0713\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0803\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0609\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0523\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0694\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0450\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.1256\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0963\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0707\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0920\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0741\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0794\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0752\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0748\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0713\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0977\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.1076\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0804\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0966\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0594\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0711\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0635\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0951\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0977\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0725\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0638\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0762\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0515\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0741\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0863\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0555\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0713\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0595\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0477\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0609\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0592\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0579\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0614\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0502\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0992\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0960\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0596\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0820\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0752\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0688\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0735\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0555\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0695\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0777\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0880\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0637\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0798\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0558\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0614\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0866\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.1155\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0805\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0618\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0616\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0701\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0793\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0630\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0689\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0818\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0626\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0544\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0442\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0870\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0824\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0886\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0541\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0515\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0809\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0829\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0629\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0956\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0664\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0582\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0660\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0769\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0599\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0936\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0759\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0707\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0898\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0676\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0704\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0738\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0574\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0688\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0563\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0731\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.1154\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.0975\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0843\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0589\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0739\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.1005\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0959\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0719\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0863\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0599\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0830\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0537\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0985\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0617\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0645\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 50, Loss: 0.0861\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0583\n",
            "root        : INFO     Epoch: 28, Batch: 150, Loss: 0.0754\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0667\n",
            "root        : INFO     Epoch: 28, Batch: 250, Loss: 0.0475\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0977\n",
            "root        : INFO     Epoch: 28, Batch: 350, Loss: 0.0626\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0744\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 50, Loss: 0.0531\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0758\n",
            "root        : INFO     Epoch: 29, Batch: 150, Loss: 0.0391\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0756\n",
            "root        : INFO     Epoch: 29, Batch: 250, Loss: 0.0760\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.1150\n",
            "root        : INFO     Epoch: 29, Batch: 350, Loss: 0.0528\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0441\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHskgWDaDewa"
      },
      "source": [
        "**手动学习率衰减 Object-Wise learning rate =0.002 → 0.001**  \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_1556_training_cornell  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDTD-83RB9QO",
        "outputId": "b578d288-a43c-4ccf-852b-c026f5e9bc86"
      },
      "source": [
        "!python train_network_t.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_0321_training_cornell/epoch_05_iou_0.85 --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-shuffle --ds-rotate 0.4 --lr=0.001 --epochs 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 16\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.40, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 16, bacthes per epoch = 448, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]           5,200\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "            Conv2d-3         [-1, 32, 112, 112]           8,224\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            "            Conv2d-5           [-1, 64, 56, 56]          32,832\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "            Conv2d-7           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "           Conv2d-24           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "           Conv2d-29           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-31           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 32, 113, 113]          32,800\n",
            "      BatchNorm2d-33         [-1, 32, 113, 113]              64\n",
            "  ConvTranspose2d-34         [-1, 16, 225, 225]           8,208\n",
            "      BatchNorm2d-35         [-1, 16, 225, 225]              32\n",
            "  ConvTranspose2d-36         [-1, 16, 225, 225]          20,752\n",
            "          Dropout-37         [-1, 16, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]              65\n",
            "          Dropout-39         [-1, 16, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]              65\n",
            "          Dropout-41         [-1, 16, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]              65\n",
            "          Dropout-43         [-1, 16, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 479,156\n",
            "Trainable params: 479,156\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 110.74\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 113.34\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0727\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0810\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.0714\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0654\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0651\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0919\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0748\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0487\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0720\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1112\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.1199\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0552\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0805\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1124\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0871\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0815\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0639\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0699\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0706\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.1040\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0856\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0778\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.1192\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0978\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0879\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0596\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0455\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0823\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0883\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0954\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0680\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0949\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0813\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0995\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0819\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0680\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0890\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1207\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.1208\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0808\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0628\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0851\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0988\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0807\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0803\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0738\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0660\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0601\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0909\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.1119\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0782\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0563\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.1023\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0855\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0591\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0969\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0905\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0796\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0721\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0925\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0698\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0677\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0691\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0799\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0518\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0599\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0762\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0672\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0717\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0690\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.1010\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0766\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0544\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0719\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.1041\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1128\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0772\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0930\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0591\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0568\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0695\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0879\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0846\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0863\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0905\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0752\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0715\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0626\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0717\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0744\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0626\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0693\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0673\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.1073\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0549\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0747\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0722\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0679\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0832\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0882\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0574\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0676\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0644\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0897\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0457\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0612\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0528\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0409\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0983\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0803\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0577\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0801\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0633\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.1003\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0973\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.1016\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0670\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0544\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0839\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0630\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0902\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0710\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0774\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.1014\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0816\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0615\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0617\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0774\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0665\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0934\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0823\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0911\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0834\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0620\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0789\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0534\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0846\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0701\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0907\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.1081\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0561\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0818\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0675\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.1148\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0724\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0720\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0822\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0742\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0598\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0606\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0831\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0601\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0759\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0514\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0781\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0580\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0507\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0870\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.1133\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0731\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0750\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0544\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.0738\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0706\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0674\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0774\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0717\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0944\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0781\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0589\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0545\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0909\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.1065\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0703\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.0904\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0568\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0404\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0680\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0821\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.1069\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.1106\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0968\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0596\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0716\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0802\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0522\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0607\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0751\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.0910\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0624\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0626\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0683\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0563\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0714\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0629\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0576\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0876\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0897\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0854\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0822\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 50, Loss: 0.0576\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0841\n",
            "root        : INFO     Epoch: 25, Batch: 150, Loss: 0.0707\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0597\n",
            "root        : INFO     Epoch: 25, Batch: 250, Loss: 0.0834\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0714\n",
            "root        : INFO     Epoch: 25, Batch: 350, Loss: 0.0731\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0559\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 50, Loss: 0.0793\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0767\n",
            "root        : INFO     Epoch: 26, Batch: 150, Loss: 0.0750\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0787\n",
            "root        : INFO     Epoch: 26, Batch: 250, Loss: 0.0654\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0654\n",
            "root        : INFO     Epoch: 26, Batch: 350, Loss: 0.0783\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0528\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 50, Loss: 0.0699\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0854\n",
            "root        : INFO     Epoch: 27, Batch: 150, Loss: 0.0886\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0664\n",
            "root        : INFO     Epoch: 27, Batch: 250, Loss: 0.0659\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0736\n",
            "root        : INFO     Epoch: 27, Batch: 350, Loss: 0.0737\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FTj1wpshIzG"
      },
      "source": [
        "!python train_network_t.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210407_1556_training_cornell/epoch_17_iou_0.87 --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-shuffle --ds-rotate 0.4 --lr=0.0005 --epochs 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wci3_hcXas5"
      },
      "source": [
        "**Adam learning rate =0.0005 → SGD lr= 0.0005**    \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_0724_training_cornell  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJw7CjNJWxV3",
        "outputId": "c68a9ab1-72de-4cfd-8d4e-418af4e878c8"
      },
      "source": [
        "!python train_network_t.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_0259_training_cornell/epoch_07_iou_0.88  --channel-size 16 --num-workers 8 --batch-size 16 --batches-per-epoch 448 --split 0.8  --ds-shuffle --ds-rotate 0.4 --optim SGD --lr=0.0005 --epochs 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 16\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.40, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 16, bacthes per epoch = 448, optimizer = SGD, learning rate = 0.000500\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]           5,200\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "            Conv2d-3         [-1, 32, 112, 112]           8,224\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            "            Conv2d-5           [-1, 64, 56, 56]          32,832\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "            Conv2d-7           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
            "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "           Conv2d-14           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-16           [-1, 64, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "           Conv2d-24           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-26           [-1, 64, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "           Conv2d-29           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
            "    ResidualBlock-31           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 32, 113, 113]          32,800\n",
            "      BatchNorm2d-33         [-1, 32, 113, 113]              64\n",
            "  ConvTranspose2d-34         [-1, 16, 225, 225]           8,208\n",
            "      BatchNorm2d-35         [-1, 16, 225, 225]              32\n",
            "  ConvTranspose2d-36         [-1, 16, 225, 225]          20,752\n",
            "          Dropout-37         [-1, 16, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]              65\n",
            "          Dropout-39         [-1, 16, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]              65\n",
            "          Dropout-41         [-1, 16, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]              65\n",
            "          Dropout-43         [-1, 16, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 479,156\n",
            "Trainable params: 479,156\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 110.74\n",
            "Params size (MB): 1.83\n",
            "Estimated Total Size (MB): 113.34\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0630\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0741\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.0441\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0688\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0811\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0902\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0525\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0655\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.1157\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0617\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0658\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0687\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0681\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0674\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0853\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0902\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0546\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0469\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0682\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0494\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0664\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0530\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0587\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0866\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0716\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0633\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0620\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0600\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0591\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0836\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0854\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0619\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0621\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0665\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0688\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0730\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0627\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0926\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0561\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0710\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0668\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0678\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0606\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0666\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0598\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0560\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0318\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0482\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0727\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0826\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0757\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0594\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0648\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0787\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0503\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0583\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0872\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0703\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0687\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0564\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0717\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0712\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0629\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0811\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0649\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0877\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0885\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0683\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0856\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0721\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0733\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0494\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0774\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0814\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0471\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0864\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0737\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0573\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0555\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0637\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0437\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0737\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0625\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0772\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0466\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0645\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0610\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0726\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0551\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0724\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0504\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0688\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0619\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0701\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0647\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0867\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jac3EEGRAcVW"
      },
      "source": [
        "**4. ds-rotate =0.6, Object-Wise, batchsize=8, Adam, learning rate =0.001, channel size 32**  \n",
        "**Achieved 0.921 **\n",
        "\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_1509_training_cornell  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY2ZD8I7Acyf",
        "outputId": "4852313f-fcd0-4c0b-cfb5-c24617e62123"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.6 --lr=0.001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.60, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1701\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1456\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.2258\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1047\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0689\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.2241\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1392\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1002\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.1237\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.1728\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0875\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1086\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.0650\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0732\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.1319\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.0685\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.1003\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.1332\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0661\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0553\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0537\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0940\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1018\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0562\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.1044\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.1084\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.1365\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.0955\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0854\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.1369\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0670\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.1046\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0582\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.0832\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     119/177 = 0.672316\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.1145\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0903\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0820\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0720\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1016\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.1214\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.1334\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0974\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0674\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0845\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.1305\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0974\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.1308\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0583\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.0991\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0445\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0788\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0920\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1107\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0587\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0880\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0667\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0769\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0959\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.1163\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.1093\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0926\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.0849\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.1096\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0916\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0914\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.1169\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0940\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0581\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0616\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0648\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0827\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0817\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0706\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1165\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0802\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1012\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.0841\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0850\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0717\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0736\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.0839\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.1123\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0864\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0493\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0762\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.1066\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.1215\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0927\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.1016\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0753\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0596\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0611\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0515\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0843\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0509\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0911\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0749\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.0773\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0368\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0523\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0903\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0820\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0641\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0491\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0640\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0503\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0785\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.1348\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0482\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0480\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0677\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.1697\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0607\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.1256\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.1261\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.1366\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0866\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0833\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0839\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0951\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0874\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0568\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0482\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0861\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0591\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.1080\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.1178\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0596\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0679\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0578\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0435\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0878\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.1047\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0841\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0506\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.1010\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0930\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0937\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0851\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0495\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.1018\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.1042\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.1257\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0766\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0920\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0479\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0573\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0927\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0351\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0864\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0709\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.1030\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0484\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0516\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0540\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0803\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0819\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.1382\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.1105\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.1017\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0921\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0987\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.1179\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.1176\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.1350\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0763\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0857\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0843\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0580\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.1083\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.1067\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0810\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0842\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.1243\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0450\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0955\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0402\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.1573\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.0459\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0644\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0603\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0508\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0908\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0858\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0812\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0417\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0783\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0637\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0590\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0817\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0826\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0914\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0422\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0831\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0794\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0895\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0989\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0534\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0808\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0562\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0735\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0500\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0409\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.1450\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0849\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0813\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0773\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0905\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.1230\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0661\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0968\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0758\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.1446\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0921\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0691\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0695\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0848\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0672\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0353\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0853\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0653\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0806\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0912\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0815\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0801\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0639\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.1110\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.1038\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0706\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.0629\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0609\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.0908\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0675\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0627\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0770\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.0438\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0757\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.0583\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0490\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0664\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0901\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0700\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0910\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0786\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0603\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0506\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.1240\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0513\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.1345\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0983\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0651\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0769\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0782\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0769\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0466\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0817\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0685\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.1221\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0795\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0974\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.1431\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.1247\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0624\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.0928\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0731\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.1040\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0703\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.0711\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0583\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.1098\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0771\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0974\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0714\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0356\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0673\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0495\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0701\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.1010\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0616\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0844\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.0989\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0505\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.0535\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0551\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0673\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0348\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0467\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0678\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0730\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0600\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.1008\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0607\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0777\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0621\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0680\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0660\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.1539\n",
            "root        : INFO     Epoch: 17, Batch: 450, Loss: 0.0852\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0621\n",
            "root        : INFO     Epoch: 17, Batch: 550, Loss: 0.1014\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0727\n",
            "root        : INFO     Epoch: 17, Batch: 650, Loss: 0.0913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmgGrmbWIecq"
      },
      "source": [
        "**4. ds-rotate =0.6, Image-Wise, batchsize=8, Adam, learning rate =0.001, channel size 32, train_network4.py**  \n",
        "**Achieved 0.921**\n",
        "logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0319_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5CgZkGfIBeN",
        "outputId": "da5bfb8f-4bac-4457-abc5-78524cc2234f"
      },
      "source": [
        "!python train_network4.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.6 --lr=0.001 --augment 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.60, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0319_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1851\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.0993\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.1417\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.1147\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1328\n",
            "root        : INFO     Epoch: 0, Batch: 120, Loss: 0.1318\n",
            "root        : INFO     Epoch: 0, Batch: 140, Loss: 0.1525\n",
            "root        : INFO     Epoch: 0, Batch: 160, Loss: 0.1232\n",
            "root        : INFO     Epoch: 0, Batch: 180, Loss: 0.1646\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.2236\n",
            "root        : INFO     Epoch: 0, Batch: 220, Loss: 0.0836\n",
            "root        : INFO     Epoch: 0, Batch: 240, Loss: 0.1014\n",
            "root        : INFO     Epoch: 0, Batch: 260, Loss: 0.1259\n",
            "root        : INFO     Epoch: 0, Batch: 280, Loss: 0.1083\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1020\n",
            "root        : INFO     Epoch: 0, Batch: 320, Loss: 0.1315\n",
            "root        : INFO     Epoch: 0, Batch: 340, Loss: 0.0928\n",
            "root        : INFO     Epoch: 0, Batch: 360, Loss: 0.0944\n",
            "root        : INFO     Epoch: 0, Batch: 380, Loss: 0.1637\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1071\n",
            "root        : INFO     Epoch: 0, Batch: 420, Loss: 0.0943\n",
            "root        : INFO     Epoch: 0, Batch: 440, Loss: 0.1238\n",
            "root        : INFO     Epoch: 0, Batch: 460, Loss: 0.1154\n",
            "root        : INFO     Epoch: 0, Batch: 480, Loss: 0.1015\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.1275\n",
            "root        : INFO     Epoch: 0, Batch: 520, Loss: 0.0564\n",
            "root        : INFO     Epoch: 0, Batch: 540, Loss: 0.1303\n",
            "root        : INFO     Epoch: 0, Batch: 560, Loss: 0.1323\n",
            "root        : INFO     Epoch: 0, Batch: 580, Loss: 0.1149\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1027\n",
            "root        : INFO     Epoch: 0, Batch: 620, Loss: 0.0743\n",
            "root        : INFO     Epoch: 0, Batch: 640, Loss: 0.1270\n",
            "root        : INFO     Epoch: 0, Batch: 660, Loss: 0.1373\n",
            "root        : INFO     Epoch: 0, Batch: 680, Loss: 0.1574\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0639\n",
            "root        : INFO     Epoch: 0, Batch: 720, Loss: 0.0843\n",
            "root        : INFO     Epoch: 0, Batch: 740, Loss: 0.1232\n",
            "root        : INFO     Epoch: 0, Batch: 760, Loss: 0.0989\n",
            "root        : INFO     Epoch: 0, Batch: 780, Loss: 0.0749\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1177\n",
            "root        : INFO     Epoch: 0, Batch: 820, Loss: 0.0837\n",
            "root        : INFO     Epoch: 0, Batch: 840, Loss: 0.0779\n",
            "root        : INFO     Epoch: 0, Batch: 860, Loss: 0.0798\n",
            "root        : INFO     Epoch: 0, Batch: 880, Loss: 0.0937\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     89/177 = 0.502825\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0614\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0767\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.1118\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0873\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1650\n",
            "root        : INFO     Epoch: 1, Batch: 120, Loss: 0.1167\n",
            "root        : INFO     Epoch: 1, Batch: 140, Loss: 0.0918\n",
            "root        : INFO     Epoch: 1, Batch: 160, Loss: 0.0860\n",
            "root        : INFO     Epoch: 1, Batch: 180, Loss: 0.1478\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1249\n",
            "root        : INFO     Epoch: 1, Batch: 220, Loss: 0.1206\n",
            "root        : INFO     Epoch: 1, Batch: 240, Loss: 0.0740\n",
            "root        : INFO     Epoch: 1, Batch: 260, Loss: 0.0639\n",
            "root        : INFO     Epoch: 1, Batch: 280, Loss: 0.1649\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0928\n",
            "root        : INFO     Epoch: 1, Batch: 320, Loss: 0.1091\n",
            "root        : INFO     Epoch: 1, Batch: 340, Loss: 0.0663\n",
            "root        : INFO     Epoch: 1, Batch: 360, Loss: 0.0880\n",
            "root        : INFO     Epoch: 1, Batch: 380, Loss: 0.1044\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0967\n",
            "root        : INFO     Epoch: 1, Batch: 420, Loss: 0.0606\n",
            "root        : INFO     Epoch: 1, Batch: 440, Loss: 0.2000\n",
            "root        : INFO     Epoch: 1, Batch: 460, Loss: 0.1561\n",
            "root        : INFO     Epoch: 1, Batch: 480, Loss: 0.0648\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0849\n",
            "root        : INFO     Epoch: 1, Batch: 520, Loss: 0.1115\n",
            "root        : INFO     Epoch: 1, Batch: 540, Loss: 0.0895\n",
            "root        : INFO     Epoch: 1, Batch: 560, Loss: 0.0896\n",
            "root        : INFO     Epoch: 1, Batch: 580, Loss: 0.0974\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0932\n",
            "root        : INFO     Epoch: 1, Batch: 620, Loss: 0.1103\n",
            "root        : INFO     Epoch: 1, Batch: 640, Loss: 0.1529\n",
            "root        : INFO     Epoch: 1, Batch: 660, Loss: 0.1075\n",
            "root        : INFO     Epoch: 1, Batch: 680, Loss: 0.1009\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.1214\n",
            "root        : INFO     Epoch: 1, Batch: 720, Loss: 0.1152\n",
            "root        : INFO     Epoch: 1, Batch: 740, Loss: 0.0705\n",
            "root        : INFO     Epoch: 1, Batch: 760, Loss: 0.1109\n",
            "root        : INFO     Epoch: 1, Batch: 780, Loss: 0.1185\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0909\n",
            "root        : INFO     Epoch: 1, Batch: 820, Loss: 0.0672\n",
            "root        : INFO     Epoch: 1, Batch: 840, Loss: 0.0854\n",
            "root        : INFO     Epoch: 1, Batch: 860, Loss: 0.0849\n",
            "root        : INFO     Epoch: 1, Batch: 880, Loss: 0.0947\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     20/177 = 0.112994\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0907\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0725\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.1352\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0954\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0791\n",
            "root        : INFO     Epoch: 2, Batch: 120, Loss: 0.0782\n",
            "root        : INFO     Epoch: 2, Batch: 140, Loss: 0.1210\n",
            "root        : INFO     Epoch: 2, Batch: 160, Loss: 0.1467\n",
            "root        : INFO     Epoch: 2, Batch: 180, Loss: 0.0529\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0598\n",
            "root        : INFO     Epoch: 2, Batch: 220, Loss: 0.0701\n",
            "root        : INFO     Epoch: 2, Batch: 240, Loss: 0.0890\n",
            "root        : INFO     Epoch: 2, Batch: 260, Loss: 0.0863\n",
            "root        : INFO     Epoch: 2, Batch: 280, Loss: 0.0482\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0658\n",
            "root        : INFO     Epoch: 2, Batch: 320, Loss: 0.0881\n",
            "root        : INFO     Epoch: 2, Batch: 340, Loss: 0.0817\n",
            "root        : INFO     Epoch: 2, Batch: 360, Loss: 0.0692\n",
            "root        : INFO     Epoch: 2, Batch: 380, Loss: 0.0741\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0842\n",
            "root        : INFO     Epoch: 2, Batch: 420, Loss: 0.1511\n",
            "root        : INFO     Epoch: 2, Batch: 440, Loss: 0.1323\n",
            "root        : INFO     Epoch: 2, Batch: 460, Loss: 0.0682\n",
            "root        : INFO     Epoch: 2, Batch: 480, Loss: 0.0868\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0487\n",
            "root        : INFO     Epoch: 2, Batch: 520, Loss: 0.0525\n",
            "root        : INFO     Epoch: 2, Batch: 540, Loss: 0.1088\n",
            "root        : INFO     Epoch: 2, Batch: 560, Loss: 0.1059\n",
            "root        : INFO     Epoch: 2, Batch: 580, Loss: 0.0715\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0930\n",
            "root        : INFO     Epoch: 2, Batch: 620, Loss: 0.1155\n",
            "root        : INFO     Epoch: 2, Batch: 640, Loss: 0.0644\n",
            "root        : INFO     Epoch: 2, Batch: 660, Loss: 0.0888\n",
            "root        : INFO     Epoch: 2, Batch: 680, Loss: 0.1484\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0519\n",
            "root        : INFO     Epoch: 2, Batch: 720, Loss: 0.0963\n",
            "root        : INFO     Epoch: 2, Batch: 740, Loss: 0.0740\n",
            "root        : INFO     Epoch: 2, Batch: 760, Loss: 0.0788\n",
            "root        : INFO     Epoch: 2, Batch: 780, Loss: 0.0582\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.1078\n",
            "root        : INFO     Epoch: 2, Batch: 820, Loss: 0.0559\n",
            "root        : INFO     Epoch: 2, Batch: 840, Loss: 0.0878\n",
            "root        : INFO     Epoch: 2, Batch: 860, Loss: 0.0581\n",
            "root        : INFO     Epoch: 2, Batch: 880, Loss: 0.1163\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.1222\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.2275\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.1102\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0780\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1253\n",
            "root        : INFO     Epoch: 3, Batch: 120, Loss: 0.0634\n",
            "root        : INFO     Epoch: 3, Batch: 140, Loss: 0.0893\n",
            "root        : INFO     Epoch: 3, Batch: 160, Loss: 0.1202\n",
            "root        : INFO     Epoch: 3, Batch: 180, Loss: 0.0680\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0971\n",
            "root        : INFO     Epoch: 3, Batch: 220, Loss: 0.0902\n",
            "root        : INFO     Epoch: 3, Batch: 240, Loss: 0.1267\n",
            "root        : INFO     Epoch: 3, Batch: 260, Loss: 0.0588\n",
            "root        : INFO     Epoch: 3, Batch: 280, Loss: 0.0883\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0762\n",
            "root        : INFO     Epoch: 3, Batch: 320, Loss: 0.0460\n",
            "root        : INFO     Epoch: 3, Batch: 340, Loss: 0.1216\n",
            "root        : INFO     Epoch: 3, Batch: 360, Loss: 0.0826\n",
            "root        : INFO     Epoch: 3, Batch: 380, Loss: 0.0708\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0677\n",
            "root        : INFO     Epoch: 3, Batch: 420, Loss: 0.0683\n",
            "root        : INFO     Epoch: 3, Batch: 440, Loss: 0.0904\n",
            "root        : INFO     Epoch: 3, Batch: 460, Loss: 0.0945\n",
            "root        : INFO     Epoch: 3, Batch: 480, Loss: 0.0649\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0803\n",
            "root        : INFO     Epoch: 3, Batch: 520, Loss: 0.0970\n",
            "root        : INFO     Epoch: 3, Batch: 540, Loss: 0.0553\n",
            "root        : INFO     Epoch: 3, Batch: 560, Loss: 0.0913\n",
            "root        : INFO     Epoch: 3, Batch: 580, Loss: 0.0794\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0848\n",
            "root        : INFO     Epoch: 3, Batch: 620, Loss: 0.0880\n",
            "root        : INFO     Epoch: 3, Batch: 640, Loss: 0.0678\n",
            "root        : INFO     Epoch: 3, Batch: 660, Loss: 0.0932\n",
            "root        : INFO     Epoch: 3, Batch: 680, Loss: 0.0525\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.1084\n",
            "root        : INFO     Epoch: 3, Batch: 720, Loss: 0.0682\n",
            "root        : INFO     Epoch: 3, Batch: 740, Loss: 0.1292\n",
            "root        : INFO     Epoch: 3, Batch: 760, Loss: 0.0817\n",
            "root        : INFO     Epoch: 3, Batch: 780, Loss: 0.0835\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0900\n",
            "root        : INFO     Epoch: 3, Batch: 820, Loss: 0.0584\n",
            "root        : INFO     Epoch: 3, Batch: 840, Loss: 0.1243\n",
            "root        : INFO     Epoch: 3, Batch: 860, Loss: 0.0772\n",
            "root        : INFO     Epoch: 3, Batch: 880, Loss: 0.0601\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0796\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0852\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0703\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.1530\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0595\n",
            "root        : INFO     Epoch: 4, Batch: 120, Loss: 0.0940\n",
            "root        : INFO     Epoch: 4, Batch: 140, Loss: 0.0575\n",
            "root        : INFO     Epoch: 4, Batch: 160, Loss: 0.1003\n",
            "root        : INFO     Epoch: 4, Batch: 180, Loss: 0.0974\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0695\n",
            "root        : INFO     Epoch: 4, Batch: 220, Loss: 0.1092\n",
            "root        : INFO     Epoch: 4, Batch: 240, Loss: 0.1057\n",
            "root        : INFO     Epoch: 4, Batch: 260, Loss: 0.0767\n",
            "root        : INFO     Epoch: 4, Batch: 280, Loss: 0.0841\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1345\n",
            "root        : INFO     Epoch: 4, Batch: 320, Loss: 0.1124\n",
            "root        : INFO     Epoch: 4, Batch: 340, Loss: 0.1013\n",
            "root        : INFO     Epoch: 4, Batch: 360, Loss: 0.1184\n",
            "root        : INFO     Epoch: 4, Batch: 380, Loss: 0.0663\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0840\n",
            "root        : INFO     Epoch: 4, Batch: 420, Loss: 0.0580\n",
            "root        : INFO     Epoch: 4, Batch: 440, Loss: 0.0821\n",
            "root        : INFO     Epoch: 4, Batch: 460, Loss: 0.0485\n",
            "root        : INFO     Epoch: 4, Batch: 480, Loss: 0.1060\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.1112\n",
            "root        : INFO     Epoch: 4, Batch: 520, Loss: 0.1613\n",
            "root        : INFO     Epoch: 4, Batch: 540, Loss: 0.1023\n",
            "root        : INFO     Epoch: 4, Batch: 560, Loss: 0.0715\n",
            "root        : INFO     Epoch: 4, Batch: 580, Loss: 0.0937\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.1639\n",
            "root        : INFO     Epoch: 4, Batch: 620, Loss: 0.0825\n",
            "root        : INFO     Epoch: 4, Batch: 640, Loss: 0.1345\n",
            "root        : INFO     Epoch: 4, Batch: 660, Loss: 0.1428\n",
            "root        : INFO     Epoch: 4, Batch: 680, Loss: 0.1165\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0688\n",
            "root        : INFO     Epoch: 4, Batch: 720, Loss: 0.1111\n",
            "root        : INFO     Epoch: 4, Batch: 740, Loss: 0.0719\n",
            "root        : INFO     Epoch: 4, Batch: 760, Loss: 0.0686\n",
            "root        : INFO     Epoch: 4, Batch: 780, Loss: 0.0954\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0991\n",
            "root        : INFO     Epoch: 4, Batch: 820, Loss: 0.1037\n",
            "root        : INFO     Epoch: 4, Batch: 840, Loss: 0.1287\n",
            "root        : INFO     Epoch: 4, Batch: 860, Loss: 0.0780\n",
            "root        : INFO     Epoch: 4, Batch: 880, Loss: 0.1255\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0553\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0873\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0805\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.1098\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0442\n",
            "root        : INFO     Epoch: 5, Batch: 120, Loss: 0.0607\n",
            "root        : INFO     Epoch: 5, Batch: 140, Loss: 0.0707\n",
            "root        : INFO     Epoch: 5, Batch: 160, Loss: 0.0958\n",
            "root        : INFO     Epoch: 5, Batch: 180, Loss: 0.0691\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0398\n",
            "root        : INFO     Epoch: 5, Batch: 220, Loss: 0.0517\n",
            "root        : INFO     Epoch: 5, Batch: 240, Loss: 0.0809\n",
            "root        : INFO     Epoch: 5, Batch: 260, Loss: 0.0891\n",
            "root        : INFO     Epoch: 5, Batch: 280, Loss: 0.1063\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0588\n",
            "root        : INFO     Epoch: 5, Batch: 320, Loss: 0.0652\n",
            "root        : INFO     Epoch: 5, Batch: 340, Loss: 0.0845\n",
            "root        : INFO     Epoch: 5, Batch: 360, Loss: 0.0561\n",
            "root        : INFO     Epoch: 5, Batch: 380, Loss: 0.1300\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0640\n",
            "root        : INFO     Epoch: 5, Batch: 420, Loss: 0.0648\n",
            "root        : INFO     Epoch: 5, Batch: 440, Loss: 0.0796\n",
            "root        : INFO     Epoch: 5, Batch: 460, Loss: 0.0964\n",
            "root        : INFO     Epoch: 5, Batch: 480, Loss: 0.0992\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0640\n",
            "root        : INFO     Epoch: 5, Batch: 520, Loss: 0.0844\n",
            "root        : INFO     Epoch: 5, Batch: 540, Loss: 0.1031\n",
            "root        : INFO     Epoch: 5, Batch: 560, Loss: 0.0607\n",
            "root        : INFO     Epoch: 5, Batch: 580, Loss: 0.0664\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0566\n",
            "root        : INFO     Epoch: 5, Batch: 620, Loss: 0.0451\n",
            "root        : INFO     Epoch: 5, Batch: 640, Loss: 0.0438\n",
            "root        : INFO     Epoch: 5, Batch: 660, Loss: 0.0939\n",
            "root        : INFO     Epoch: 5, Batch: 680, Loss: 0.0639\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0848\n",
            "root        : INFO     Epoch: 5, Batch: 720, Loss: 0.0492\n",
            "root        : INFO     Epoch: 5, Batch: 740, Loss: 0.0577\n",
            "root        : INFO     Epoch: 5, Batch: 760, Loss: 0.0857\n",
            "root        : INFO     Epoch: 5, Batch: 780, Loss: 0.0538\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0692\n",
            "root        : INFO     Epoch: 5, Batch: 820, Loss: 0.1269\n",
            "root        : INFO     Epoch: 5, Batch: 840, Loss: 0.0657\n",
            "root        : INFO     Epoch: 5, Batch: 860, Loss: 0.0674\n",
            "root        : INFO     Epoch: 5, Batch: 880, Loss: 0.1000\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.1038\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0579\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0519\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0546\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0904\n",
            "root        : INFO     Epoch: 6, Batch: 120, Loss: 0.0424\n",
            "root        : INFO     Epoch: 6, Batch: 140, Loss: 0.0814\n",
            "root        : INFO     Epoch: 6, Batch: 160, Loss: 0.0989\n",
            "root        : INFO     Epoch: 6, Batch: 180, Loss: 0.0890\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0841\n",
            "root        : INFO     Epoch: 6, Batch: 220, Loss: 0.0751\n",
            "root        : INFO     Epoch: 6, Batch: 240, Loss: 0.0484\n",
            "root        : INFO     Epoch: 6, Batch: 260, Loss: 0.0571\n",
            "root        : INFO     Epoch: 6, Batch: 280, Loss: 0.1468\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0681\n",
            "root        : INFO     Epoch: 6, Batch: 320, Loss: 0.0491\n",
            "root        : INFO     Epoch: 6, Batch: 340, Loss: 0.0498\n",
            "root        : INFO     Epoch: 6, Batch: 360, Loss: 0.0815\n",
            "root        : INFO     Epoch: 6, Batch: 380, Loss: 0.1039\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0966\n",
            "root        : INFO     Epoch: 6, Batch: 420, Loss: 0.0699\n",
            "root        : INFO     Epoch: 6, Batch: 440, Loss: 0.0587\n",
            "root        : INFO     Epoch: 6, Batch: 460, Loss: 0.0811\n",
            "root        : INFO     Epoch: 6, Batch: 480, Loss: 0.0709\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0644\n",
            "root        : INFO     Epoch: 6, Batch: 520, Loss: 0.0708\n",
            "root        : INFO     Epoch: 6, Batch: 540, Loss: 0.1076\n",
            "root        : INFO     Epoch: 6, Batch: 560, Loss: 0.0590\n",
            "root        : INFO     Epoch: 6, Batch: 580, Loss: 0.0833\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0819\n",
            "root        : INFO     Epoch: 6, Batch: 620, Loss: 0.0592\n",
            "root        : INFO     Epoch: 6, Batch: 640, Loss: 0.1067\n",
            "root        : INFO     Epoch: 6, Batch: 660, Loss: 0.0757\n",
            "root        : INFO     Epoch: 6, Batch: 680, Loss: 0.0270\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0988\n",
            "root        : INFO     Epoch: 6, Batch: 720, Loss: 0.0742\n",
            "root        : INFO     Epoch: 6, Batch: 740, Loss: 0.0852\n",
            "root        : INFO     Epoch: 6, Batch: 760, Loss: 0.0443\n",
            "root        : INFO     Epoch: 6, Batch: 780, Loss: 0.1126\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0409\n",
            "root        : INFO     Epoch: 6, Batch: 820, Loss: 0.0807\n",
            "root        : INFO     Epoch: 6, Batch: 840, Loss: 0.0344\n",
            "root        : INFO     Epoch: 6, Batch: 860, Loss: 0.0577\n",
            "root        : INFO     Epoch: 6, Batch: 880, Loss: 0.0927\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0694\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0821\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.1103\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0556\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0947\n",
            "root        : INFO     Epoch: 7, Batch: 120, Loss: 0.0495\n",
            "root        : INFO     Epoch: 7, Batch: 140, Loss: 0.0425\n",
            "root        : INFO     Epoch: 7, Batch: 160, Loss: 0.0750\n",
            "root        : INFO     Epoch: 7, Batch: 180, Loss: 0.0552\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0663\n",
            "root        : INFO     Epoch: 7, Batch: 220, Loss: 0.0480\n",
            "root        : INFO     Epoch: 7, Batch: 240, Loss: 0.1096\n",
            "root        : INFO     Epoch: 7, Batch: 260, Loss: 0.0817\n",
            "root        : INFO     Epoch: 7, Batch: 280, Loss: 0.1230\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0945\n",
            "root        : INFO     Epoch: 7, Batch: 320, Loss: 0.0897\n",
            "root        : INFO     Epoch: 7, Batch: 340, Loss: 0.0750\n",
            "root        : INFO     Epoch: 7, Batch: 360, Loss: 0.1065\n",
            "root        : INFO     Epoch: 7, Batch: 380, Loss: 0.0851\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0519\n",
            "root        : INFO     Epoch: 7, Batch: 420, Loss: 0.0933\n",
            "root        : INFO     Epoch: 7, Batch: 440, Loss: 0.0471\n",
            "root        : INFO     Epoch: 7, Batch: 460, Loss: 0.0995\n",
            "root        : INFO     Epoch: 7, Batch: 480, Loss: 0.1201\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0565\n",
            "root        : INFO     Epoch: 7, Batch: 520, Loss: 0.1001\n",
            "root        : INFO     Epoch: 7, Batch: 540, Loss: 0.0900\n",
            "root        : INFO     Epoch: 7, Batch: 560, Loss: 0.0734\n",
            "root        : INFO     Epoch: 7, Batch: 580, Loss: 0.0854\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.1194\n",
            "root        : INFO     Epoch: 7, Batch: 620, Loss: 0.0824\n",
            "root        : INFO     Epoch: 7, Batch: 640, Loss: 0.0666\n",
            "root        : INFO     Epoch: 7, Batch: 660, Loss: 0.0778\n",
            "root        : INFO     Epoch: 7, Batch: 680, Loss: 0.1814\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0567\n",
            "root        : INFO     Epoch: 7, Batch: 720, Loss: 0.0644\n",
            "root        : INFO     Epoch: 7, Batch: 740, Loss: 0.0865\n",
            "root        : INFO     Epoch: 7, Batch: 760, Loss: 0.1010\n",
            "root        : INFO     Epoch: 7, Batch: 780, Loss: 0.0324\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0992\n",
            "root        : INFO     Epoch: 7, Batch: 820, Loss: 0.0794\n",
            "root        : INFO     Epoch: 7, Batch: 840, Loss: 0.0977\n",
            "root        : INFO     Epoch: 7, Batch: 860, Loss: 0.1731\n",
            "root        : INFO     Epoch: 7, Batch: 880, Loss: 0.0666\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0484\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.0612\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.1106\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0412\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0593\n",
            "root        : INFO     Epoch: 8, Batch: 120, Loss: 0.0654\n",
            "root        : INFO     Epoch: 8, Batch: 140, Loss: 0.0752\n",
            "root        : INFO     Epoch: 8, Batch: 160, Loss: 0.1335\n",
            "root        : INFO     Epoch: 8, Batch: 180, Loss: 0.0957\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0459\n",
            "root        : INFO     Epoch: 8, Batch: 220, Loss: 0.0835\n",
            "root        : INFO     Epoch: 8, Batch: 240, Loss: 0.0741\n",
            "root        : INFO     Epoch: 8, Batch: 260, Loss: 0.0871\n",
            "root        : INFO     Epoch: 8, Batch: 280, Loss: 0.0377\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0598\n",
            "root        : INFO     Epoch: 8, Batch: 320, Loss: 0.0444\n",
            "root        : INFO     Epoch: 8, Batch: 340, Loss: 0.0956\n",
            "root        : INFO     Epoch: 8, Batch: 360, Loss: 0.0906\n",
            "root        : INFO     Epoch: 8, Batch: 380, Loss: 0.0383\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0599\n",
            "root        : INFO     Epoch: 8, Batch: 420, Loss: 0.0808\n",
            "root        : INFO     Epoch: 8, Batch: 440, Loss: 0.1385\n",
            "root        : INFO     Epoch: 8, Batch: 460, Loss: 0.0829\n",
            "root        : INFO     Epoch: 8, Batch: 480, Loss: 0.0972\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0715\n",
            "root        : INFO     Epoch: 8, Batch: 520, Loss: 0.0365\n",
            "root        : INFO     Epoch: 8, Batch: 540, Loss: 0.0754\n",
            "root        : INFO     Epoch: 8, Batch: 560, Loss: 0.0516\n",
            "root        : INFO     Epoch: 8, Batch: 580, Loss: 0.0452\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0736\n",
            "root        : INFO     Epoch: 8, Batch: 620, Loss: 0.1490\n",
            "root        : INFO     Epoch: 8, Batch: 640, Loss: 0.0553\n",
            "root        : INFO     Epoch: 8, Batch: 660, Loss: 0.0503\n",
            "root        : INFO     Epoch: 8, Batch: 680, Loss: 0.0649\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.1073\n",
            "root        : INFO     Epoch: 8, Batch: 720, Loss: 0.1103\n",
            "root        : INFO     Epoch: 8, Batch: 740, Loss: 0.0675\n",
            "root        : INFO     Epoch: 8, Batch: 760, Loss: 0.0943\n",
            "root        : INFO     Epoch: 8, Batch: 780, Loss: 0.0649\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.1316\n",
            "root        : INFO     Epoch: 8, Batch: 820, Loss: 0.0667\n",
            "root        : INFO     Epoch: 8, Batch: 840, Loss: 0.0847\n",
            "root        : INFO     Epoch: 8, Batch: 860, Loss: 0.1055\n",
            "root        : INFO     Epoch: 8, Batch: 880, Loss: 0.0791\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.1001\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0844\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0911\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0685\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.1091\n",
            "root        : INFO     Epoch: 9, Batch: 120, Loss: 0.0973\n",
            "root        : INFO     Epoch: 9, Batch: 140, Loss: 0.0762\n",
            "root        : INFO     Epoch: 9, Batch: 160, Loss: 0.0810\n",
            "root        : INFO     Epoch: 9, Batch: 180, Loss: 0.0390\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1108\n",
            "root        : INFO     Epoch: 9, Batch: 220, Loss: 0.0794\n",
            "root        : INFO     Epoch: 9, Batch: 240, Loss: 0.1127\n",
            "root        : INFO     Epoch: 9, Batch: 260, Loss: 0.0970\n",
            "root        : INFO     Epoch: 9, Batch: 280, Loss: 0.1579\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0512\n",
            "root        : INFO     Epoch: 9, Batch: 320, Loss: 0.1043\n",
            "root        : INFO     Epoch: 9, Batch: 340, Loss: 0.0551\n",
            "root        : INFO     Epoch: 9, Batch: 360, Loss: 0.0806\n",
            "root        : INFO     Epoch: 9, Batch: 380, Loss: 0.1318\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.1127\n",
            "root        : INFO     Epoch: 9, Batch: 420, Loss: 0.0677\n",
            "root        : INFO     Epoch: 9, Batch: 440, Loss: 0.0662\n",
            "root        : INFO     Epoch: 9, Batch: 460, Loss: 0.1637\n",
            "root        : INFO     Epoch: 9, Batch: 480, Loss: 0.0648\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0762\n",
            "root        : INFO     Epoch: 9, Batch: 520, Loss: 0.0630\n",
            "root        : INFO     Epoch: 9, Batch: 540, Loss: 0.0570\n",
            "root        : INFO     Epoch: 9, Batch: 560, Loss: 0.0695\n",
            "root        : INFO     Epoch: 9, Batch: 580, Loss: 0.0476\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0840\n",
            "root        : INFO     Epoch: 9, Batch: 620, Loss: 0.0651\n",
            "root        : INFO     Epoch: 9, Batch: 640, Loss: 0.0842\n",
            "root        : INFO     Epoch: 9, Batch: 660, Loss: 0.0506\n",
            "root        : INFO     Epoch: 9, Batch: 680, Loss: 0.0595\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0493\n",
            "root        : INFO     Epoch: 9, Batch: 720, Loss: 0.0685\n",
            "root        : INFO     Epoch: 9, Batch: 740, Loss: 0.0488\n",
            "root        : INFO     Epoch: 9, Batch: 760, Loss: 0.0674\n",
            "root        : INFO     Epoch: 9, Batch: 780, Loss: 0.0965\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0621\n",
            "root        : INFO     Epoch: 9, Batch: 820, Loss: 0.0579\n",
            "root        : INFO     Epoch: 9, Batch: 840, Loss: 0.0544\n",
            "root        : INFO     Epoch: 9, Batch: 860, Loss: 0.0362\n",
            "root        : INFO     Epoch: 9, Batch: 880, Loss: 0.0992\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0469\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0619\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0621\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0820\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0929\n",
            "root        : INFO     Epoch: 10, Batch: 120, Loss: 0.0733\n",
            "root        : INFO     Epoch: 10, Batch: 140, Loss: 0.0641\n",
            "root        : INFO     Epoch: 10, Batch: 160, Loss: 0.0715\n",
            "root        : INFO     Epoch: 10, Batch: 180, Loss: 0.0700\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0541\n",
            "root        : INFO     Epoch: 10, Batch: 220, Loss: 0.0991\n",
            "root        : INFO     Epoch: 10, Batch: 240, Loss: 0.0849\n",
            "root        : INFO     Epoch: 10, Batch: 260, Loss: 0.0717\n",
            "root        : INFO     Epoch: 10, Batch: 280, Loss: 0.0849\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0516\n",
            "root        : INFO     Epoch: 10, Batch: 320, Loss: 0.0609\n",
            "root        : INFO     Epoch: 10, Batch: 340, Loss: 0.0641\n",
            "root        : INFO     Epoch: 10, Batch: 360, Loss: 0.0765\n",
            "root        : INFO     Epoch: 10, Batch: 380, Loss: 0.0739\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0932\n",
            "root        : INFO     Epoch: 10, Batch: 420, Loss: 0.0913\n",
            "root        : INFO     Epoch: 10, Batch: 440, Loss: 0.0897\n",
            "root        : INFO     Epoch: 10, Batch: 460, Loss: 0.1071\n",
            "root        : INFO     Epoch: 10, Batch: 480, Loss: 0.0830\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0470\n",
            "root        : INFO     Epoch: 10, Batch: 520, Loss: 0.0871\n",
            "root        : INFO     Epoch: 10, Batch: 540, Loss: 0.0822\n",
            "root        : INFO     Epoch: 10, Batch: 560, Loss: 0.0666\n",
            "root        : INFO     Epoch: 10, Batch: 580, Loss: 0.0787\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0327\n",
            "root        : INFO     Epoch: 10, Batch: 620, Loss: 0.0946\n",
            "root        : INFO     Epoch: 10, Batch: 640, Loss: 0.0767\n",
            "root        : INFO     Epoch: 10, Batch: 660, Loss: 0.0709\n",
            "root        : INFO     Epoch: 10, Batch: 680, Loss: 0.1065\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0740\n",
            "root        : INFO     Epoch: 10, Batch: 720, Loss: 0.0823\n",
            "root        : INFO     Epoch: 10, Batch: 740, Loss: 0.0580\n",
            "root        : INFO     Epoch: 10, Batch: 760, Loss: 0.0919\n",
            "root        : INFO     Epoch: 10, Batch: 780, Loss: 0.0663\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0589\n",
            "root        : INFO     Epoch: 10, Batch: 820, Loss: 0.0967\n",
            "root        : INFO     Epoch: 10, Batch: 840, Loss: 0.0651\n",
            "root        : INFO     Epoch: 10, Batch: 860, Loss: 0.1171\n",
            "root        : INFO     Epoch: 10, Batch: 880, Loss: 0.0616\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0754\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0528\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0721\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0965\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.1043\n",
            "root        : INFO     Epoch: 11, Batch: 120, Loss: 0.0692\n",
            "root        : INFO     Epoch: 11, Batch: 140, Loss: 0.0658\n",
            "root        : INFO     Epoch: 11, Batch: 160, Loss: 0.1136\n",
            "root        : INFO     Epoch: 11, Batch: 180, Loss: 0.0791\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0493\n",
            "root        : INFO     Epoch: 11, Batch: 220, Loss: 0.0506\n",
            "root        : INFO     Epoch: 11, Batch: 240, Loss: 0.0641\n",
            "root        : INFO     Epoch: 11, Batch: 260, Loss: 0.0691\n",
            "root        : INFO     Epoch: 11, Batch: 280, Loss: 0.0596\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0380\n",
            "root        : INFO     Epoch: 11, Batch: 320, Loss: 0.0401\n",
            "root        : INFO     Epoch: 11, Batch: 340, Loss: 0.0634\n",
            "root        : INFO     Epoch: 11, Batch: 360, Loss: 0.1011\n",
            "root        : INFO     Epoch: 11, Batch: 380, Loss: 0.0836\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0716\n",
            "root        : INFO     Epoch: 11, Batch: 420, Loss: 0.0600\n",
            "root        : INFO     Epoch: 11, Batch: 440, Loss: 0.0569\n",
            "root        : INFO     Epoch: 11, Batch: 460, Loss: 0.0722\n",
            "root        : INFO     Epoch: 11, Batch: 480, Loss: 0.0838\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.1176\n",
            "root        : INFO     Epoch: 11, Batch: 520, Loss: 0.0848\n",
            "root        : INFO     Epoch: 11, Batch: 540, Loss: 0.0569\n",
            "root        : INFO     Epoch: 11, Batch: 560, Loss: 0.0700\n",
            "root        : INFO     Epoch: 11, Batch: 580, Loss: 0.0714\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0760\n",
            "root        : INFO     Epoch: 11, Batch: 620, Loss: 0.0859\n",
            "root        : INFO     Epoch: 11, Batch: 640, Loss: 0.0811\n",
            "root        : INFO     Epoch: 11, Batch: 660, Loss: 0.0238\n",
            "root        : INFO     Epoch: 11, Batch: 680, Loss: 0.0569\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0627\n",
            "root        : INFO     Epoch: 11, Batch: 720, Loss: 0.0734\n",
            "root        : INFO     Epoch: 11, Batch: 740, Loss: 0.0581\n",
            "root        : INFO     Epoch: 11, Batch: 760, Loss: 0.0707\n",
            "root        : INFO     Epoch: 11, Batch: 780, Loss: 0.1022\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0637\n",
            "root        : INFO     Epoch: 11, Batch: 820, Loss: 0.0481\n",
            "root        : INFO     Epoch: 11, Batch: 840, Loss: 0.0633\n",
            "root        : INFO     Epoch: 11, Batch: 860, Loss: 0.0792\n",
            "root        : INFO     Epoch: 11, Batch: 880, Loss: 0.0823\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0632\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0759\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0566\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.1489\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0838\n",
            "root        : INFO     Epoch: 12, Batch: 120, Loss: 0.0831\n",
            "root        : INFO     Epoch: 12, Batch: 140, Loss: 0.0776\n",
            "root        : INFO     Epoch: 12, Batch: 160, Loss: 0.0726\n",
            "root        : INFO     Epoch: 12, Batch: 180, Loss: 0.1017\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.1229\n",
            "root        : INFO     Epoch: 12, Batch: 220, Loss: 0.0691\n",
            "root        : INFO     Epoch: 12, Batch: 240, Loss: 0.0666\n",
            "root        : INFO     Epoch: 12, Batch: 260, Loss: 0.1230\n",
            "root        : INFO     Epoch: 12, Batch: 280, Loss: 0.0659\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0901\n",
            "root        : INFO     Epoch: 12, Batch: 320, Loss: 0.0923\n",
            "root        : INFO     Epoch: 12, Batch: 340, Loss: 0.1130\n",
            "root        : INFO     Epoch: 12, Batch: 360, Loss: 0.1609\n",
            "root        : INFO     Epoch: 12, Batch: 380, Loss: 0.0800\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0595\n",
            "root        : INFO     Epoch: 12, Batch: 420, Loss: 0.0428\n",
            "root        : INFO     Epoch: 12, Batch: 440, Loss: 0.0903\n",
            "root        : INFO     Epoch: 12, Batch: 460, Loss: 0.0755\n",
            "root        : INFO     Epoch: 12, Batch: 480, Loss: 0.0745\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.1211\n",
            "root        : INFO     Epoch: 12, Batch: 520, Loss: 0.1306\n",
            "root        : INFO     Epoch: 12, Batch: 540, Loss: 0.0955\n",
            "root        : INFO     Epoch: 12, Batch: 560, Loss: 0.0805\n",
            "root        : INFO     Epoch: 12, Batch: 580, Loss: 0.0544\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0713\n",
            "root        : INFO     Epoch: 12, Batch: 620, Loss: 0.0730\n",
            "root        : INFO     Epoch: 12, Batch: 640, Loss: 0.0404\n",
            "root        : INFO     Epoch: 12, Batch: 660, Loss: 0.0659\n",
            "root        : INFO     Epoch: 12, Batch: 680, Loss: 0.1082\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0672\n",
            "root        : INFO     Epoch: 12, Batch: 720, Loss: 0.1296\n",
            "root        : INFO     Epoch: 12, Batch: 740, Loss: 0.0727\n",
            "root        : INFO     Epoch: 12, Batch: 760, Loss: 0.0605\n",
            "root        : INFO     Epoch: 12, Batch: 780, Loss: 0.0715\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0550\n",
            "root        : INFO     Epoch: 12, Batch: 820, Loss: 0.0474\n",
            "root        : INFO     Epoch: 12, Batch: 840, Loss: 0.1174\n",
            "root        : INFO     Epoch: 12, Batch: 860, Loss: 0.0554\n",
            "root        : INFO     Epoch: 12, Batch: 880, Loss: 0.0431\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.1064\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0519\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0855\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.1286\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0838\n",
            "root        : INFO     Epoch: 13, Batch: 120, Loss: 0.0698\n",
            "root        : INFO     Epoch: 13, Batch: 140, Loss: 0.0917\n",
            "root        : INFO     Epoch: 13, Batch: 160, Loss: 0.1002\n",
            "root        : INFO     Epoch: 13, Batch: 180, Loss: 0.0605\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0656\n",
            "root        : INFO     Epoch: 13, Batch: 220, Loss: 0.1221\n",
            "root        : INFO     Epoch: 13, Batch: 240, Loss: 0.0749\n",
            "root        : INFO     Epoch: 13, Batch: 260, Loss: 0.0629\n",
            "root        : INFO     Epoch: 13, Batch: 280, Loss: 0.0605\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0381\n",
            "root        : INFO     Epoch: 13, Batch: 320, Loss: 0.1105\n",
            "root        : INFO     Epoch: 13, Batch: 340, Loss: 0.0792\n",
            "root        : INFO     Epoch: 13, Batch: 360, Loss: 0.0665\n",
            "root        : INFO     Epoch: 13, Batch: 380, Loss: 0.0556\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.1190\n",
            "root        : INFO     Epoch: 13, Batch: 420, Loss: 0.0575\n",
            "root        : INFO     Epoch: 13, Batch: 440, Loss: 0.0836\n",
            "root        : INFO     Epoch: 13, Batch: 460, Loss: 0.0603\n",
            "root        : INFO     Epoch: 13, Batch: 480, Loss: 0.0852\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0755\n",
            "root        : INFO     Epoch: 13, Batch: 520, Loss: 0.0650\n",
            "root        : INFO     Epoch: 13, Batch: 540, Loss: 0.0812\n",
            "root        : INFO     Epoch: 13, Batch: 560, Loss: 0.0787\n",
            "root        : INFO     Epoch: 13, Batch: 580, Loss: 0.1013\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.1227\n",
            "root        : INFO     Epoch: 13, Batch: 620, Loss: 0.1343\n",
            "root        : INFO     Epoch: 13, Batch: 640, Loss: 0.0562\n",
            "root        : INFO     Epoch: 13, Batch: 660, Loss: 0.0773\n",
            "root        : INFO     Epoch: 13, Batch: 680, Loss: 0.0579\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0839\n",
            "root        : INFO     Epoch: 13, Batch: 720, Loss: 0.0653\n",
            "root        : INFO     Epoch: 13, Batch: 740, Loss: 0.1196\n",
            "root        : INFO     Epoch: 13, Batch: 760, Loss: 0.0639\n",
            "root        : INFO     Epoch: 13, Batch: 780, Loss: 0.1179\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0873\n",
            "root        : INFO     Epoch: 13, Batch: 820, Loss: 0.0852\n",
            "root        : INFO     Epoch: 13, Batch: 840, Loss: 0.0888\n",
            "root        : INFO     Epoch: 13, Batch: 860, Loss: 0.0769\n",
            "root        : INFO     Epoch: 13, Batch: 880, Loss: 0.0505\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0500\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0550\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0281\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0493\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0623\n",
            "root        : INFO     Epoch: 14, Batch: 120, Loss: 0.0718\n",
            "root        : INFO     Epoch: 14, Batch: 140, Loss: 0.0557\n",
            "root        : INFO     Epoch: 14, Batch: 160, Loss: 0.0524\n",
            "root        : INFO     Epoch: 14, Batch: 180, Loss: 0.1046\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0605\n",
            "root        : INFO     Epoch: 14, Batch: 220, Loss: 0.0489\n",
            "root        : INFO     Epoch: 14, Batch: 240, Loss: 0.0994\n",
            "root        : INFO     Epoch: 14, Batch: 260, Loss: 0.0625\n",
            "root        : INFO     Epoch: 14, Batch: 280, Loss: 0.1010\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0628\n",
            "root        : INFO     Epoch: 14, Batch: 320, Loss: 0.0536\n",
            "root        : INFO     Epoch: 14, Batch: 340, Loss: 0.0305\n",
            "root        : INFO     Epoch: 14, Batch: 360, Loss: 0.0773\n",
            "root        : INFO     Epoch: 14, Batch: 380, Loss: 0.1122\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0601\n",
            "root        : INFO     Epoch: 14, Batch: 420, Loss: 0.0644\n",
            "root        : INFO     Epoch: 14, Batch: 440, Loss: 0.0700\n",
            "root        : INFO     Epoch: 14, Batch: 460, Loss: 0.0800\n",
            "root        : INFO     Epoch: 14, Batch: 480, Loss: 0.0525\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0521\n",
            "root        : INFO     Epoch: 14, Batch: 520, Loss: 0.0693\n",
            "root        : INFO     Epoch: 14, Batch: 540, Loss: 0.0753\n",
            "root        : INFO     Epoch: 14, Batch: 560, Loss: 0.0964\n",
            "root        : INFO     Epoch: 14, Batch: 580, Loss: 0.0568\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.1057\n",
            "root        : INFO     Epoch: 14, Batch: 620, Loss: 0.0655\n",
            "root        : INFO     Epoch: 14, Batch: 640, Loss: 0.0710\n",
            "root        : INFO     Epoch: 14, Batch: 660, Loss: 0.0678\n",
            "root        : INFO     Epoch: 14, Batch: 680, Loss: 0.0532\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0855\n",
            "root        : INFO     Epoch: 14, Batch: 720, Loss: 0.0716\n",
            "root        : INFO     Epoch: 14, Batch: 740, Loss: 0.0898\n",
            "root        : INFO     Epoch: 14, Batch: 760, Loss: 0.0957\n",
            "root        : INFO     Epoch: 14, Batch: 780, Loss: 0.0827\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.1029\n",
            "root        : INFO     Epoch: 14, Batch: 820, Loss: 0.0944\n",
            "root        : INFO     Epoch: 14, Batch: 840, Loss: 0.0687\n",
            "root        : INFO     Epoch: 14, Batch: 860, Loss: 0.1300\n",
            "root        : INFO     Epoch: 14, Batch: 880, Loss: 0.0516\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0819\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0724\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0787\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0650\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0630\n",
            "root        : INFO     Epoch: 15, Batch: 120, Loss: 0.1002\n",
            "root        : INFO     Epoch: 15, Batch: 140, Loss: 0.0598\n",
            "root        : INFO     Epoch: 15, Batch: 160, Loss: 0.1086\n",
            "root        : INFO     Epoch: 15, Batch: 180, Loss: 0.0476\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0804\n",
            "root        : INFO     Epoch: 15, Batch: 220, Loss: 0.0586\n",
            "root        : INFO     Epoch: 15, Batch: 240, Loss: 0.0964\n",
            "root        : INFO     Epoch: 15, Batch: 260, Loss: 0.0787\n",
            "root        : INFO     Epoch: 15, Batch: 280, Loss: 0.0749\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0355\n",
            "root        : INFO     Epoch: 15, Batch: 320, Loss: 0.0573\n",
            "root        : INFO     Epoch: 15, Batch: 340, Loss: 0.0512\n",
            "root        : INFO     Epoch: 15, Batch: 360, Loss: 0.0608\n",
            "root        : INFO     Epoch: 15, Batch: 380, Loss: 0.0772\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0970\n",
            "root        : INFO     Epoch: 15, Batch: 420, Loss: 0.0707\n",
            "root        : INFO     Epoch: 15, Batch: 440, Loss: 0.0535\n",
            "root        : INFO     Epoch: 15, Batch: 460, Loss: 0.0372\n",
            "root        : INFO     Epoch: 15, Batch: 480, Loss: 0.0548\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0770\n",
            "root        : INFO     Epoch: 15, Batch: 520, Loss: 0.0926\n",
            "root        : INFO     Epoch: 15, Batch: 540, Loss: 0.0690\n",
            "root        : INFO     Epoch: 15, Batch: 560, Loss: 0.0604\n",
            "root        : INFO     Epoch: 15, Batch: 580, Loss: 0.0451\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0906\n",
            "root        : INFO     Epoch: 15, Batch: 620, Loss: 0.0972\n",
            "root        : INFO     Epoch: 15, Batch: 640, Loss: 0.0527\n",
            "root        : INFO     Epoch: 15, Batch: 660, Loss: 0.0632\n",
            "root        : INFO     Epoch: 15, Batch: 680, Loss: 0.1058\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0500\n",
            "root        : INFO     Epoch: 15, Batch: 720, Loss: 0.0330\n",
            "root        : INFO     Epoch: 15, Batch: 740, Loss: 0.0682\n",
            "root        : INFO     Epoch: 15, Batch: 760, Loss: 0.0507\n",
            "root        : INFO     Epoch: 15, Batch: 780, Loss: 0.0732\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0460\n",
            "root        : INFO     Epoch: 15, Batch: 820, Loss: 0.0897\n",
            "root        : INFO     Epoch: 15, Batch: 840, Loss: 0.1062\n",
            "root        : INFO     Epoch: 15, Batch: 860, Loss: 0.0660\n",
            "root        : INFO     Epoch: 15, Batch: 880, Loss: 0.0519\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0812\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0549\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0630\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0528\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0699\n",
            "root        : INFO     Epoch: 16, Batch: 120, Loss: 0.0760\n",
            "root        : INFO     Epoch: 16, Batch: 140, Loss: 0.0815\n",
            "root        : INFO     Epoch: 16, Batch: 160, Loss: 0.0456\n",
            "root        : INFO     Epoch: 16, Batch: 180, Loss: 0.0362\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.1317\n",
            "root        : INFO     Epoch: 16, Batch: 220, Loss: 0.0633\n",
            "root        : INFO     Epoch: 16, Batch: 240, Loss: 0.0903\n",
            "root        : INFO     Epoch: 16, Batch: 260, Loss: 0.0325\n",
            "root        : INFO     Epoch: 16, Batch: 280, Loss: 0.0851\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.1170\n",
            "root        : INFO     Epoch: 16, Batch: 320, Loss: 0.0699\n",
            "root        : INFO     Epoch: 16, Batch: 340, Loss: 0.1411\n",
            "root        : INFO     Epoch: 16, Batch: 360, Loss: 0.0568\n",
            "root        : INFO     Epoch: 16, Batch: 380, Loss: 0.0761\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0788\n",
            "root        : INFO     Epoch: 16, Batch: 420, Loss: 0.0266\n",
            "root        : INFO     Epoch: 16, Batch: 440, Loss: 0.0417\n",
            "root        : INFO     Epoch: 16, Batch: 460, Loss: 0.0576\n",
            "root        : INFO     Epoch: 16, Batch: 480, Loss: 0.1210\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0982\n",
            "root        : INFO     Epoch: 16, Batch: 520, Loss: 0.1313\n",
            "root        : INFO     Epoch: 16, Batch: 540, Loss: 0.0671\n",
            "root        : INFO     Epoch: 16, Batch: 560, Loss: 0.0681\n",
            "root        : INFO     Epoch: 16, Batch: 580, Loss: 0.0974\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0481\n",
            "root        : INFO     Epoch: 16, Batch: 620, Loss: 0.0398\n",
            "root        : INFO     Epoch: 16, Batch: 640, Loss: 0.1155\n",
            "root        : INFO     Epoch: 16, Batch: 660, Loss: 0.0908\n",
            "root        : INFO     Epoch: 16, Batch: 680, Loss: 0.0573\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0651\n",
            "root        : INFO     Epoch: 16, Batch: 720, Loss: 0.0448\n",
            "root        : INFO     Epoch: 16, Batch: 740, Loss: 0.0705\n",
            "root        : INFO     Epoch: 16, Batch: 760, Loss: 0.0812\n",
            "root        : INFO     Epoch: 16, Batch: 780, Loss: 0.0568\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0750\n",
            "root        : INFO     Epoch: 16, Batch: 820, Loss: 0.1084\n",
            "root        : INFO     Epoch: 16, Batch: 840, Loss: 0.0793\n",
            "root        : INFO     Epoch: 16, Batch: 860, Loss: 0.0382\n",
            "root        : INFO     Epoch: 16, Batch: 880, Loss: 0.0744\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.1108\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0678\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.1009\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0549\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0665\n",
            "root        : INFO     Epoch: 17, Batch: 120, Loss: 0.0848\n",
            "root        : INFO     Epoch: 17, Batch: 140, Loss: 0.1050\n",
            "root        : INFO     Epoch: 17, Batch: 160, Loss: 0.0992\n",
            "root        : INFO     Epoch: 17, Batch: 180, Loss: 0.0901\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0729\n",
            "root        : INFO     Epoch: 17, Batch: 220, Loss: 0.0816\n",
            "root        : INFO     Epoch: 17, Batch: 240, Loss: 0.0837\n",
            "root        : INFO     Epoch: 17, Batch: 260, Loss: 0.0774\n",
            "root        : INFO     Epoch: 17, Batch: 280, Loss: 0.0667\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0481\n",
            "root        : INFO     Epoch: 17, Batch: 320, Loss: 0.0480\n",
            "root        : INFO     Epoch: 17, Batch: 340, Loss: 0.0587\n",
            "root        : INFO     Epoch: 17, Batch: 360, Loss: 0.0532\n",
            "root        : INFO     Epoch: 17, Batch: 380, Loss: 0.1187\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0717\n",
            "root        : INFO     Epoch: 17, Batch: 420, Loss: 0.0885\n",
            "root        : INFO     Epoch: 17, Batch: 440, Loss: 0.0925\n",
            "root        : INFO     Epoch: 17, Batch: 460, Loss: 0.0481\n",
            "root        : INFO     Epoch: 17, Batch: 480, Loss: 0.1117\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0959\n",
            "root        : INFO     Epoch: 17, Batch: 520, Loss: 0.0698\n",
            "root        : INFO     Epoch: 17, Batch: 540, Loss: 0.0768\n",
            "root        : INFO     Epoch: 17, Batch: 560, Loss: 0.0602\n",
            "root        : INFO     Epoch: 17, Batch: 580, Loss: 0.0821\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0696\n",
            "root        : INFO     Epoch: 17, Batch: 620, Loss: 0.0596\n",
            "root        : INFO     Epoch: 17, Batch: 640, Loss: 0.0789\n",
            "root        : INFO     Epoch: 17, Batch: 660, Loss: 0.0469\n",
            "root        : INFO     Epoch: 17, Batch: 680, Loss: 0.0430\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.1004\n",
            "root        : INFO     Epoch: 17, Batch: 720, Loss: 0.0967\n",
            "root        : INFO     Epoch: 17, Batch: 740, Loss: 0.0931\n",
            "root        : INFO     Epoch: 17, Batch: 760, Loss: 0.0631\n",
            "root        : INFO     Epoch: 17, Batch: 780, Loss: 0.0438\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0892\n",
            "root        : INFO     Epoch: 17, Batch: 820, Loss: 0.1015\n",
            "root        : INFO     Epoch: 17, Batch: 840, Loss: 0.0686\n",
            "root        : INFO     Epoch: 17, Batch: 860, Loss: 0.0936\n",
            "root        : INFO     Epoch: 17, Batch: 880, Loss: 0.0786\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.1556\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0985\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0814\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0603\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0397\n",
            "root        : INFO     Epoch: 18, Batch: 120, Loss: 0.0587\n",
            "root        : INFO     Epoch: 18, Batch: 140, Loss: 0.1046\n",
            "root        : INFO     Epoch: 18, Batch: 160, Loss: 0.0665\n",
            "root        : INFO     Epoch: 18, Batch: 180, Loss: 0.0520\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.1069\n",
            "root        : INFO     Epoch: 18, Batch: 220, Loss: 0.1007\n",
            "root        : INFO     Epoch: 18, Batch: 240, Loss: 0.0434\n",
            "root        : INFO     Epoch: 18, Batch: 260, Loss: 0.0953\n",
            "root        : INFO     Epoch: 18, Batch: 280, Loss: 0.0636\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.1064\n",
            "root        : INFO     Epoch: 18, Batch: 320, Loss: 0.0744\n",
            "root        : INFO     Epoch: 18, Batch: 340, Loss: 0.0964\n",
            "root        : INFO     Epoch: 18, Batch: 360, Loss: 0.0429\n",
            "root        : INFO     Epoch: 18, Batch: 380, Loss: 0.1027\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0452\n",
            "root        : INFO     Epoch: 18, Batch: 420, Loss: 0.0629\n",
            "root        : INFO     Epoch: 18, Batch: 440, Loss: 0.0698\n",
            "root        : INFO     Epoch: 18, Batch: 460, Loss: 0.0721\n",
            "root        : INFO     Epoch: 18, Batch: 480, Loss: 0.0376\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0394\n",
            "root        : INFO     Epoch: 18, Batch: 520, Loss: 0.0871\n",
            "root        : INFO     Epoch: 18, Batch: 540, Loss: 0.0700\n",
            "root        : INFO     Epoch: 18, Batch: 560, Loss: 0.1020\n",
            "root        : INFO     Epoch: 18, Batch: 580, Loss: 0.0681\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0543\n",
            "root        : INFO     Epoch: 18, Batch: 620, Loss: 0.0477\n",
            "root        : INFO     Epoch: 18, Batch: 640, Loss: 0.0791\n",
            "root        : INFO     Epoch: 18, Batch: 660, Loss: 0.0391\n",
            "root        : INFO     Epoch: 18, Batch: 680, Loss: 0.0472\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.0856\n",
            "root        : INFO     Epoch: 18, Batch: 720, Loss: 0.0418\n",
            "root        : INFO     Epoch: 18, Batch: 740, Loss: 0.0613\n",
            "root        : INFO     Epoch: 18, Batch: 760, Loss: 0.0458\n",
            "root        : INFO     Epoch: 18, Batch: 780, Loss: 0.0983\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0919\n",
            "root        : INFO     Epoch: 18, Batch: 820, Loss: 0.0547\n",
            "root        : INFO     Epoch: 18, Batch: 840, Loss: 0.0773\n",
            "root        : INFO     Epoch: 18, Batch: 860, Loss: 0.0957\n",
            "root        : INFO     Epoch: 18, Batch: 880, Loss: 0.0589\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0756\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0509\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0500\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0784\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0589\n",
            "root        : INFO     Epoch: 19, Batch: 120, Loss: 0.1350\n",
            "root        : INFO     Epoch: 19, Batch: 140, Loss: 0.0592\n",
            "root        : INFO     Epoch: 19, Batch: 160, Loss: 0.0811\n",
            "root        : INFO     Epoch: 19, Batch: 180, Loss: 0.0451\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0533\n",
            "root        : INFO     Epoch: 19, Batch: 220, Loss: 0.0538\n",
            "root        : INFO     Epoch: 19, Batch: 240, Loss: 0.0399\n",
            "root        : INFO     Epoch: 19, Batch: 260, Loss: 0.0487\n",
            "root        : INFO     Epoch: 19, Batch: 280, Loss: 0.1122\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0662\n",
            "root        : INFO     Epoch: 19, Batch: 320, Loss: 0.0461\n",
            "root        : INFO     Epoch: 19, Batch: 340, Loss: 0.0752\n",
            "root        : INFO     Epoch: 19, Batch: 360, Loss: 0.0653\n",
            "root        : INFO     Epoch: 19, Batch: 380, Loss: 0.0938\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0522\n",
            "root        : INFO     Epoch: 19, Batch: 420, Loss: 0.0791\n",
            "root        : INFO     Epoch: 19, Batch: 440, Loss: 0.0747\n",
            "root        : INFO     Epoch: 19, Batch: 460, Loss: 0.0691\n",
            "root        : INFO     Epoch: 19, Batch: 480, Loss: 0.0848\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0856\n",
            "root        : INFO     Epoch: 19, Batch: 520, Loss: 0.0915\n",
            "root        : INFO     Epoch: 19, Batch: 540, Loss: 0.0748\n",
            "root        : INFO     Epoch: 19, Batch: 560, Loss: 0.1031\n",
            "root        : INFO     Epoch: 19, Batch: 580, Loss: 0.0766\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.0896\n",
            "root        : INFO     Epoch: 19, Batch: 620, Loss: 0.0364\n",
            "root        : INFO     Epoch: 19, Batch: 640, Loss: 0.0639\n",
            "root        : INFO     Epoch: 19, Batch: 660, Loss: 0.0495\n",
            "root        : INFO     Epoch: 19, Batch: 680, Loss: 0.0645\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0855\n",
            "root        : INFO     Epoch: 19, Batch: 720, Loss: 0.0698\n",
            "root        : INFO     Epoch: 19, Batch: 740, Loss: 0.0765\n",
            "root        : INFO     Epoch: 19, Batch: 760, Loss: 0.0762\n",
            "root        : INFO     Epoch: 19, Batch: 780, Loss: 0.0410\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0441\n",
            "root        : INFO     Epoch: 19, Batch: 820, Loss: 0.0827\n",
            "root        : INFO     Epoch: 19, Batch: 840, Loss: 0.0833\n",
            "root        : INFO     Epoch: 19, Batch: 860, Loss: 0.0678\n",
            "root        : INFO     Epoch: 19, Batch: 880, Loss: 0.1342\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0929\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.1042\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0916\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.1309\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0789\n",
            "root        : INFO     Epoch: 20, Batch: 120, Loss: 0.0612\n",
            "root        : INFO     Epoch: 20, Batch: 140, Loss: 0.0669\n",
            "root        : INFO     Epoch: 20, Batch: 160, Loss: 0.0599\n",
            "root        : INFO     Epoch: 20, Batch: 180, Loss: 0.0681\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0700\n",
            "root        : INFO     Epoch: 20, Batch: 220, Loss: 0.0808\n",
            "root        : INFO     Epoch: 20, Batch: 240, Loss: 0.0760\n",
            "root        : INFO     Epoch: 20, Batch: 260, Loss: 0.0585\n",
            "root        : INFO     Epoch: 20, Batch: 280, Loss: 0.0529\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.0590\n",
            "root        : INFO     Epoch: 20, Batch: 320, Loss: 0.1030\n",
            "root        : INFO     Epoch: 20, Batch: 340, Loss: 0.0932\n",
            "root        : INFO     Epoch: 20, Batch: 360, Loss: 0.0586\n",
            "root        : INFO     Epoch: 20, Batch: 380, Loss: 0.0770\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0690\n",
            "root        : INFO     Epoch: 20, Batch: 420, Loss: 0.0810\n",
            "root        : INFO     Epoch: 20, Batch: 440, Loss: 0.0868\n",
            "root        : INFO     Epoch: 20, Batch: 460, Loss: 0.0666\n",
            "root        : INFO     Epoch: 20, Batch: 480, Loss: 0.0706\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.1016\n",
            "root        : INFO     Epoch: 20, Batch: 520, Loss: 0.0772\n",
            "root        : INFO     Epoch: 20, Batch: 540, Loss: 0.0382\n",
            "root        : INFO     Epoch: 20, Batch: 560, Loss: 0.0678\n",
            "root        : INFO     Epoch: 20, Batch: 580, Loss: 0.0475\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0579\n",
            "root        : INFO     Epoch: 20, Batch: 620, Loss: 0.0991\n",
            "root        : INFO     Epoch: 20, Batch: 640, Loss: 0.0954\n",
            "root        : INFO     Epoch: 20, Batch: 660, Loss: 0.0342\n",
            "root        : INFO     Epoch: 20, Batch: 680, Loss: 0.0804\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.0682\n",
            "root        : INFO     Epoch: 20, Batch: 720, Loss: 0.0609\n",
            "root        : INFO     Epoch: 20, Batch: 740, Loss: 0.0703\n",
            "root        : INFO     Epoch: 20, Batch: 760, Loss: 0.0661\n",
            "root        : INFO     Epoch: 20, Batch: 780, Loss: 0.0470\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.1058\n",
            "root        : INFO     Epoch: 20, Batch: 820, Loss: 0.1211\n",
            "root        : INFO     Epoch: 20, Batch: 840, Loss: 0.0859\n",
            "root        : INFO     Epoch: 20, Batch: 860, Loss: 0.0536\n",
            "root        : INFO     Epoch: 20, Batch: 880, Loss: 0.0600\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0515\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0655\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0647\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0852\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0601\n",
            "root        : INFO     Epoch: 21, Batch: 120, Loss: 0.0621\n",
            "root        : INFO     Epoch: 21, Batch: 140, Loss: 0.0799\n",
            "root        : INFO     Epoch: 21, Batch: 160, Loss: 0.0591\n",
            "root        : INFO     Epoch: 21, Batch: 180, Loss: 0.1176\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0388\n",
            "root        : INFO     Epoch: 21, Batch: 220, Loss: 0.0628\n",
            "root        : INFO     Epoch: 21, Batch: 240, Loss: 0.0890\n",
            "root        : INFO     Epoch: 21, Batch: 260, Loss: 0.0513\n",
            "root        : INFO     Epoch: 21, Batch: 280, Loss: 0.0630\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0641\n",
            "root        : INFO     Epoch: 21, Batch: 320, Loss: 0.0610\n",
            "root        : INFO     Epoch: 21, Batch: 340, Loss: 0.0561\n",
            "root        : INFO     Epoch: 21, Batch: 360, Loss: 0.1015\n",
            "root        : INFO     Epoch: 21, Batch: 380, Loss: 0.0610\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0551\n",
            "root        : INFO     Epoch: 21, Batch: 420, Loss: 0.0755\n",
            "root        : INFO     Epoch: 21, Batch: 440, Loss: 0.0674\n",
            "root        : INFO     Epoch: 21, Batch: 460, Loss: 0.0525\n",
            "root        : INFO     Epoch: 21, Batch: 480, Loss: 0.0751\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.1174\n",
            "root        : INFO     Epoch: 21, Batch: 520, Loss: 0.0691\n",
            "root        : INFO     Epoch: 21, Batch: 540, Loss: 0.0859\n",
            "root        : INFO     Epoch: 21, Batch: 560, Loss: 0.0422\n",
            "root        : INFO     Epoch: 21, Batch: 580, Loss: 0.0711\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.0570\n",
            "root        : INFO     Epoch: 21, Batch: 620, Loss: 0.0301\n",
            "root        : INFO     Epoch: 21, Batch: 640, Loss: 0.0517\n",
            "root        : INFO     Epoch: 21, Batch: 660, Loss: 0.0904\n",
            "root        : INFO     Epoch: 21, Batch: 680, Loss: 0.0667\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.0831\n",
            "root        : INFO     Epoch: 21, Batch: 720, Loss: 0.1065\n",
            "root        : INFO     Epoch: 21, Batch: 740, Loss: 0.1148\n",
            "root        : INFO     Epoch: 21, Batch: 760, Loss: 0.0447\n",
            "root        : INFO     Epoch: 21, Batch: 780, Loss: 0.1061\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0966\n",
            "root        : INFO     Epoch: 21, Batch: 820, Loss: 0.0563\n",
            "root        : INFO     Epoch: 21, Batch: 840, Loss: 0.0396\n",
            "root        : INFO     Epoch: 21, Batch: 860, Loss: 0.0644\n",
            "root        : INFO     Epoch: 21, Batch: 880, Loss: 0.0727\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0465\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0832\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.1025\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0834\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.0608\n",
            "root        : INFO     Epoch: 22, Batch: 120, Loss: 0.0671\n",
            "root        : INFO     Epoch: 22, Batch: 140, Loss: 0.0599\n",
            "root        : INFO     Epoch: 22, Batch: 160, Loss: 0.0522\n",
            "root        : INFO     Epoch: 22, Batch: 180, Loss: 0.0600\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0914\n",
            "root        : INFO     Epoch: 22, Batch: 220, Loss: 0.0554\n",
            "root        : INFO     Epoch: 22, Batch: 240, Loss: 0.0648\n",
            "root        : INFO     Epoch: 22, Batch: 260, Loss: 0.0704\n",
            "root        : INFO     Epoch: 22, Batch: 280, Loss: 0.0431\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0616\n",
            "root        : INFO     Epoch: 22, Batch: 320, Loss: 0.0515\n",
            "root        : INFO     Epoch: 22, Batch: 340, Loss: 0.1022\n",
            "root        : INFO     Epoch: 22, Batch: 360, Loss: 0.0854\n",
            "root        : INFO     Epoch: 22, Batch: 380, Loss: 0.0842\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0969\n",
            "root        : INFO     Epoch: 22, Batch: 420, Loss: 0.0932\n",
            "root        : INFO     Epoch: 22, Batch: 440, Loss: 0.0712\n",
            "root        : INFO     Epoch: 22, Batch: 460, Loss: 0.0779\n",
            "root        : INFO     Epoch: 22, Batch: 480, Loss: 0.0774\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0372\n",
            "root        : INFO     Epoch: 22, Batch: 520, Loss: 0.0889\n",
            "root        : INFO     Epoch: 22, Batch: 540, Loss: 0.1109\n",
            "root        : INFO     Epoch: 22, Batch: 560, Loss: 0.0769\n",
            "root        : INFO     Epoch: 22, Batch: 580, Loss: 0.0494\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.0730\n",
            "root        : INFO     Epoch: 22, Batch: 620, Loss: 0.0913\n",
            "root        : INFO     Epoch: 22, Batch: 640, Loss: 0.0493\n",
            "root        : INFO     Epoch: 22, Batch: 660, Loss: 0.0851\n",
            "root        : INFO     Epoch: 22, Batch: 680, Loss: 0.0940\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.0819\n",
            "root        : INFO     Epoch: 22, Batch: 720, Loss: 0.0852\n",
            "root        : INFO     Epoch: 22, Batch: 740, Loss: 0.0563\n",
            "root        : INFO     Epoch: 22, Batch: 760, Loss: 0.0704\n",
            "root        : INFO     Epoch: 22, Batch: 780, Loss: 0.0417\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.0753\n",
            "root        : INFO     Epoch: 22, Batch: 820, Loss: 0.1228\n",
            "root        : INFO     Epoch: 22, Batch: 840, Loss: 0.0868\n",
            "root        : INFO     Epoch: 22, Batch: 860, Loss: 0.0986\n",
            "root        : INFO     Epoch: 22, Batch: 880, Loss: 0.0844\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0329\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0668\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0845\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.1222\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0934\n",
            "root        : INFO     Epoch: 23, Batch: 120, Loss: 0.0763\n",
            "root        : INFO     Epoch: 23, Batch: 140, Loss: 0.0895\n",
            "root        : INFO     Epoch: 23, Batch: 160, Loss: 0.0771\n",
            "root        : INFO     Epoch: 23, Batch: 180, Loss: 0.0838\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0781\n",
            "root        : INFO     Epoch: 23, Batch: 220, Loss: 0.0657\n",
            "root        : INFO     Epoch: 23, Batch: 240, Loss: 0.1278\n",
            "root        : INFO     Epoch: 23, Batch: 260, Loss: 0.0810\n",
            "root        : INFO     Epoch: 23, Batch: 280, Loss: 0.0910\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0933\n",
            "root        : INFO     Epoch: 23, Batch: 320, Loss: 0.0665\n",
            "root        : INFO     Epoch: 23, Batch: 340, Loss: 0.0968\n",
            "root        : INFO     Epoch: 23, Batch: 360, Loss: 0.0901\n",
            "root        : INFO     Epoch: 23, Batch: 380, Loss: 0.0722\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0599\n",
            "root        : INFO     Epoch: 23, Batch: 420, Loss: 0.0934\n",
            "root        : INFO     Epoch: 23, Batch: 440, Loss: 0.0388\n",
            "root        : INFO     Epoch: 23, Batch: 460, Loss: 0.0517\n",
            "root        : INFO     Epoch: 23, Batch: 480, Loss: 0.0783\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0950\n",
            "root        : INFO     Epoch: 23, Batch: 520, Loss: 0.1403\n",
            "root        : INFO     Epoch: 23, Batch: 540, Loss: 0.0952\n",
            "root        : INFO     Epoch: 23, Batch: 560, Loss: 0.1014\n",
            "root        : INFO     Epoch: 23, Batch: 580, Loss: 0.1133\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0887\n",
            "root        : INFO     Epoch: 23, Batch: 620, Loss: 0.0913\n",
            "root        : INFO     Epoch: 23, Batch: 640, Loss: 0.0641\n",
            "root        : INFO     Epoch: 23, Batch: 660, Loss: 0.0438\n",
            "root        : INFO     Epoch: 23, Batch: 680, Loss: 0.0755\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.1044\n",
            "root        : INFO     Epoch: 23, Batch: 720, Loss: 0.1009\n",
            "root        : INFO     Epoch: 23, Batch: 740, Loss: 0.0632\n",
            "root        : INFO     Epoch: 23, Batch: 760, Loss: 0.1510\n",
            "root        : INFO     Epoch: 23, Batch: 780, Loss: 0.0984\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.1082\n",
            "root        : INFO     Epoch: 23, Batch: 820, Loss: 0.0570\n",
            "root        : INFO     Epoch: 23, Batch: 840, Loss: 0.0825\n",
            "root        : INFO     Epoch: 23, Batch: 860, Loss: 0.0612\n",
            "root        : INFO     Epoch: 23, Batch: 880, Loss: 0.1043\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0569\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0971\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0506\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0404\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0729\n",
            "root        : INFO     Epoch: 24, Batch: 120, Loss: 0.0880\n",
            "root        : INFO     Epoch: 24, Batch: 140, Loss: 0.0401\n",
            "root        : INFO     Epoch: 24, Batch: 160, Loss: 0.0885\n",
            "root        : INFO     Epoch: 24, Batch: 180, Loss: 0.0963\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0668\n",
            "root        : INFO     Epoch: 24, Batch: 220, Loss: 0.0844\n",
            "root        : INFO     Epoch: 24, Batch: 240, Loss: 0.0489\n",
            "root        : INFO     Epoch: 24, Batch: 260, Loss: 0.0491\n",
            "root        : INFO     Epoch: 24, Batch: 280, Loss: 0.1241\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0610\n",
            "root        : INFO     Epoch: 24, Batch: 320, Loss: 0.0502\n",
            "root        : INFO     Epoch: 24, Batch: 340, Loss: 0.0491\n",
            "root        : INFO     Epoch: 24, Batch: 360, Loss: 0.0644\n",
            "root        : INFO     Epoch: 24, Batch: 380, Loss: 0.0493\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0534\n",
            "root        : INFO     Epoch: 24, Batch: 420, Loss: 0.0507\n",
            "root        : INFO     Epoch: 24, Batch: 440, Loss: 0.0753\n",
            "root        : INFO     Epoch: 24, Batch: 460, Loss: 0.0533\n",
            "root        : INFO     Epoch: 24, Batch: 480, Loss: 0.0660\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.0964\n",
            "root        : INFO     Epoch: 24, Batch: 520, Loss: 0.0364\n",
            "root        : INFO     Epoch: 24, Batch: 540, Loss: 0.0801\n",
            "root        : INFO     Epoch: 24, Batch: 560, Loss: 0.0349\n",
            "root        : INFO     Epoch: 24, Batch: 580, Loss: 0.0624\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.0660\n",
            "root        : INFO     Epoch: 24, Batch: 620, Loss: 0.0432\n",
            "root        : INFO     Epoch: 24, Batch: 640, Loss: 0.0559\n",
            "root        : INFO     Epoch: 24, Batch: 660, Loss: 0.0492\n",
            "root        : INFO     Epoch: 24, Batch: 680, Loss: 0.0542\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.0355\n",
            "root        : INFO     Epoch: 24, Batch: 720, Loss: 0.0742\n",
            "root        : INFO     Epoch: 24, Batch: 740, Loss: 0.0752\n",
            "root        : INFO     Epoch: 24, Batch: 760, Loss: 0.0873\n",
            "root        : INFO     Epoch: 24, Batch: 780, Loss: 0.0283\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.0501\n",
            "root        : INFO     Epoch: 24, Batch: 820, Loss: 0.0893\n",
            "root        : INFO     Epoch: 24, Batch: 840, Loss: 0.1240\n",
            "root        : INFO     Epoch: 24, Batch: 860, Loss: 0.0460\n",
            "root        : INFO     Epoch: 24, Batch: 880, Loss: 0.0694\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0374\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0736\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0806\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0905\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0849\n",
            "root        : INFO     Epoch: 25, Batch: 120, Loss: 0.0689\n",
            "root        : INFO     Epoch: 25, Batch: 140, Loss: 0.0433\n",
            "root        : INFO     Epoch: 25, Batch: 160, Loss: 0.0424\n",
            "root        : INFO     Epoch: 25, Batch: 180, Loss: 0.1027\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0380\n",
            "root        : INFO     Epoch: 25, Batch: 220, Loss: 0.0455\n",
            "root        : INFO     Epoch: 25, Batch: 240, Loss: 0.0851\n",
            "root        : INFO     Epoch: 25, Batch: 260, Loss: 0.0752\n",
            "root        : INFO     Epoch: 25, Batch: 280, Loss: 0.0735\n",
            "root        : INFO     Epoch: 25, Batch: 300, Loss: 0.0755\n",
            "root        : INFO     Epoch: 25, Batch: 320, Loss: 0.0711\n",
            "root        : INFO     Epoch: 25, Batch: 340, Loss: 0.0444\n",
            "root        : INFO     Epoch: 25, Batch: 360, Loss: 0.0436\n",
            "root        : INFO     Epoch: 25, Batch: 380, Loss: 0.0617\n",
            "root        : INFO     Epoch: 25, Batch: 400, Loss: 0.0438\n",
            "root        : INFO     Epoch: 25, Batch: 420, Loss: 0.0637\n",
            "root        : INFO     Epoch: 25, Batch: 440, Loss: 0.0445\n",
            "root        : INFO     Epoch: 25, Batch: 460, Loss: 0.0555\n",
            "root        : INFO     Epoch: 25, Batch: 480, Loss: 0.0829\n",
            "root        : INFO     Epoch: 25, Batch: 500, Loss: 0.0726\n",
            "root        : INFO     Epoch: 25, Batch: 520, Loss: 0.0528\n",
            "root        : INFO     Epoch: 25, Batch: 540, Loss: 0.0868\n",
            "root        : INFO     Epoch: 25, Batch: 560, Loss: 0.0689\n",
            "root        : INFO     Epoch: 25, Batch: 580, Loss: 0.0607\n",
            "root        : INFO     Epoch: 25, Batch: 600, Loss: 0.0344\n",
            "root        : INFO     Epoch: 25, Batch: 620, Loss: 0.0725\n",
            "root        : INFO     Epoch: 25, Batch: 640, Loss: 0.0925\n",
            "root        : INFO     Epoch: 25, Batch: 660, Loss: 0.0541\n",
            "root        : INFO     Epoch: 25, Batch: 680, Loss: 0.0714\n",
            "root        : INFO     Epoch: 25, Batch: 700, Loss: 0.0659\n",
            "root        : INFO     Epoch: 25, Batch: 720, Loss: 0.0752\n",
            "root        : INFO     Epoch: 25, Batch: 740, Loss: 0.0890\n",
            "root        : INFO     Epoch: 25, Batch: 760, Loss: 0.0393\n",
            "root        : INFO     Epoch: 25, Batch: 780, Loss: 0.0700\n",
            "root        : INFO     Epoch: 25, Batch: 800, Loss: 0.0907\n",
            "root        : INFO     Epoch: 25, Batch: 820, Loss: 0.0707\n",
            "root        : INFO     Epoch: 25, Batch: 840, Loss: 0.0808\n",
            "root        : INFO     Epoch: 25, Batch: 860, Loss: 0.0701\n",
            "root        : INFO     Epoch: 25, Batch: 880, Loss: 0.0968\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0436\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0506\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0526\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0897\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0455\n",
            "root        : INFO     Epoch: 26, Batch: 120, Loss: 0.0362\n",
            "root        : INFO     Epoch: 26, Batch: 140, Loss: 0.0598\n",
            "root        : INFO     Epoch: 26, Batch: 160, Loss: 0.0389\n",
            "root        : INFO     Epoch: 26, Batch: 180, Loss: 0.0719\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0312\n",
            "root        : INFO     Epoch: 26, Batch: 220, Loss: 0.0330\n",
            "root        : INFO     Epoch: 26, Batch: 240, Loss: 0.0376\n",
            "root        : INFO     Epoch: 26, Batch: 260, Loss: 0.0621\n",
            "root        : INFO     Epoch: 26, Batch: 280, Loss: 0.0396\n",
            "root        : INFO     Epoch: 26, Batch: 300, Loss: 0.0404\n",
            "root        : INFO     Epoch: 26, Batch: 320, Loss: 0.0688\n",
            "root        : INFO     Epoch: 26, Batch: 340, Loss: 0.0830\n",
            "root        : INFO     Epoch: 26, Batch: 360, Loss: 0.0873\n",
            "root        : INFO     Epoch: 26, Batch: 380, Loss: 0.0457\n",
            "root        : INFO     Epoch: 26, Batch: 400, Loss: 0.0666\n",
            "root        : INFO     Epoch: 26, Batch: 420, Loss: 0.0457\n",
            "root        : INFO     Epoch: 26, Batch: 440, Loss: 0.0995\n",
            "root        : INFO     Epoch: 26, Batch: 460, Loss: 0.0748\n",
            "root        : INFO     Epoch: 26, Batch: 480, Loss: 0.1091\n",
            "root        : INFO     Epoch: 26, Batch: 500, Loss: 0.0999\n",
            "root        : INFO     Epoch: 26, Batch: 520, Loss: 0.0590\n",
            "root        : INFO     Epoch: 26, Batch: 540, Loss: 0.0482\n",
            "root        : INFO     Epoch: 26, Batch: 560, Loss: 0.0315\n",
            "root        : INFO     Epoch: 26, Batch: 580, Loss: 0.0409\n",
            "root        : INFO     Epoch: 26, Batch: 600, Loss: 0.0706\n",
            "root        : INFO     Epoch: 26, Batch: 620, Loss: 0.0984\n",
            "root        : INFO     Epoch: 26, Batch: 640, Loss: 0.0412\n",
            "root        : INFO     Epoch: 26, Batch: 660, Loss: 0.0344\n",
            "root        : INFO     Epoch: 26, Batch: 680, Loss: 0.0777\n",
            "root        : INFO     Epoch: 26, Batch: 700, Loss: 0.1440\n",
            "root        : INFO     Epoch: 26, Batch: 720, Loss: 0.0963\n",
            "root        : INFO     Epoch: 26, Batch: 740, Loss: 0.0607\n",
            "root        : INFO     Epoch: 26, Batch: 760, Loss: 0.0575\n",
            "root        : INFO     Epoch: 26, Batch: 780, Loss: 0.1081\n",
            "root        : INFO     Epoch: 26, Batch: 800, Loss: 0.0745\n",
            "root        : INFO     Epoch: 26, Batch: 820, Loss: 0.0720\n",
            "root        : INFO     Epoch: 26, Batch: 840, Loss: 0.0437\n",
            "root        : INFO     Epoch: 26, Batch: 860, Loss: 0.0723\n",
            "root        : INFO     Epoch: 26, Batch: 880, Loss: 0.0529\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0770\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0717\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0938\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0761\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0674\n",
            "root        : INFO     Epoch: 27, Batch: 120, Loss: 0.0294\n",
            "root        : INFO     Epoch: 27, Batch: 140, Loss: 0.0622\n",
            "root        : INFO     Epoch: 27, Batch: 160, Loss: 0.0471\n",
            "root        : INFO     Epoch: 27, Batch: 180, Loss: 0.0579\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0629\n",
            "root        : INFO     Epoch: 27, Batch: 220, Loss: 0.0430\n",
            "root        : INFO     Epoch: 27, Batch: 240, Loss: 0.0296\n",
            "root        : INFO     Epoch: 27, Batch: 260, Loss: 0.0668\n",
            "root        : INFO     Epoch: 27, Batch: 280, Loss: 0.0878\n",
            "root        : INFO     Epoch: 27, Batch: 300, Loss: 0.0659\n",
            "root        : INFO     Epoch: 27, Batch: 320, Loss: 0.0638\n",
            "root        : INFO     Epoch: 27, Batch: 340, Loss: 0.0683\n",
            "root        : INFO     Epoch: 27, Batch: 360, Loss: 0.0601\n",
            "root        : INFO     Epoch: 27, Batch: 380, Loss: 0.0546\n",
            "root        : INFO     Epoch: 27, Batch: 400, Loss: 0.0698\n",
            "root        : INFO     Epoch: 27, Batch: 420, Loss: 0.0810\n",
            "root        : INFO     Epoch: 27, Batch: 440, Loss: 0.1070\n",
            "root        : INFO     Epoch: 27, Batch: 460, Loss: 0.0645\n",
            "root        : INFO     Epoch: 27, Batch: 480, Loss: 0.1029\n",
            "root        : INFO     Epoch: 27, Batch: 500, Loss: 0.0874\n",
            "root        : INFO     Epoch: 27, Batch: 520, Loss: 0.0507\n",
            "root        : INFO     Epoch: 27, Batch: 540, Loss: 0.0481\n",
            "root        : INFO     Epoch: 27, Batch: 560, Loss: 0.0264\n",
            "root        : INFO     Epoch: 27, Batch: 580, Loss: 0.0736\n",
            "root        : INFO     Epoch: 27, Batch: 600, Loss: 0.0527\n",
            "root        : INFO     Epoch: 27, Batch: 620, Loss: 0.1804\n",
            "root        : INFO     Epoch: 27, Batch: 640, Loss: 0.0950\n",
            "root        : INFO     Epoch: 27, Batch: 660, Loss: 0.0609\n",
            "root        : INFO     Epoch: 27, Batch: 680, Loss: 0.0444\n",
            "root        : INFO     Epoch: 27, Batch: 700, Loss: 0.0538\n",
            "root        : INFO     Epoch: 27, Batch: 720, Loss: 0.0464\n",
            "root        : INFO     Epoch: 27, Batch: 740, Loss: 0.0353\n",
            "root        : INFO     Epoch: 27, Batch: 760, Loss: 0.0528\n",
            "root        : INFO     Epoch: 27, Batch: 780, Loss: 0.0517\n",
            "root        : INFO     Epoch: 27, Batch: 800, Loss: 0.0805\n",
            "root        : INFO     Epoch: 27, Batch: 820, Loss: 0.0709\n",
            "root        : INFO     Epoch: 27, Batch: 840, Loss: 0.0787\n",
            "root        : INFO     Epoch: 27, Batch: 860, Loss: 0.0389\n",
            "root        : INFO     Epoch: 27, Batch: 880, Loss: 0.0662\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0668\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.1063\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0502\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0773\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0488\n",
            "root        : INFO     Epoch: 28, Batch: 120, Loss: 0.1131\n",
            "root        : INFO     Epoch: 28, Batch: 140, Loss: 0.0719\n",
            "root        : INFO     Epoch: 28, Batch: 160, Loss: 0.0719\n",
            "root        : INFO     Epoch: 28, Batch: 180, Loss: 0.0577\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.0628\n",
            "root        : INFO     Epoch: 28, Batch: 220, Loss: 0.0832\n",
            "root        : INFO     Epoch: 28, Batch: 240, Loss: 0.0675\n",
            "root        : INFO     Epoch: 28, Batch: 260, Loss: 0.0818\n",
            "root        : INFO     Epoch: 28, Batch: 280, Loss: 0.0582\n",
            "root        : INFO     Epoch: 28, Batch: 300, Loss: 0.0621\n",
            "root        : INFO     Epoch: 28, Batch: 320, Loss: 0.1255\n",
            "root        : INFO     Epoch: 28, Batch: 340, Loss: 0.0779\n",
            "root        : INFO     Epoch: 28, Batch: 360, Loss: 0.0791\n",
            "root        : INFO     Epoch: 28, Batch: 380, Loss: 0.0512\n",
            "root        : INFO     Epoch: 28, Batch: 400, Loss: 0.0481\n",
            "root        : INFO     Epoch: 28, Batch: 420, Loss: 0.0492\n",
            "root        : INFO     Epoch: 28, Batch: 440, Loss: 0.0819\n",
            "root        : INFO     Epoch: 28, Batch: 460, Loss: 0.0805\n",
            "root        : INFO     Epoch: 28, Batch: 480, Loss: 0.0846\n",
            "root        : INFO     Epoch: 28, Batch: 500, Loss: 0.0688\n",
            "root        : INFO     Epoch: 28, Batch: 520, Loss: 0.0850\n",
            "root        : INFO     Epoch: 28, Batch: 540, Loss: 0.0588\n",
            "root        : INFO     Epoch: 28, Batch: 560, Loss: 0.0785\n",
            "root        : INFO     Epoch: 28, Batch: 580, Loss: 0.0384\n",
            "root        : INFO     Epoch: 28, Batch: 600, Loss: 0.0473\n",
            "root        : INFO     Epoch: 28, Batch: 620, Loss: 0.0522\n",
            "root        : INFO     Epoch: 28, Batch: 640, Loss: 0.0624\n",
            "root        : INFO     Epoch: 28, Batch: 660, Loss: 0.0702\n",
            "root        : INFO     Epoch: 28, Batch: 680, Loss: 0.0745\n",
            "root        : INFO     Epoch: 28, Batch: 700, Loss: 0.0896\n",
            "root        : INFO     Epoch: 28, Batch: 720, Loss: 0.0483\n",
            "root        : INFO     Epoch: 28, Batch: 740, Loss: 0.0739\n",
            "root        : INFO     Epoch: 28, Batch: 760, Loss: 0.0691\n",
            "root        : INFO     Epoch: 28, Batch: 780, Loss: 0.0733\n",
            "root        : INFO     Epoch: 28, Batch: 800, Loss: 0.1296\n",
            "root        : INFO     Epoch: 28, Batch: 820, Loss: 0.0878\n",
            "root        : INFO     Epoch: 28, Batch: 840, Loss: 0.0614\n",
            "root        : INFO     Epoch: 28, Batch: 860, Loss: 0.0419\n",
            "root        : INFO     Epoch: 28, Batch: 880, Loss: 0.0718\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0825\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0638\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0827\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0391\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0928\n",
            "root        : INFO     Epoch: 29, Batch: 120, Loss: 0.0885\n",
            "root        : INFO     Epoch: 29, Batch: 140, Loss: 0.0981\n",
            "root        : INFO     Epoch: 29, Batch: 160, Loss: 0.0875\n",
            "root        : INFO     Epoch: 29, Batch: 180, Loss: 0.0561\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.1173\n",
            "root        : INFO     Epoch: 29, Batch: 220, Loss: 0.0592\n",
            "root        : INFO     Epoch: 29, Batch: 240, Loss: 0.1140\n",
            "root        : INFO     Epoch: 29, Batch: 260, Loss: 0.0456\n",
            "root        : INFO     Epoch: 29, Batch: 280, Loss: 0.0915\n",
            "root        : INFO     Epoch: 29, Batch: 300, Loss: 0.0558\n",
            "root        : INFO     Epoch: 29, Batch: 320, Loss: 0.0915\n",
            "root        : INFO     Epoch: 29, Batch: 340, Loss: 0.0355\n",
            "root        : INFO     Epoch: 29, Batch: 360, Loss: 0.0454\n",
            "root        : INFO     Epoch: 29, Batch: 380, Loss: 0.0681\n",
            "root        : INFO     Epoch: 29, Batch: 400, Loss: 0.0433\n",
            "root        : INFO     Epoch: 29, Batch: 420, Loss: 0.0645\n",
            "root        : INFO     Epoch: 29, Batch: 440, Loss: 0.0673\n",
            "root        : INFO     Epoch: 29, Batch: 460, Loss: 0.0498\n",
            "root        : INFO     Epoch: 29, Batch: 480, Loss: 0.0986\n",
            "root        : INFO     Epoch: 29, Batch: 500, Loss: 0.0995\n",
            "root        : INFO     Epoch: 29, Batch: 520, Loss: 0.0471\n",
            "root        : INFO     Epoch: 29, Batch: 540, Loss: 0.0500\n",
            "root        : INFO     Epoch: 29, Batch: 560, Loss: 0.0652\n",
            "root        : INFO     Epoch: 29, Batch: 580, Loss: 0.0614\n",
            "root        : INFO     Epoch: 29, Batch: 600, Loss: 0.0400\n",
            "root        : INFO     Epoch: 29, Batch: 620, Loss: 0.0876\n",
            "root        : INFO     Epoch: 29, Batch: 640, Loss: 0.0431\n",
            "root        : INFO     Epoch: 29, Batch: 660, Loss: 0.0663\n",
            "root        : INFO     Epoch: 29, Batch: 680, Loss: 0.0680\n",
            "root        : INFO     Epoch: 29, Batch: 700, Loss: 0.0445\n",
            "root        : INFO     Epoch: 29, Batch: 720, Loss: 0.0578\n",
            "root        : INFO     Epoch: 29, Batch: 740, Loss: 0.0550\n",
            "root        : INFO     Epoch: 29, Batch: 760, Loss: 0.0489\n",
            "root        : INFO     Epoch: 29, Batch: 780, Loss: 0.0751\n",
            "root        : INFO     Epoch: 29, Batch: 800, Loss: 0.0713\n",
            "root        : INFO     Epoch: 29, Batch: 820, Loss: 0.0878\n",
            "root        : INFO     Epoch: 29, Batch: 840, Loss: 0.0610\n",
            "root        : INFO     Epoch: 29, Batch: 860, Loss: 0.0825\n",
            "root        : INFO     Epoch: 29, Batch: 880, Loss: 0.0761\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyPQvn-SCT4B"
      },
      "source": [
        "**4. Tranfer Learning ds-rotate =0.6, Object-Wise, batchsize=8, SGD, learning rate =0.0001, channel size 32, train_network_t.py**  \n",
        "**Achieved 0.972 in Training validation, and 0.966 when testing**  \n",
        "**COOL !**  \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKkT-flWAeUm",
        "outputId": "63c1ed80-82c8-4593-c7ca-f8ed489c4b15"
      },
      "source": [
        "!python train_network_t.py --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0319_training_cornell/epoch_16_iou_0.92 --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.6  --optim SGD --lr=0.0001 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.60, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = SGD, learning rate = 0.000100\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0562\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0518\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.0783\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0648\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0408\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1110\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0666\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0820\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0649\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0988\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0912\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1003\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.0697\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0349\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.0482\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.0532\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.1461\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     171/177 = 0.966102\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.1130\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0638\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0780\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0317\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0720\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0916\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0688\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0672\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.0757\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0965\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.0547\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0811\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.1182\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0883\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.0589\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0384\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.1124\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     169/177 = 0.954802\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.1143\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0612\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0501\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0657\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0811\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0520\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0945\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0401\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0844\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.1112\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.1051\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0748\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.0723\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0490\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.1302\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0614\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0495\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0318\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0709\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0828\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0583\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0739\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0666\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0569\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0812\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0895\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0979\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.1287\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0656\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0575\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.1127\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0323\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0612\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0976\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     168/177 = 0.949153\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0832\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1047\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.1056\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0750\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.1328\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1329\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0842\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0695\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.1234\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0645\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0594\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.1090\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.0664\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.1289\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0549\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.1123\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0378\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     172/177 = 0.971751\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0264\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.1455\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0827\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0683\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0516\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0786\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0960\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0870\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0533\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0807\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.1574\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0868\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.0401\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0988\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0707\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0676\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0768\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0927\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0681\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0758\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.1062\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0724\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0657\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0395\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0552\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0582\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0677\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0619\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.1429\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0726\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.1563\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0919\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0355\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0529\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.1158\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0870\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.1022\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0512\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.1532\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0884\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0849\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0439\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0418\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0728\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0618\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0848\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0717\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0376\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0693\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.1053\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0432\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     169/177 = 0.954802\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.1521\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0983\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.1163\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0543\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0786\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0825\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0373\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.1010\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0686\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0944\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0507\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0644\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0892\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0893\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0843\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0442\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.1188\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     169/177 = 0.954802\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0241\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0646\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0785\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0739\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0719\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0433\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0701\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0877\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0877\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0523\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0842\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.1114\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0302\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.1090\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0769\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0555\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0970\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0358\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.1137\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0625\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0635\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.1002\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0657\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0692\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0891\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.0720\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0438\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0797\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0605\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0436\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.1172\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0757\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0724\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.1057\n",
            "Traceback (most recent call last):\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     169/177 = 0.954802\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0946\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0278\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0485\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0522\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0623\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0474\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0316\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0806\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0404\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.1069\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0515\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0570\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0676\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0815\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0492\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0742\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0962\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0565\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0920\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0774\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0431\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.1030\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0436\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0652\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.1019\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.1132\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0485\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0355\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.1090\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0913\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0773\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.1090\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.1132\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0267\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     171/177 = 0.966102\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.1089\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.1461\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0821\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0840\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0869\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.1147\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0501\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0685\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.0400\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0719\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.1241\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0727\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0451\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0563\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.0729\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0456\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.0734\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     170/177 = 0.960452\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0902\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0487\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0703\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0746\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.1332\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0719\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0489\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0747\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0731\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0473\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.0870\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0853\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0612\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0846\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0863\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0821\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0893\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     165/177 = 0.932203\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.1063\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0702\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0779\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0770\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0912\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.1280\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0516\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0811\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.0694\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.1151\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.0436\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0532\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.1154\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0596\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.1060\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0838\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0416\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     168/177 = 0.949153\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0663\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0822\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.1123\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0463\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0337\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0690\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.1207\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0772\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.0555\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0951\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.0607\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0826\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0939\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0333\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0433\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0322\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0677\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     170/177 = 0.960452\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0541\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0384\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0654\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0703\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0549\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0644\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.1088\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0582\n",
            "root        : INFO     Epoch: 17, Batch: 450, Loss: 0.0773\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0769\n",
            "root        : INFO     Epoch: 17, Batch: 550, Loss: 0.0710\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0750\n",
            "root        : INFO     Epoch: 17, Batch: 650, Loss: 0.0821\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0889\n",
            "root        : INFO     Epoch: 17, Batch: 750, Loss: 0.1176\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0512\n",
            "root        : INFO     Epoch: 17, Batch: 850, Loss: 0.0319\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     168/177 = 0.949153\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0889\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0680\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.1703\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.1274\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.1250\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0769\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0369\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0954\n",
            "root        : INFO     Epoch: 18, Batch: 450, Loss: 0.0454\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0846\n",
            "root        : INFO     Epoch: 18, Batch: 550, Loss: 0.1453\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0778\n",
            "root        : INFO     Epoch: 18, Batch: 650, Loss: 0.1009\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.0767\n",
            "root        : INFO     Epoch: 18, Batch: 750, Loss: 0.0683\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0869\n",
            "root        : INFO     Epoch: 18, Batch: 850, Loss: 0.0868\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     168/177 = 0.949153\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0940\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0638\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.1227\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0550\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0486\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0441\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.1397\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.1163\n",
            "root        : INFO     Epoch: 19, Batch: 450, Loss: 0.0530\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0714\n",
            "root        : INFO     Epoch: 19, Batch: 550, Loss: 0.0518\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.0944\n",
            "root        : INFO     Epoch: 19, Batch: 650, Loss: 0.0868\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0369\n",
            "root        : INFO     Epoch: 19, Batch: 750, Loss: 0.0656\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0609\n",
            "root        : INFO     Epoch: 19, Batch: 850, Loss: 0.0589\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     169/177 = 0.954802\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 50, Loss: 0.0812\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0448\n",
            "root        : INFO     Epoch: 20, Batch: 150, Loss: 0.1268\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0491\n",
            "root        : INFO     Epoch: 20, Batch: 250, Loss: 0.0777\n",
            "root        : INFO     Epoch: 20, Batch: 300, Loss: 0.1547\n",
            "root        : INFO     Epoch: 20, Batch: 350, Loss: 0.0525\n",
            "root        : INFO     Epoch: 20, Batch: 400, Loss: 0.0626\n",
            "root        : INFO     Epoch: 20, Batch: 450, Loss: 0.0680\n",
            "root        : INFO     Epoch: 20, Batch: 500, Loss: 0.0387\n",
            "root        : INFO     Epoch: 20, Batch: 550, Loss: 0.0749\n",
            "root        : INFO     Epoch: 20, Batch: 600, Loss: 0.0659\n",
            "root        : INFO     Epoch: 20, Batch: 650, Loss: 0.1138\n",
            "root        : INFO     Epoch: 20, Batch: 700, Loss: 0.0622\n",
            "root        : INFO     Epoch: 20, Batch: 750, Loss: 0.0459\n",
            "root        : INFO     Epoch: 20, Batch: 800, Loss: 0.0561\n",
            "root        : INFO     Epoch: 20, Batch: 850, Loss: 0.1060\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     170/177 = 0.960452\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 50, Loss: 0.0416\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0320\n",
            "root        : INFO     Epoch: 21, Batch: 150, Loss: 0.0648\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.0773\n",
            "root        : INFO     Epoch: 21, Batch: 250, Loss: 0.0754\n",
            "root        : INFO     Epoch: 21, Batch: 300, Loss: 0.0870\n",
            "root        : INFO     Epoch: 21, Batch: 350, Loss: 0.1070\n",
            "root        : INFO     Epoch: 21, Batch: 400, Loss: 0.0697\n",
            "root        : INFO     Epoch: 21, Batch: 450, Loss: 0.0807\n",
            "root        : INFO     Epoch: 21, Batch: 500, Loss: 0.0263\n",
            "root        : INFO     Epoch: 21, Batch: 550, Loss: 0.0593\n",
            "root        : INFO     Epoch: 21, Batch: 600, Loss: 0.1026\n",
            "root        : INFO     Epoch: 21, Batch: 650, Loss: 0.0949\n",
            "root        : INFO     Epoch: 21, Batch: 700, Loss: 0.0794\n",
            "root        : INFO     Epoch: 21, Batch: 750, Loss: 0.0590\n",
            "root        : INFO     Epoch: 21, Batch: 800, Loss: 0.0705\n",
            "root        : INFO     Epoch: 21, Batch: 850, Loss: 0.0594\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     167/177 = 0.943503\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 50, Loss: 0.0672\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.1091\n",
            "root        : INFO     Epoch: 22, Batch: 150, Loss: 0.0473\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.0720\n",
            "root        : INFO     Epoch: 22, Batch: 250, Loss: 0.0773\n",
            "root        : INFO     Epoch: 22, Batch: 300, Loss: 0.0550\n",
            "root        : INFO     Epoch: 22, Batch: 350, Loss: 0.0529\n",
            "root        : INFO     Epoch: 22, Batch: 400, Loss: 0.0983\n",
            "root        : INFO     Epoch: 22, Batch: 450, Loss: 0.0858\n",
            "root        : INFO     Epoch: 22, Batch: 500, Loss: 0.0788\n",
            "root        : INFO     Epoch: 22, Batch: 550, Loss: 0.0793\n",
            "root        : INFO     Epoch: 22, Batch: 600, Loss: 0.0630\n",
            "root        : INFO     Epoch: 22, Batch: 650, Loss: 0.0655\n",
            "root        : INFO     Epoch: 22, Batch: 700, Loss: 0.0814\n",
            "root        : INFO     Epoch: 22, Batch: 750, Loss: 0.0734\n",
            "root        : INFO     Epoch: 22, Batch: 800, Loss: 0.0839\n",
            "root        : INFO     Epoch: 22, Batch: 850, Loss: 0.0689\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 50, Loss: 0.0637\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0607\n",
            "root        : INFO     Epoch: 23, Batch: 150, Loss: 0.0863\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0542\n",
            "root        : INFO     Epoch: 23, Batch: 250, Loss: 0.1214\n",
            "root        : INFO     Epoch: 23, Batch: 300, Loss: 0.0630\n",
            "root        : INFO     Epoch: 23, Batch: 350, Loss: 0.0811\n",
            "root        : INFO     Epoch: 23, Batch: 400, Loss: 0.0829\n",
            "root        : INFO     Epoch: 23, Batch: 450, Loss: 0.1034\n",
            "root        : INFO     Epoch: 23, Batch: 500, Loss: 0.0462\n",
            "root        : INFO     Epoch: 23, Batch: 550, Loss: 0.0852\n",
            "root        : INFO     Epoch: 23, Batch: 600, Loss: 0.0463\n",
            "root        : INFO     Epoch: 23, Batch: 650, Loss: 0.1272\n",
            "root        : INFO     Epoch: 23, Batch: 700, Loss: 0.0989\n",
            "root        : INFO     Epoch: 23, Batch: 750, Loss: 0.0374\n",
            "root        : INFO     Epoch: 23, Batch: 800, Loss: 0.0374\n",
            "root        : INFO     Epoch: 23, Batch: 850, Loss: 0.0771\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     170/177 = 0.960452\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 50, Loss: 0.0633\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0479\n",
            "root        : INFO     Epoch: 24, Batch: 150, Loss: 0.0787\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0536\n",
            "root        : INFO     Epoch: 24, Batch: 250, Loss: 0.0633\n",
            "root        : INFO     Epoch: 24, Batch: 300, Loss: 0.0404\n",
            "root        : INFO     Epoch: 24, Batch: 350, Loss: 0.0818\n",
            "root        : INFO     Epoch: 24, Batch: 400, Loss: 0.0746\n",
            "root        : INFO     Epoch: 24, Batch: 450, Loss: 0.0879\n",
            "root        : INFO     Epoch: 24, Batch: 500, Loss: 0.0428\n",
            "root        : INFO     Epoch: 24, Batch: 550, Loss: 0.0407\n",
            "root        : INFO     Epoch: 24, Batch: 600, Loss: 0.0536\n",
            "root        : INFO     Epoch: 24, Batch: 650, Loss: 0.0986\n",
            "root        : INFO     Epoch: 24, Batch: 700, Loss: 0.0866\n",
            "root        : INFO     Epoch: 24, Batch: 750, Loss: 0.0262\n",
            "root        : INFO     Epoch: 24, Batch: 800, Loss: 0.0718\n",
            "root        : INFO     Epoch: 24, Batch: 850, Loss: 0.1198\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     167/177 = 0.943503\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "Traceback (most recent call last):\n",
            "  File \"train_network_t.py\", line 371, in <module>\n",
            "    run()\n",
            "  File \"train_network_t.py\", line 343, in run\n",
            "    train_results = train(epoch, net, device, train_data, optimizer, args.batches_per_epoch, vis=args.vis)\n",
            "  File \"train_network_t.py\", line 183, in train\n",
            "    optimizer.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\", line 117, in step\n",
            "    nesterov)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\", line 169, in sgd\n",
            "    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz9FSBSDkDXN"
      },
      "source": [
        "**4. Tranfer Learning ds-rotate =0.6, Image-Wise, batchsize=8, SGD, learning rate =0.0001, channel size 32, train_network_it.py**  \n",
        "**Achieved 0. in Training validation, and 0. when testing**  \n",
        "**Failed keep 0.921 !**  \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210413_0626_training_cornell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82Yqpxe5j3RO",
        "outputId": "b419c998-f9d2-41ad-f18e-be685bdaa6fe"
      },
      "source": [
        "!python train_network_it.py --network pretrained_net --pretrained-net-path /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0319_training_cornell/epoch_16_iou_0.92 --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-rotate 0.6  --optim SGD --lr=0.0001 --augment 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = pretrained_net, use-depth = 1, use-rgb = 1, augment=1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.60, ds-shuffle = 1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = SGD, learning rate = 0.000100\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210413_0626_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 25, Loss: 0.0415\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0921\n",
            "root        : INFO     Epoch: 0, Batch: 75, Loss: 0.1038\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0813\n",
            "root        : INFO     Epoch: 0, Batch: 125, Loss: 0.0912\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1015\n",
            "root        : INFO     Epoch: 0, Batch: 175, Loss: 0.1096\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1033\n",
            "root        : INFO     Epoch: 0, Batch: 225, Loss: 0.0906\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0757\n",
            "root        : INFO     Epoch: 0, Batch: 275, Loss: 0.0692\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0731\n",
            "root        : INFO     Epoch: 0, Batch: 325, Loss: 0.0875\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0987\n",
            "root        : INFO     Epoch: 0, Batch: 375, Loss: 0.0460\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0921\n",
            "root        : INFO     Epoch: 0, Batch: 425, Loss: 0.0818\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0397\n",
            "root        : INFO     Epoch: 0, Batch: 475, Loss: 0.0651\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0531\n",
            "root        : INFO     Epoch: 0, Batch: 525, Loss: 0.0633\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0983\n",
            "root        : INFO     Epoch: 0, Batch: 575, Loss: 0.0632\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.0631\n",
            "root        : INFO     Epoch: 0, Batch: 625, Loss: 0.0590\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.0855\n",
            "root        : INFO     Epoch: 0, Batch: 675, Loss: 0.1019\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0693\n",
            "root        : INFO     Epoch: 0, Batch: 725, Loss: 0.0639\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.0469\n",
            "root        : INFO     Epoch: 0, Batch: 775, Loss: 0.0375\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.0538\n",
            "root        : INFO     Epoch: 0, Batch: 825, Loss: 0.0587\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0451\n",
            "root        : INFO     Epoch: 0, Batch: 875, Loss: 0.0733\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 25, Loss: 0.1386\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0537\n",
            "root        : INFO     Epoch: 1, Batch: 75, Loss: 0.0591\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0675\n",
            "root        : INFO     Epoch: 1, Batch: 125, Loss: 0.0773\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0337\n",
            "root        : INFO     Epoch: 1, Batch: 175, Loss: 0.0843\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0530\n",
            "root        : INFO     Epoch: 1, Batch: 225, Loss: 0.0537\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0331\n",
            "root        : INFO     Epoch: 1, Batch: 275, Loss: 0.0537\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0411\n",
            "root        : INFO     Epoch: 1, Batch: 325, Loss: 0.0536\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0920\n",
            "root        : INFO     Epoch: 1, Batch: 375, Loss: 0.0485\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0375\n",
            "root        : INFO     Epoch: 1, Batch: 425, Loss: 0.0825\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.0525\n",
            "root        : INFO     Epoch: 1, Batch: 475, Loss: 0.0587\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0300\n",
            "root        : INFO     Epoch: 1, Batch: 525, Loss: 0.1321\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.1089\n",
            "root        : INFO     Epoch: 1, Batch: 575, Loss: 0.0945\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0730\n",
            "root        : INFO     Epoch: 1, Batch: 625, Loss: 0.0682\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0629\n",
            "root        : INFO     Epoch: 1, Batch: 675, Loss: 0.0644\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0732\n",
            "root        : INFO     Epoch: 1, Batch: 725, Loss: 0.0299\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.0700\n",
            "root        : INFO     Epoch: 1, Batch: 775, Loss: 0.0999\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.1024\n",
            "root        : INFO     Epoch: 1, Batch: 825, Loss: 0.0474\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.0787\n",
            "root        : INFO     Epoch: 1, Batch: 875, Loss: 0.1140\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 25, Loss: 0.0826\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0889\n",
            "root        : INFO     Epoch: 2, Batch: 75, Loss: 0.1103\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0686\n",
            "root        : INFO     Epoch: 2, Batch: 125, Loss: 0.0908\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0706\n",
            "root        : INFO     Epoch: 2, Batch: 175, Loss: 0.0719\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0574\n",
            "root        : INFO     Epoch: 2, Batch: 225, Loss: 0.1185\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0429\n",
            "root        : INFO     Epoch: 2, Batch: 275, Loss: 0.0662\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0722\n",
            "root        : INFO     Epoch: 2, Batch: 325, Loss: 0.1171\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0883\n",
            "root        : INFO     Epoch: 2, Batch: 375, Loss: 0.0642\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0741\n",
            "root        : INFO     Epoch: 2, Batch: 425, Loss: 0.1143\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0855\n",
            "root        : INFO     Epoch: 2, Batch: 475, Loss: 0.0683\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0436\n",
            "root        : INFO     Epoch: 2, Batch: 525, Loss: 0.0547\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.0592\n",
            "root        : INFO     Epoch: 2, Batch: 575, Loss: 0.0931\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0387\n",
            "root        : INFO     Epoch: 2, Batch: 625, Loss: 0.0696\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.0807\n",
            "root        : INFO     Epoch: 2, Batch: 675, Loss: 0.0658\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0560\n",
            "root        : INFO     Epoch: 2, Batch: 725, Loss: 0.0921\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.0684\n",
            "root        : INFO     Epoch: 2, Batch: 775, Loss: 0.0637\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0553\n",
            "root        : INFO     Epoch: 2, Batch: 825, Loss: 0.0756\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0743\n",
            "root        : INFO     Epoch: 2, Batch: 875, Loss: 0.0824\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 25, Loss: 0.0770\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0733\n",
            "root        : INFO     Epoch: 3, Batch: 75, Loss: 0.0927\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0617\n",
            "root        : INFO     Epoch: 3, Batch: 125, Loss: 0.0613\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0820\n",
            "root        : INFO     Epoch: 3, Batch: 175, Loss: 0.0672\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0878\n",
            "root        : INFO     Epoch: 3, Batch: 225, Loss: 0.0780\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0909\n",
            "root        : INFO     Epoch: 3, Batch: 275, Loss: 0.0730\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0581\n",
            "root        : INFO     Epoch: 3, Batch: 325, Loss: 0.0619\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.1052\n",
            "root        : INFO     Epoch: 3, Batch: 375, Loss: 0.1277\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0501\n",
            "root        : INFO     Epoch: 3, Batch: 425, Loss: 0.0702\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0581\n",
            "root        : INFO     Epoch: 3, Batch: 475, Loss: 0.0438\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0911\n",
            "root        : INFO     Epoch: 3, Batch: 525, Loss: 0.0408\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.1132\n",
            "root        : INFO     Epoch: 3, Batch: 575, Loss: 0.1006\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0569\n",
            "root        : INFO     Epoch: 3, Batch: 625, Loss: 0.0801\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0493\n",
            "root        : INFO     Epoch: 3, Batch: 675, Loss: 0.0842\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0792\n",
            "root        : INFO     Epoch: 3, Batch: 725, Loss: 0.0995\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0510\n",
            "root        : INFO     Epoch: 3, Batch: 775, Loss: 0.0217\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0617\n",
            "root        : INFO     Epoch: 3, Batch: 825, Loss: 0.0761\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0724\n",
            "root        : INFO     Epoch: 3, Batch: 875, Loss: 0.0802\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 25, Loss: 0.0503\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0640\n",
            "root        : INFO     Epoch: 4, Batch: 75, Loss: 0.0648\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0644\n",
            "root        : INFO     Epoch: 4, Batch: 125, Loss: 0.0520\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.1145\n",
            "root        : INFO     Epoch: 4, Batch: 175, Loss: 0.0376\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0951\n",
            "root        : INFO     Epoch: 4, Batch: 225, Loss: 0.0530\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0577\n",
            "root        : INFO     Epoch: 4, Batch: 275, Loss: 0.0836\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0502\n",
            "root        : INFO     Epoch: 4, Batch: 325, Loss: 0.0979\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0580\n",
            "root        : INFO     Epoch: 4, Batch: 375, Loss: 0.1094\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0890\n",
            "root        : INFO     Epoch: 4, Batch: 425, Loss: 0.0899\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.0600\n",
            "root        : INFO     Epoch: 4, Batch: 475, Loss: 0.0654\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0668\n",
            "root        : INFO     Epoch: 4, Batch: 525, Loss: 0.0316\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0642\n",
            "root        : INFO     Epoch: 4, Batch: 575, Loss: 0.0887\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0592\n",
            "root        : INFO     Epoch: 4, Batch: 625, Loss: 0.1338\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.0528\n",
            "root        : INFO     Epoch: 4, Batch: 675, Loss: 0.0843\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0363\n",
            "root        : INFO     Epoch: 4, Batch: 725, Loss: 0.0680\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0833\n",
            "root        : INFO     Epoch: 4, Batch: 775, Loss: 0.0967\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0505\n",
            "root        : INFO     Epoch: 4, Batch: 825, Loss: 0.1112\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0437\n",
            "root        : INFO     Epoch: 4, Batch: 875, Loss: 0.0803\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 25, Loss: 0.0878\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0734\n",
            "root        : INFO     Epoch: 5, Batch: 75, Loss: 0.0469\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0828\n",
            "root        : INFO     Epoch: 5, Batch: 125, Loss: 0.1271\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0693\n",
            "root        : INFO     Epoch: 5, Batch: 175, Loss: 0.0893\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.1142\n",
            "root        : INFO     Epoch: 5, Batch: 225, Loss: 0.0717\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0702\n",
            "root        : INFO     Epoch: 5, Batch: 275, Loss: 0.0339\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0904\n",
            "root        : INFO     Epoch: 5, Batch: 325, Loss: 0.0755\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0627\n",
            "root        : INFO     Epoch: 5, Batch: 375, Loss: 0.0783\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0455\n",
            "root        : INFO     Epoch: 5, Batch: 425, Loss: 0.0661\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0841\n",
            "root        : INFO     Epoch: 5, Batch: 475, Loss: 0.1624\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0817\n",
            "root        : INFO     Epoch: 5, Batch: 525, Loss: 0.0658\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0584\n",
            "root        : INFO     Epoch: 5, Batch: 575, Loss: 0.0590\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0566\n",
            "root        : INFO     Epoch: 5, Batch: 625, Loss: 0.0493\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.1244\n",
            "root        : INFO     Epoch: 5, Batch: 675, Loss: 0.0922\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0468\n",
            "root        : INFO     Epoch: 5, Batch: 725, Loss: 0.0599\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0632\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0643\n",
            "root        : INFO     Epoch: 5, Batch: 825, Loss: 0.1036\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0852\n",
            "root        : INFO     Epoch: 5, Batch: 875, Loss: 0.0710\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     158/177 = 0.892655\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 25, Loss: 0.0673\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0650\n",
            "root        : INFO     Epoch: 6, Batch: 75, Loss: 0.0916\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0472\n",
            "root        : INFO     Epoch: 6, Batch: 125, Loss: 0.0518\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0749\n",
            "root        : INFO     Epoch: 6, Batch: 175, Loss: 0.0641\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0701\n",
            "root        : INFO     Epoch: 6, Batch: 225, Loss: 0.1017\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0714\n",
            "root        : INFO     Epoch: 6, Batch: 275, Loss: 0.0867\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.1353\n",
            "root        : INFO     Epoch: 6, Batch: 325, Loss: 0.1097\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0625\n",
            "root        : INFO     Epoch: 6, Batch: 375, Loss: 0.0898\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0628\n",
            "root        : INFO     Epoch: 6, Batch: 425, Loss: 0.0580\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0540\n",
            "root        : INFO     Epoch: 6, Batch: 475, Loss: 0.0594\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0647\n",
            "root        : INFO     Epoch: 6, Batch: 525, Loss: 0.0846\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0694\n",
            "root        : INFO     Epoch: 6, Batch: 575, Loss: 0.0931\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0441\n",
            "root        : INFO     Epoch: 6, Batch: 625, Loss: 0.1202\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0335\n",
            "root        : INFO     Epoch: 6, Batch: 675, Loss: 0.1157\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0476\n",
            "root        : INFO     Epoch: 6, Batch: 725, Loss: 0.0511\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.1212\n",
            "root        : INFO     Epoch: 6, Batch: 775, Loss: 0.0824\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0838\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0681\n",
            "root        : INFO     Epoch: 6, Batch: 875, Loss: 0.0484\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 25, Loss: 0.0886\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0404\n",
            "root        : INFO     Epoch: 7, Batch: 75, Loss: 0.0731\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0680\n",
            "root        : INFO     Epoch: 7, Batch: 125, Loss: 0.0446\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0703\n",
            "root        : INFO     Epoch: 7, Batch: 175, Loss: 0.0679\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0719\n",
            "root        : INFO     Epoch: 7, Batch: 225, Loss: 0.0424\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0447\n",
            "root        : INFO     Epoch: 7, Batch: 275, Loss: 0.0697\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0609\n",
            "root        : INFO     Epoch: 7, Batch: 325, Loss: 0.0778\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0567\n",
            "root        : INFO     Epoch: 7, Batch: 375, Loss: 0.0691\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0701\n",
            "root        : INFO     Epoch: 7, Batch: 425, Loss: 0.0467\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0957\n",
            "root        : INFO     Epoch: 7, Batch: 475, Loss: 0.0392\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0887\n",
            "root        : INFO     Epoch: 7, Batch: 525, Loss: 0.0428\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0911\n",
            "root        : INFO     Epoch: 7, Batch: 575, Loss: 0.0387\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0373\n",
            "root        : INFO     Epoch: 7, Batch: 625, Loss: 0.0768\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0732\n",
            "root        : INFO     Epoch: 7, Batch: 675, Loss: 0.0541\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0970\n",
            "root        : INFO     Epoch: 7, Batch: 725, Loss: 0.0485\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0426\n",
            "root        : INFO     Epoch: 7, Batch: 775, Loss: 0.0463\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0840\n",
            "root        : INFO     Epoch: 7, Batch: 825, Loss: 0.0535\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0694\n",
            "root        : INFO     Epoch: 7, Batch: 875, Loss: 0.0696\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 25, Loss: 0.0805\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0823\n",
            "root        : INFO     Epoch: 8, Batch: 75, Loss: 0.1070\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0636\n",
            "root        : INFO     Epoch: 8, Batch: 125, Loss: 0.0621\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0663\n",
            "root        : INFO     Epoch: 8, Batch: 175, Loss: 0.1015\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0978\n",
            "root        : INFO     Epoch: 8, Batch: 225, Loss: 0.0835\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0896\n",
            "root        : INFO     Epoch: 8, Batch: 275, Loss: 0.0481\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0530\n",
            "root        : INFO     Epoch: 8, Batch: 325, Loss: 0.1113\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0624\n",
            "root        : INFO     Epoch: 8, Batch: 375, Loss: 0.0493\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0978\n",
            "root        : INFO     Epoch: 8, Batch: 425, Loss: 0.0730\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0743\n",
            "root        : INFO     Epoch: 8, Batch: 475, Loss: 0.0567\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0713\n",
            "root        : INFO     Epoch: 8, Batch: 525, Loss: 0.0973\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0547\n",
            "root        : INFO     Epoch: 8, Batch: 575, Loss: 0.0687\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0835\n",
            "root        : INFO     Epoch: 8, Batch: 625, Loss: 0.1151\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0430\n",
            "root        : INFO     Epoch: 8, Batch: 675, Loss: 0.0529\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0739\n",
            "root        : INFO     Epoch: 8, Batch: 725, Loss: 0.0759\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.1406\n",
            "root        : INFO     Epoch: 8, Batch: 775, Loss: 0.0796\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0862\n",
            "root        : INFO     Epoch: 8, Batch: 825, Loss: 0.0840\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0517\n",
            "root        : INFO     Epoch: 8, Batch: 875, Loss: 0.0591\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 25, Loss: 0.0898\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0602\n",
            "root        : INFO     Epoch: 9, Batch: 75, Loss: 0.0311\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0766\n",
            "root        : INFO     Epoch: 9, Batch: 125, Loss: 0.0623\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0469\n",
            "root        : INFO     Epoch: 9, Batch: 175, Loss: 0.0797\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0692\n",
            "root        : INFO     Epoch: 9, Batch: 225, Loss: 0.0666\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0824\n",
            "root        : INFO     Epoch: 9, Batch: 275, Loss: 0.1387\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0523\n",
            "root        : INFO     Epoch: 9, Batch: 325, Loss: 0.0991\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0395\n",
            "root        : INFO     Epoch: 9, Batch: 375, Loss: 0.0620\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0613\n",
            "root        : INFO     Epoch: 9, Batch: 425, Loss: 0.0740\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0813\n",
            "root        : INFO     Epoch: 9, Batch: 475, Loss: 0.0845\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.1151\n",
            "root        : INFO     Epoch: 9, Batch: 525, Loss: 0.0914\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0562\n",
            "root        : INFO     Epoch: 9, Batch: 575, Loss: 0.0696\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.1347\n",
            "root        : INFO     Epoch: 9, Batch: 625, Loss: 0.0942\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0597\n",
            "root        : INFO     Epoch: 9, Batch: 675, Loss: 0.0498\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0461\n",
            "root        : INFO     Epoch: 9, Batch: 725, Loss: 0.0382\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0520\n",
            "root        : INFO     Epoch: 9, Batch: 775, Loss: 0.1070\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0857\n",
            "root        : INFO     Epoch: 9, Batch: 825, Loss: 0.0512\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0689\n",
            "root        : INFO     Epoch: 9, Batch: 875, Loss: 0.0640\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 25, Loss: 0.0949\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0840\n",
            "root        : INFO     Epoch: 10, Batch: 75, Loss: 0.0891\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0689\n",
            "root        : INFO     Epoch: 10, Batch: 125, Loss: 0.0497\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0844\n",
            "root        : INFO     Epoch: 10, Batch: 175, Loss: 0.0714\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0603\n",
            "root        : INFO     Epoch: 10, Batch: 225, Loss: 0.0617\n",
            "root        : INFO     Epoch: 10, Batch: 275, Loss: 0.0777\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0436\n",
            "root        : INFO     Epoch: 10, Batch: 325, Loss: 0.0811\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0881\n",
            "root        : INFO     Epoch: 10, Batch: 375, Loss: 0.0579\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.1258\n",
            "root        : INFO     Epoch: 10, Batch: 425, Loss: 0.0598\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.0698\n",
            "root        : INFO     Epoch: 10, Batch: 475, Loss: 0.0615\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0642\n",
            "root        : INFO     Epoch: 10, Batch: 525, Loss: 0.0682\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0626\n",
            "root        : INFO     Epoch: 10, Batch: 575, Loss: 0.1275\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0708\n",
            "root        : INFO     Epoch: 10, Batch: 625, Loss: 0.0575\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0835\n",
            "root        : INFO     Epoch: 10, Batch: 675, Loss: 0.0872\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0610\n",
            "root        : INFO     Epoch: 10, Batch: 725, Loss: 0.0824\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.1043\n",
            "root        : INFO     Epoch: 10, Batch: 775, Loss: 0.0964\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0709\n",
            "root        : INFO     Epoch: 10, Batch: 825, Loss: 0.0443\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0663\n",
            "root        : INFO     Epoch: 10, Batch: 875, Loss: 0.0693\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     162/177 = 0.915254\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 25, Loss: 0.1029\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0661\n",
            "root        : INFO     Epoch: 11, Batch: 75, Loss: 0.0881\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0647\n",
            "root        : INFO     Epoch: 11, Batch: 125, Loss: 0.0488\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.1107\n",
            "root        : INFO     Epoch: 11, Batch: 175, Loss: 0.0428\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0878\n",
            "root        : INFO     Epoch: 11, Batch: 225, Loss: 0.0699\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0602\n",
            "root        : INFO     Epoch: 11, Batch: 275, Loss: 0.0562\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0666\n",
            "root        : INFO     Epoch: 11, Batch: 325, Loss: 0.0564\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.1032\n",
            "root        : INFO     Epoch: 11, Batch: 375, Loss: 0.0734\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.1199\n",
            "root        : INFO     Epoch: 11, Batch: 425, Loss: 0.0959\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0539\n",
            "root        : INFO     Epoch: 11, Batch: 475, Loss: 0.0705\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0619\n",
            "root        : INFO     Epoch: 11, Batch: 525, Loss: 0.0597\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0989\n",
            "root        : INFO     Epoch: 11, Batch: 575, Loss: 0.0685\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.1085\n",
            "root        : INFO     Epoch: 11, Batch: 625, Loss: 0.0996\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0705\n",
            "root        : INFO     Epoch: 11, Batch: 675, Loss: 0.0600\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0505\n",
            "root        : INFO     Epoch: 11, Batch: 725, Loss: 0.0743\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0515\n",
            "root        : INFO     Epoch: 11, Batch: 775, Loss: 0.0602\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0508\n",
            "root        : INFO     Epoch: 11, Batch: 825, Loss: 0.0621\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.1131\n",
            "root        : INFO     Epoch: 11, Batch: 875, Loss: 0.0667\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 25, Loss: 0.0407\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.1017\n",
            "root        : INFO     Epoch: 12, Batch: 75, Loss: 0.0717\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.1375\n",
            "root        : INFO     Epoch: 12, Batch: 125, Loss: 0.0596\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0734\n",
            "root        : INFO     Epoch: 12, Batch: 175, Loss: 0.0658\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0415\n",
            "root        : INFO     Epoch: 12, Batch: 225, Loss: 0.1415\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0642\n",
            "root        : INFO     Epoch: 12, Batch: 275, Loss: 0.0522\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1138, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train_network_it.py\", line 369, in <module>\n",
            "    run()\n",
            "  File \"train_network_it.py\", line 339, in run\n",
            "    train_results = train(epoch, net, device, train_data, optimizer, args.batches_per_epoch, vis=args.vis)\n",
            "  File \"train_network_it.py\", line 163, in train\n",
            "    for x, y, _, _, _ in train_data:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
            "    return data\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/profiler.py\", line 621, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFqlvKU-iME0"
      },
      "source": [
        "**4. Evaluate2 the 4th, Object-Wise ds-rotate=0.6**\n",
        "**Achievd 0.966**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3oqOVmmhqB6",
        "outputId": "00492a7f-6198-4548-a3ce-2c9da61362b4"
      },
      "source": [
        "!python evaluate2.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_00_iou_0.97 /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_04_iou_0.97 /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_12_iou_0.97 /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_13_iou_0.96 /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_16_iou_0.96 /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_20_iou_0.96 /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_23_iou_0.96  --dataset cornell --dataset-path /content/cornell_dataset --num-workers 8 --split 0.8 --ds-rotate 0.6 --iou-eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 177\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_00_iou_0.97\n",
            "INFO:root:Average evaluation time per image: 108.9630490642483ms\n",
            "INFO:root:IOU Results: 171/177 = 0.966102\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_04_iou_0.97\n",
            "INFO:root:Average evaluation time per image: 112.368862507707ms\n",
            "INFO:root:IOU Results: 166/177 = 0.937853\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_12_iou_0.97\n",
            "INFO:root:Average evaluation time per image: 111.13976624052403ms\n",
            "INFO:root:IOU Results: 165/177 = 0.932203\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_13_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 110.59224807609947ms\n",
            "INFO:root:IOU Results: 165/177 = 0.932203\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_16_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 111.2294345252258ms\n",
            "INFO:root:IOU Results: 164/177 = 0.926554\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_20_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 111.20506060325492ms\n",
            "INFO:root:IOU Results: 167/177 = 0.943503\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210412_0930_training_cornell/epoch_23_iou_0.96\n",
            "INFO:root:Average evaluation time per image: 112.84676110003628ms\n",
            "INFO:root:IOU Results: 165/177 = 0.932203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXTUZrpiHX5n"
      },
      "source": [
        "5. without augmentation image wise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbkqtV8eHG_0",
        "outputId": "ee800e4a-1e0c-42c6-cd4c-7483556ad08f"
      },
      "source": [
        "!python train_network_i.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --num-workers 8 --batch-size 8 --batches-per-epoch 89 --split 0.8  --ds-rotate 0.8 --augment 0 --lr=0.001 --epochs 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.80, ds-shuffle=1, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 50, batch size = 8, bacthes per epoch = 89, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210414_2040_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1279\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.1473\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.1324\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.0759\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     79/177 = 0.446328\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0673\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0830\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0799\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0863\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     70/177 = 0.395480\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0654\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0990\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.1059\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.1110\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     80/177 = 0.451977\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0739\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0943\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0570\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0922\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     82/177 = 0.463277\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0468\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0509\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0732\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0406\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     95/177 = 0.536723\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0480\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.1001\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0614\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0688\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     115/177 = 0.649718\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0912\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0373\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0836\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0465\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     107/177 = 0.604520\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0346\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0631\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0859\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0593\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     113/177 = 0.638418\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0585\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.1050\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.0722\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0374\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.0617\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0474\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0804\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.0489\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     113/177 = 0.638418\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0789\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0569\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0425\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0566\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0637\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0368\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0472\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0830\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     104/177 = 0.587571\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0553\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0508\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0721\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.0512\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     117/177 = 0.661017\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0312\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0358\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0505\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.0574\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     142/177 = 0.802260\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0579\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0484\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0512\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0446\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     134/177 = 0.757062\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.0803\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0538\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0357\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0374\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     133/177 = 0.751412\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0417\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0874\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0328\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0331\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0521\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0342\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0525\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0599\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0622\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0719\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0509\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0878\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.0755\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.0480\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0372\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.0653\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.0365\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.0411\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0640\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0479\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0476\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0360\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.0437\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.0500\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0571\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.0263\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0424\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0596\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.0370\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0239\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0450\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0428\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0500\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0476\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0400\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0506\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0383\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0380\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0715\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0373\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0543\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0465\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.0503\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0352\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     149/177 = 0.841808\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0516\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.0622\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0339\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0367\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0423\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0368\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0627\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0608\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0431\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.0687\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0607\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0318\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 20, Loss: 0.0646\n",
            "root        : INFO     Epoch: 30, Batch: 40, Loss: 0.0502\n",
            "root        : INFO     Epoch: 30, Batch: 60, Loss: 0.0494\n",
            "root        : INFO     Epoch: 30, Batch: 80, Loss: 0.0349\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 20, Loss: 0.0351\n",
            "root        : INFO     Epoch: 31, Batch: 40, Loss: 0.0392\n",
            "root        : INFO     Epoch: 31, Batch: 60, Loss: 0.0542\n",
            "root        : INFO     Epoch: 31, Batch: 80, Loss: 0.0390\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 20, Loss: 0.0461\n",
            "root        : INFO     Epoch: 32, Batch: 40, Loss: 0.0398\n",
            "root        : INFO     Epoch: 32, Batch: 60, Loss: 0.0615\n",
            "root        : INFO     Epoch: 32, Batch: 80, Loss: 0.0357\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 20, Loss: 0.0237\n",
            "root        : INFO     Epoch: 33, Batch: 40, Loss: 0.0386\n",
            "root        : INFO     Epoch: 33, Batch: 60, Loss: 0.0428\n",
            "root        : INFO     Epoch: 33, Batch: 80, Loss: 0.0477\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 20, Loss: 0.0631\n",
            "root        : INFO     Epoch: 34, Batch: 40, Loss: 0.0503\n",
            "root        : INFO     Epoch: 34, Batch: 60, Loss: 0.0515\n",
            "root        : INFO     Epoch: 34, Batch: 80, Loss: 0.0359\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 20, Loss: 0.0369\n",
            "root        : INFO     Epoch: 35, Batch: 40, Loss: 0.0272\n",
            "root        : INFO     Epoch: 35, Batch: 60, Loss: 0.0430\n",
            "root        : INFO     Epoch: 35, Batch: 80, Loss: 0.0520\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 20, Loss: 0.0495\n",
            "root        : INFO     Epoch: 36, Batch: 40, Loss: 0.0314\n",
            "root        : INFO     Epoch: 36, Batch: 60, Loss: 0.0341\n",
            "root        : INFO     Epoch: 36, Batch: 80, Loss: 0.0304\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 20, Loss: 0.0482\n",
            "root        : INFO     Epoch: 37, Batch: 40, Loss: 0.0552\n",
            "root        : INFO     Epoch: 37, Batch: 60, Loss: 0.0521\n",
            "root        : INFO     Epoch: 37, Batch: 80, Loss: 0.0311\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     160/177 = 0.903955\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 20, Loss: 0.0332\n",
            "root        : INFO     Epoch: 38, Batch: 40, Loss: 0.0495\n",
            "root        : INFO     Epoch: 38, Batch: 60, Loss: 0.0435\n",
            "root        : INFO     Epoch: 38, Batch: 80, Loss: 0.0516\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 20, Loss: 0.0367\n",
            "root        : INFO     Epoch: 39, Batch: 40, Loss: 0.0361\n",
            "root        : INFO     Epoch: 39, Batch: 60, Loss: 0.0545\n",
            "root        : INFO     Epoch: 39, Batch: 80, Loss: 0.0301\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     157/177 = 0.887006\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 20, Loss: 0.0394\n",
            "root        : INFO     Epoch: 40, Batch: 40, Loss: 0.0163\n",
            "root        : INFO     Epoch: 40, Batch: 60, Loss: 0.0395\n",
            "root        : INFO     Epoch: 40, Batch: 80, Loss: 0.0449\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 20, Loss: 0.0287\n",
            "root        : INFO     Epoch: 41, Batch: 40, Loss: 0.0460\n",
            "root        : INFO     Epoch: 41, Batch: 60, Loss: 0.0468\n",
            "root        : INFO     Epoch: 41, Batch: 80, Loss: 0.0716\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 20, Loss: 0.0298\n",
            "root        : INFO     Epoch: 42, Batch: 40, Loss: 0.0476\n",
            "root        : INFO     Epoch: 42, Batch: 60, Loss: 0.0202\n",
            "root        : INFO     Epoch: 42, Batch: 80, Loss: 0.0411\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 20, Loss: 0.0348\n",
            "root        : INFO     Epoch: 43, Batch: 40, Loss: 0.0311\n",
            "root        : INFO     Epoch: 43, Batch: 60, Loss: 0.0299\n",
            "root        : INFO     Epoch: 43, Batch: 80, Loss: 0.0423\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 20, Loss: 0.0195\n",
            "root        : INFO     Epoch: 44, Batch: 40, Loss: 0.0433\n",
            "root        : INFO     Epoch: 44, Batch: 60, Loss: 0.0628\n",
            "root        : INFO     Epoch: 44, Batch: 80, Loss: 0.0435\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 20, Loss: 0.0569\n",
            "root        : INFO     Epoch: 45, Batch: 40, Loss: 0.0232\n",
            "root        : INFO     Epoch: 45, Batch: 60, Loss: 0.0277\n",
            "root        : INFO     Epoch: 45, Batch: 80, Loss: 0.0390\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     146/177 = 0.824859\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 20, Loss: 0.0768\n",
            "root        : INFO     Epoch: 46, Batch: 40, Loss: 0.0530\n",
            "root        : INFO     Epoch: 46, Batch: 60, Loss: 0.0464\n",
            "root        : INFO     Epoch: 46, Batch: 80, Loss: 0.0301\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 20, Loss: 0.0366\n",
            "root        : INFO     Epoch: 47, Batch: 40, Loss: 0.0448\n",
            "root        : INFO     Epoch: 47, Batch: 60, Loss: 0.0504\n",
            "root        : INFO     Epoch: 47, Batch: 80, Loss: 0.0361\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/177 = 0.819209\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 20, Loss: 0.0371\n",
            "root        : INFO     Epoch: 48, Batch: 40, Loss: 0.0332\n",
            "root        : INFO     Epoch: 48, Batch: 60, Loss: 0.0282\n",
            "root        : INFO     Epoch: 48, Batch: 80, Loss: 0.0543\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 20, Loss: 0.0810\n",
            "root        : INFO     Epoch: 49, Batch: 40, Loss: 0.0469\n",
            "root        : INFO     Epoch: 49, Batch: 60, Loss: 0.0588\n",
            "root        : INFO     Epoch: 49, Batch: 80, Loss: 0.0308\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBJE6qlJDIPo"
      },
      "source": [
        "**5. ds-rotate =0.8, Object-Wise, batchsize=8, Adam, learning rate =0.001, channel size 32**  \n",
        "**Achieved 0.949, and 0.96 when evaluate the trained net**\n",
        "需要继续训练\n",
        "\n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_1516_training_cornell  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cByj4eFIC7ux",
        "outputId": "3367fd38-6c70-4526-c2b0-2e524cb5b06f"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.8 --lr=0.001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.80, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.1238\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0873\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1618\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1155\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.1795\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1410\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1347\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1148\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.1125\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.1284\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0749\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1381\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.0901\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.1112\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.0969\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1221\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.1055\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     45/177 = 0.254237\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.1308\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0821\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.1196\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0952\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.1059\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1599\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1023\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0877\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.1094\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0914\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.0787\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.1068\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0950\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0788\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.1109\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0949\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.1131\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     124/177 = 0.700565\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.1085\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0902\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0618\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0848\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1079\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0992\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0946\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.1119\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0670\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0988\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.0904\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0472\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.0958\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.1167\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.1112\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0984\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.1633\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     147/177 = 0.830508\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.1379\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1304\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.1161\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0797\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0466\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0745\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0707\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.1026\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0970\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0646\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.0695\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0654\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0792\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0878\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0776\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0672\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0932\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0494\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0735\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.1273\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0745\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.1110\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1059\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.1101\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0827\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.0981\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.1282\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.1417\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0837\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.1221\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0747\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0698\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.1070\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0696\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0932\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0773\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0831\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0731\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0699\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0862\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0765\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0926\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0849\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.1315\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0953\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0564\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.0737\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.1246\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0567\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0541\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.1047\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0794\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.1172\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0555\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.1000\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0582\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.1324\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0911\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0604\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0990\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0958\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0498\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0714\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0997\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0633\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0518\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0784\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0777\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0539\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0734\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0837\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0995\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0561\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0909\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0597\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.1104\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0816\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.1092\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.1103\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0422\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0909\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.1297\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0860\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0855\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0880\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     161/177 = 0.909605\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.1270\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0509\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0671\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0870\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0588\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0698\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0672\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0834\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0497\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0706\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0791\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0575\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.1284\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0557\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0593\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0913\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0840\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/177 = 0.937853\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0846\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0673\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.1185\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0524\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0509\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0512\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0852\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0529\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0637\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0654\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0853\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.1038\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.1422\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.1024\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0713\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0576\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0848\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     164/177 = 0.926554\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0557\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0792\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0592\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0510\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.1088\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.1850\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.1566\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0737\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.1082\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0943\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.1239\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0760\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0979\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0703\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.1194\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.1224\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0871\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0667\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0577\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.1057\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0793\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0829\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.1442\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0949\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0519\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0617\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0768\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0830\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.1045\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0721\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0736\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.1132\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0878\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.1197\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     154/177 = 0.870056\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0789\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0529\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0844\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0722\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0418\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.1347\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0642\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0614\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.0663\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0549\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0806\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0675\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0773\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0775\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0926\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0734\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0623\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     163/177 = 0.920904\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0739\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0883\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0577\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.1023\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0484\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.1145\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0690\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.1554\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.0631\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0466\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.0689\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0701\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0639\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XU9U_oYGFy2",
        "outputId": "e56fc28c-41fd-471a-8f3f-0481a1c6f883"
      },
      "source": [
        "!python evaluate2.py --network /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_1516_training_cornell/epoch_14_iou_0.95 --dataset cornell --dataset-path /content/cornell_dataset --num-workers 8 --split 0.8 --ds-rotate 0.8 --iou-eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:CUDA detected. Running with GPU acceleration.\n",
            "INFO:root:Loading Cornell Dataset...\n",
            "INFO:root:Validation size: 177\n",
            "INFO:root:Done\n",
            "INFO:root:\n",
            "Evaluating model /content/drive/MyDrive/GR_ConvNet_Code/logs/210408_1516_training_cornell/epoch_14_iou_0.95\n",
            "INFO:root:Average evaluation time per image: 108.31071023887161ms\n",
            "INFO:root:IOU Results: 170/177 = 0.960452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbkV9KDkVOAw"
      },
      "source": [
        "**5. ds-rotate =0.8, Image-Wise, batchsize=8, Adam, learning rate =0.001, channel size 32, train_network4.py **  \n",
        "**Achieved 0.898**\n",
        "\n",
        "logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210411_0857_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kbkfYCyVRNw",
        "outputId": "5b5532db-96a4-40c1-d4ba-30c663d53e03"
      },
      "source": [
        "!python train_network4.py --dataset cornell --dataset-path /content/cornell_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.8 --lr=0.001 --augment 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla T4, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.80, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210411_0857_training_cornell\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.1995\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.1996\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.1461\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.1384\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.2014\n",
            "root        : INFO     Epoch: 0, Batch: 120, Loss: 0.1164\n",
            "root        : INFO     Epoch: 0, Batch: 140, Loss: 0.1040\n",
            "root        : INFO     Epoch: 0, Batch: 160, Loss: 0.0848\n",
            "root        : INFO     Epoch: 0, Batch: 180, Loss: 0.0891\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1211\n",
            "root        : INFO     Epoch: 0, Batch: 220, Loss: 0.0948\n",
            "root        : INFO     Epoch: 0, Batch: 240, Loss: 0.1430\n",
            "root        : INFO     Epoch: 0, Batch: 260, Loss: 0.1454\n",
            "root        : INFO     Epoch: 0, Batch: 280, Loss: 0.1253\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1307\n",
            "root        : INFO     Epoch: 0, Batch: 320, Loss: 0.1943\n",
            "root        : INFO     Epoch: 0, Batch: 340, Loss: 0.0708\n",
            "root        : INFO     Epoch: 0, Batch: 360, Loss: 0.1047\n",
            "root        : INFO     Epoch: 0, Batch: 380, Loss: 0.0888\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0936\n",
            "root        : INFO     Epoch: 0, Batch: 420, Loss: 0.1536\n",
            "root        : INFO     Epoch: 0, Batch: 440, Loss: 0.1054\n",
            "root        : INFO     Epoch: 0, Batch: 460, Loss: 0.1059\n",
            "root        : INFO     Epoch: 0, Batch: 480, Loss: 0.1494\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.1085\n",
            "root        : INFO     Epoch: 0, Batch: 520, Loss: 0.1335\n",
            "root        : INFO     Epoch: 0, Batch: 540, Loss: 0.1023\n",
            "root        : INFO     Epoch: 0, Batch: 560, Loss: 0.1095\n",
            "root        : INFO     Epoch: 0, Batch: 580, Loss: 0.0933\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.1119\n",
            "root        : INFO     Epoch: 0, Batch: 620, Loss: 0.1210\n",
            "root        : INFO     Epoch: 0, Batch: 640, Loss: 0.0717\n",
            "root        : INFO     Epoch: 0, Batch: 660, Loss: 0.1007\n",
            "root        : INFO     Epoch: 0, Batch: 680, Loss: 0.1237\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.1474\n",
            "root        : INFO     Epoch: 0, Batch: 720, Loss: 0.0617\n",
            "root        : INFO     Epoch: 0, Batch: 740, Loss: 0.0613\n",
            "root        : INFO     Epoch: 0, Batch: 760, Loss: 0.0999\n",
            "root        : INFO     Epoch: 0, Batch: 780, Loss: 0.0565\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1248\n",
            "root        : INFO     Epoch: 0, Batch: 820, Loss: 0.1124\n",
            "root        : INFO     Epoch: 0, Batch: 840, Loss: 0.1624\n",
            "root        : INFO     Epoch: 0, Batch: 860, Loss: 0.1448\n",
            "root        : INFO     Epoch: 0, Batch: 880, Loss: 0.1569\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     120/177 = 0.677966\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0819\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.1129\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0915\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.1011\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0914\n",
            "root        : INFO     Epoch: 1, Batch: 120, Loss: 0.0825\n",
            "root        : INFO     Epoch: 1, Batch: 140, Loss: 0.1289\n",
            "root        : INFO     Epoch: 1, Batch: 160, Loss: 0.0636\n",
            "root        : INFO     Epoch: 1, Batch: 180, Loss: 0.1882\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0998\n",
            "root        : INFO     Epoch: 1, Batch: 220, Loss: 0.0574\n",
            "root        : INFO     Epoch: 1, Batch: 240, Loss: 0.0658\n",
            "root        : INFO     Epoch: 1, Batch: 260, Loss: 0.0429\n",
            "root        : INFO     Epoch: 1, Batch: 280, Loss: 0.1179\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1107\n",
            "root        : INFO     Epoch: 1, Batch: 320, Loss: 0.0995\n",
            "root        : INFO     Epoch: 1, Batch: 340, Loss: 0.0762\n",
            "root        : INFO     Epoch: 1, Batch: 360, Loss: 0.1006\n",
            "root        : INFO     Epoch: 1, Batch: 380, Loss: 0.0993\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.1254\n",
            "root        : INFO     Epoch: 1, Batch: 420, Loss: 0.0906\n",
            "root        : INFO     Epoch: 1, Batch: 440, Loss: 0.0737\n",
            "root        : INFO     Epoch: 1, Batch: 460, Loss: 0.1757\n",
            "root        : INFO     Epoch: 1, Batch: 480, Loss: 0.1103\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0768\n",
            "root        : INFO     Epoch: 1, Batch: 520, Loss: 0.1089\n",
            "root        : INFO     Epoch: 1, Batch: 540, Loss: 0.1065\n",
            "root        : INFO     Epoch: 1, Batch: 560, Loss: 0.0769\n",
            "root        : INFO     Epoch: 1, Batch: 580, Loss: 0.0745\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0749\n",
            "root        : INFO     Epoch: 1, Batch: 620, Loss: 0.0812\n",
            "root        : INFO     Epoch: 1, Batch: 640, Loss: 0.1074\n",
            "root        : INFO     Epoch: 1, Batch: 660, Loss: 0.4535\n",
            "root        : INFO     Epoch: 1, Batch: 680, Loss: 0.1043\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.1146\n",
            "root        : INFO     Epoch: 1, Batch: 720, Loss: 0.1128\n",
            "root        : INFO     Epoch: 1, Batch: 740, Loss: 0.0862\n",
            "root        : INFO     Epoch: 1, Batch: 760, Loss: 0.1203\n",
            "root        : INFO     Epoch: 1, Batch: 780, Loss: 0.0878\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0541\n",
            "root        : INFO     Epoch: 1, Batch: 820, Loss: 0.0688\n",
            "root        : INFO     Epoch: 1, Batch: 840, Loss: 0.1669\n",
            "root        : INFO     Epoch: 1, Batch: 860, Loss: 0.0835\n",
            "root        : INFO     Epoch: 1, Batch: 880, Loss: 0.1243\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     67/177 = 0.378531\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0994\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.1142\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.1063\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.1080\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1107\n",
            "root        : INFO     Epoch: 2, Batch: 120, Loss: 0.0762\n",
            "root        : INFO     Epoch: 2, Batch: 140, Loss: 0.1017\n",
            "root        : INFO     Epoch: 2, Batch: 160, Loss: 0.1283\n",
            "root        : INFO     Epoch: 2, Batch: 180, Loss: 0.1146\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0815\n",
            "root        : INFO     Epoch: 2, Batch: 220, Loss: 0.1580\n",
            "root        : INFO     Epoch: 2, Batch: 240, Loss: 0.0811\n",
            "root        : INFO     Epoch: 2, Batch: 260, Loss: 0.0560\n",
            "root        : INFO     Epoch: 2, Batch: 280, Loss: 0.0876\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.1071\n",
            "root        : INFO     Epoch: 2, Batch: 320, Loss: 0.1365\n",
            "root        : INFO     Epoch: 2, Batch: 340, Loss: 0.0924\n",
            "root        : INFO     Epoch: 2, Batch: 360, Loss: 0.0853\n",
            "root        : INFO     Epoch: 2, Batch: 380, Loss: 0.1113\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0743\n",
            "root        : INFO     Epoch: 2, Batch: 420, Loss: 0.1430\n",
            "root        : INFO     Epoch: 2, Batch: 440, Loss: 0.0904\n",
            "root        : INFO     Epoch: 2, Batch: 460, Loss: 0.1076\n",
            "root        : INFO     Epoch: 2, Batch: 480, Loss: 0.0972\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0960\n",
            "root        : INFO     Epoch: 2, Batch: 520, Loss: 0.0590\n",
            "root        : INFO     Epoch: 2, Batch: 540, Loss: 0.0945\n",
            "root        : INFO     Epoch: 2, Batch: 560, Loss: 0.0753\n",
            "root        : INFO     Epoch: 2, Batch: 580, Loss: 0.1344\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0755\n",
            "root        : INFO     Epoch: 2, Batch: 620, Loss: 0.1078\n",
            "root        : INFO     Epoch: 2, Batch: 640, Loss: 0.0669\n",
            "root        : INFO     Epoch: 2, Batch: 660, Loss: 0.1180\n",
            "root        : INFO     Epoch: 2, Batch: 680, Loss: 0.0640\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.1091\n",
            "root        : INFO     Epoch: 2, Batch: 720, Loss: 0.0657\n",
            "root        : INFO     Epoch: 2, Batch: 740, Loss: 0.1052\n",
            "root        : INFO     Epoch: 2, Batch: 760, Loss: 0.1123\n",
            "root        : INFO     Epoch: 2, Batch: 780, Loss: 0.0744\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0852\n",
            "root        : INFO     Epoch: 2, Batch: 820, Loss: 0.0539\n",
            "root        : INFO     Epoch: 2, Batch: 840, Loss: 0.1027\n",
            "root        : INFO     Epoch: 2, Batch: 860, Loss: 0.1144\n",
            "root        : INFO     Epoch: 2, Batch: 880, Loss: 0.1565\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     139/177 = 0.785311\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.1077\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0582\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.1038\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0650\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1053\n",
            "root        : INFO     Epoch: 3, Batch: 120, Loss: 0.1342\n",
            "root        : INFO     Epoch: 3, Batch: 140, Loss: 0.0969\n",
            "root        : INFO     Epoch: 3, Batch: 160, Loss: 0.0886\n",
            "root        : INFO     Epoch: 3, Batch: 180, Loss: 0.0878\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.1164\n",
            "root        : INFO     Epoch: 3, Batch: 220, Loss: 0.1188\n",
            "root        : INFO     Epoch: 3, Batch: 240, Loss: 0.1355\n",
            "root        : INFO     Epoch: 3, Batch: 260, Loss: 0.0837\n",
            "root        : INFO     Epoch: 3, Batch: 280, Loss: 0.0903\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0845\n",
            "root        : INFO     Epoch: 3, Batch: 320, Loss: 0.1287\n",
            "root        : INFO     Epoch: 3, Batch: 340, Loss: 0.0778\n",
            "root        : INFO     Epoch: 3, Batch: 360, Loss: 0.0874\n",
            "root        : INFO     Epoch: 3, Batch: 380, Loss: 0.0949\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0947\n",
            "root        : INFO     Epoch: 3, Batch: 420, Loss: 0.1811\n",
            "root        : INFO     Epoch: 3, Batch: 440, Loss: 0.1057\n",
            "root        : INFO     Epoch: 3, Batch: 460, Loss: 0.1283\n",
            "root        : INFO     Epoch: 3, Batch: 480, Loss: 0.0907\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0611\n",
            "root        : INFO     Epoch: 3, Batch: 520, Loss: 0.0948\n",
            "root        : INFO     Epoch: 3, Batch: 540, Loss: 0.0935\n",
            "root        : INFO     Epoch: 3, Batch: 560, Loss: 0.0879\n",
            "root        : INFO     Epoch: 3, Batch: 580, Loss: 0.1043\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.1037\n",
            "root        : INFO     Epoch: 3, Batch: 620, Loss: 0.1203\n",
            "root        : INFO     Epoch: 3, Batch: 640, Loss: 0.1007\n",
            "root        : INFO     Epoch: 3, Batch: 660, Loss: 0.1246\n",
            "root        : INFO     Epoch: 3, Batch: 680, Loss: 0.1139\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0897\n",
            "root        : INFO     Epoch: 3, Batch: 720, Loss: 0.1003\n",
            "root        : INFO     Epoch: 3, Batch: 740, Loss: 0.0829\n",
            "root        : INFO     Epoch: 3, Batch: 760, Loss: 0.0897\n",
            "root        : INFO     Epoch: 3, Batch: 780, Loss: 0.1124\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0899\n",
            "root        : INFO     Epoch: 3, Batch: 820, Loss: 0.1018\n",
            "root        : INFO     Epoch: 3, Batch: 840, Loss: 0.0579\n",
            "root        : INFO     Epoch: 3, Batch: 860, Loss: 0.0721\n",
            "root        : INFO     Epoch: 3, Batch: 880, Loss: 0.0521\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0916\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0688\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0889\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0693\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0806\n",
            "root        : INFO     Epoch: 4, Batch: 120, Loss: 0.0746\n",
            "root        : INFO     Epoch: 4, Batch: 140, Loss: 0.1063\n",
            "root        : INFO     Epoch: 4, Batch: 160, Loss: 0.1134\n",
            "root        : INFO     Epoch: 4, Batch: 180, Loss: 0.0897\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0803\n",
            "root        : INFO     Epoch: 4, Batch: 220, Loss: 0.0910\n",
            "root        : INFO     Epoch: 4, Batch: 240, Loss: 0.0964\n",
            "root        : INFO     Epoch: 4, Batch: 260, Loss: 0.0554\n",
            "root        : INFO     Epoch: 4, Batch: 280, Loss: 0.0636\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0678\n",
            "root        : INFO     Epoch: 4, Batch: 320, Loss: 0.1104\n",
            "root        : INFO     Epoch: 4, Batch: 340, Loss: 0.0958\n",
            "root        : INFO     Epoch: 4, Batch: 360, Loss: 0.0790\n",
            "root        : INFO     Epoch: 4, Batch: 380, Loss: 0.0898\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.1232\n",
            "root        : INFO     Epoch: 4, Batch: 420, Loss: 0.1103\n",
            "root        : INFO     Epoch: 4, Batch: 440, Loss: 0.1275\n",
            "root        : INFO     Epoch: 4, Batch: 460, Loss: 0.0670\n",
            "root        : INFO     Epoch: 4, Batch: 480, Loss: 0.0776\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0926\n",
            "root        : INFO     Epoch: 4, Batch: 520, Loss: 0.0882\n",
            "root        : INFO     Epoch: 4, Batch: 540, Loss: 0.0772\n",
            "root        : INFO     Epoch: 4, Batch: 560, Loss: 0.0645\n",
            "root        : INFO     Epoch: 4, Batch: 580, Loss: 0.0865\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0591\n",
            "root        : INFO     Epoch: 4, Batch: 620, Loss: 0.0785\n",
            "root        : INFO     Epoch: 4, Batch: 640, Loss: 0.0890\n",
            "root        : INFO     Epoch: 4, Batch: 660, Loss: 0.0543\n",
            "root        : INFO     Epoch: 4, Batch: 680, Loss: 0.0736\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0897\n",
            "root        : INFO     Epoch: 4, Batch: 720, Loss: 0.0785\n",
            "root        : INFO     Epoch: 4, Batch: 740, Loss: 0.0738\n",
            "root        : INFO     Epoch: 4, Batch: 760, Loss: 0.1353\n",
            "root        : INFO     Epoch: 4, Batch: 780, Loss: 0.0732\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0811\n",
            "root        : INFO     Epoch: 4, Batch: 820, Loss: 0.1094\n",
            "root        : INFO     Epoch: 4, Batch: 840, Loss: 0.0774\n",
            "root        : INFO     Epoch: 4, Batch: 860, Loss: 0.0839\n",
            "root        : INFO     Epoch: 4, Batch: 880, Loss: 0.0753\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     143/177 = 0.807910\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.1613\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0596\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0879\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0880\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.1321\n",
            "root        : INFO     Epoch: 5, Batch: 120, Loss: 0.0574\n",
            "root        : INFO     Epoch: 5, Batch: 140, Loss: 0.0735\n",
            "root        : INFO     Epoch: 5, Batch: 160, Loss: 0.0871\n",
            "root        : INFO     Epoch: 5, Batch: 180, Loss: 0.0595\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0684\n",
            "root        : INFO     Epoch: 5, Batch: 220, Loss: 0.0675\n",
            "root        : INFO     Epoch: 5, Batch: 240, Loss: 0.0766\n",
            "root        : INFO     Epoch: 5, Batch: 260, Loss: 0.0619\n",
            "root        : INFO     Epoch: 5, Batch: 280, Loss: 0.1086\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.1426\n",
            "root        : INFO     Epoch: 5, Batch: 320, Loss: 0.0745\n",
            "root        : INFO     Epoch: 5, Batch: 340, Loss: 0.1103\n",
            "root        : INFO     Epoch: 5, Batch: 360, Loss: 0.0443\n",
            "root        : INFO     Epoch: 5, Batch: 380, Loss: 0.1084\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0771\n",
            "root        : INFO     Epoch: 5, Batch: 420, Loss: 0.0608\n",
            "root        : INFO     Epoch: 5, Batch: 440, Loss: 0.1105\n",
            "root        : INFO     Epoch: 5, Batch: 460, Loss: 0.0921\n",
            "root        : INFO     Epoch: 5, Batch: 480, Loss: 0.0645\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0753\n",
            "root        : INFO     Epoch: 5, Batch: 520, Loss: 0.0811\n",
            "root        : INFO     Epoch: 5, Batch: 540, Loss: 0.0911\n",
            "root        : INFO     Epoch: 5, Batch: 560, Loss: 0.0783\n",
            "root        : INFO     Epoch: 5, Batch: 580, Loss: 0.0688\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0733\n",
            "root        : INFO     Epoch: 5, Batch: 620, Loss: 0.0633\n",
            "root        : INFO     Epoch: 5, Batch: 640, Loss: 0.0711\n",
            "root        : INFO     Epoch: 5, Batch: 660, Loss: 0.0923\n",
            "root        : INFO     Epoch: 5, Batch: 680, Loss: 0.0714\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0830\n",
            "root        : INFO     Epoch: 5, Batch: 720, Loss: 0.0973\n",
            "root        : INFO     Epoch: 5, Batch: 740, Loss: 0.0893\n",
            "root        : INFO     Epoch: 5, Batch: 760, Loss: 0.0863\n",
            "root        : INFO     Epoch: 5, Batch: 780, Loss: 0.0881\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0576\n",
            "root        : INFO     Epoch: 5, Batch: 820, Loss: 0.0632\n",
            "root        : INFO     Epoch: 5, Batch: 840, Loss: 0.1038\n",
            "root        : INFO     Epoch: 5, Batch: 860, Loss: 0.0880\n",
            "root        : INFO     Epoch: 5, Batch: 880, Loss: 0.1154\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     159/177 = 0.898305\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.1200\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0849\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0570\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0667\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.1143\n",
            "root        : INFO     Epoch: 6, Batch: 120, Loss: 0.1535\n",
            "root        : INFO     Epoch: 6, Batch: 140, Loss: 0.1192\n",
            "root        : INFO     Epoch: 6, Batch: 160, Loss: 0.0992\n",
            "root        : INFO     Epoch: 6, Batch: 180, Loss: 0.0762\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0869\n",
            "root        : INFO     Epoch: 6, Batch: 220, Loss: 0.1037\n",
            "root        : INFO     Epoch: 6, Batch: 240, Loss: 0.0633\n",
            "root        : INFO     Epoch: 6, Batch: 260, Loss: 0.0895\n",
            "root        : INFO     Epoch: 6, Batch: 280, Loss: 0.1109\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0748\n",
            "root        : INFO     Epoch: 6, Batch: 320, Loss: 0.1673\n",
            "root        : INFO     Epoch: 6, Batch: 340, Loss: 0.1392\n",
            "root        : INFO     Epoch: 6, Batch: 360, Loss: 0.0668\n",
            "root        : INFO     Epoch: 6, Batch: 380, Loss: 0.1242\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0925\n",
            "root        : INFO     Epoch: 6, Batch: 420, Loss: 0.0788\n",
            "root        : INFO     Epoch: 6, Batch: 440, Loss: 0.0631\n",
            "root        : INFO     Epoch: 6, Batch: 460, Loss: 0.0966\n",
            "root        : INFO     Epoch: 6, Batch: 480, Loss: 0.0915\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.1065\n",
            "root        : INFO     Epoch: 6, Batch: 520, Loss: 0.0961\n",
            "root        : INFO     Epoch: 6, Batch: 540, Loss: 0.0852\n",
            "root        : INFO     Epoch: 6, Batch: 560, Loss: 0.0991\n",
            "root        : INFO     Epoch: 6, Batch: 580, Loss: 0.0931\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0673\n",
            "root        : INFO     Epoch: 6, Batch: 620, Loss: 0.0561\n",
            "root        : INFO     Epoch: 6, Batch: 640, Loss: 0.0531\n",
            "root        : INFO     Epoch: 6, Batch: 660, Loss: 0.1215\n",
            "root        : INFO     Epoch: 6, Batch: 680, Loss: 0.0694\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0937\n",
            "root        : INFO     Epoch: 6, Batch: 720, Loss: 0.1167\n",
            "root        : INFO     Epoch: 6, Batch: 740, Loss: 0.1089\n",
            "root        : INFO     Epoch: 6, Batch: 760, Loss: 0.0994\n",
            "root        : INFO     Epoch: 6, Batch: 780, Loss: 0.0780\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0893\n",
            "root        : INFO     Epoch: 6, Batch: 820, Loss: 0.0638\n",
            "root        : INFO     Epoch: 6, Batch: 840, Loss: 0.0801\n",
            "root        : INFO     Epoch: 6, Batch: 860, Loss: 0.0822\n",
            "root        : INFO     Epoch: 6, Batch: 880, Loss: 0.1258\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     155/177 = 0.875706\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.1261\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.1159\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.0586\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.0837\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0843\n",
            "root        : INFO     Epoch: 7, Batch: 120, Loss: 0.0688\n",
            "root        : INFO     Epoch: 7, Batch: 140, Loss: 0.0859\n",
            "root        : INFO     Epoch: 7, Batch: 160, Loss: 0.1176\n",
            "root        : INFO     Epoch: 7, Batch: 180, Loss: 0.1015\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.1411\n",
            "root        : INFO     Epoch: 7, Batch: 220, Loss: 0.1238\n",
            "root        : INFO     Epoch: 7, Batch: 240, Loss: 0.0545\n",
            "root        : INFO     Epoch: 7, Batch: 260, Loss: 0.0988\n",
            "root        : INFO     Epoch: 7, Batch: 280, Loss: 0.0819\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0949\n",
            "root        : INFO     Epoch: 7, Batch: 320, Loss: 0.0586\n",
            "root        : INFO     Epoch: 7, Batch: 340, Loss: 0.0689\n",
            "root        : INFO     Epoch: 7, Batch: 360, Loss: 0.1563\n",
            "root        : INFO     Epoch: 7, Batch: 380, Loss: 0.1193\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0968\n",
            "root        : INFO     Epoch: 7, Batch: 420, Loss: 0.0544\n",
            "root        : INFO     Epoch: 7, Batch: 440, Loss: 0.0879\n",
            "root        : INFO     Epoch: 7, Batch: 460, Loss: 0.0634\n",
            "root        : INFO     Epoch: 7, Batch: 480, Loss: 0.0745\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0363\n",
            "root        : INFO     Epoch: 7, Batch: 520, Loss: 0.1070\n",
            "root        : INFO     Epoch: 7, Batch: 540, Loss: 0.0941\n",
            "root        : INFO     Epoch: 7, Batch: 560, Loss: 0.0878\n",
            "root        : INFO     Epoch: 7, Batch: 580, Loss: 0.0522\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0952\n",
            "root        : INFO     Epoch: 7, Batch: 620, Loss: 0.0735\n",
            "root        : INFO     Epoch: 7, Batch: 640, Loss: 0.1044\n",
            "root        : INFO     Epoch: 7, Batch: 660, Loss: 0.1008\n",
            "root        : INFO     Epoch: 7, Batch: 680, Loss: 0.0595\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.1279\n",
            "root        : INFO     Epoch: 7, Batch: 720, Loss: 0.0862\n",
            "root        : INFO     Epoch: 7, Batch: 740, Loss: 0.1048\n",
            "root        : INFO     Epoch: 7, Batch: 760, Loss: 0.0771\n",
            "root        : INFO     Epoch: 7, Batch: 780, Loss: 0.0925\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0994\n",
            "root        : INFO     Epoch: 7, Batch: 820, Loss: 0.1123\n",
            "root        : INFO     Epoch: 7, Batch: 840, Loss: 0.0810\n",
            "root        : INFO     Epoch: 7, Batch: 860, Loss: 0.0628\n",
            "root        : INFO     Epoch: 7, Batch: 880, Loss: 0.0666\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     150/177 = 0.847458\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0705\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.1342\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.1088\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.0676\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0506\n",
            "root        : INFO     Epoch: 8, Batch: 120, Loss: 0.0783\n",
            "root        : INFO     Epoch: 8, Batch: 140, Loss: 0.0672\n",
            "root        : INFO     Epoch: 8, Batch: 160, Loss: 0.1434\n",
            "root        : INFO     Epoch: 8, Batch: 180, Loss: 0.0687\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.1165\n",
            "root        : INFO     Epoch: 8, Batch: 220, Loss: 0.0681\n",
            "root        : INFO     Epoch: 8, Batch: 240, Loss: 0.0511\n",
            "root        : INFO     Epoch: 8, Batch: 260, Loss: 0.1159\n",
            "root        : INFO     Epoch: 8, Batch: 280, Loss: 0.0648\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.1464\n",
            "root        : INFO     Epoch: 8, Batch: 320, Loss: 0.0889\n",
            "root        : INFO     Epoch: 8, Batch: 340, Loss: 0.0967\n",
            "root        : INFO     Epoch: 8, Batch: 360, Loss: 0.0259\n",
            "root        : INFO     Epoch: 8, Batch: 380, Loss: 0.1162\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0686\n",
            "root        : INFO     Epoch: 8, Batch: 420, Loss: 0.0691\n",
            "root        : INFO     Epoch: 8, Batch: 440, Loss: 0.0612\n",
            "root        : INFO     Epoch: 8, Batch: 460, Loss: 0.0503\n",
            "root        : INFO     Epoch: 8, Batch: 480, Loss: 0.0618\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0672\n",
            "root        : INFO     Epoch: 8, Batch: 520, Loss: 0.1138\n",
            "root        : INFO     Epoch: 8, Batch: 540, Loss: 0.0696\n",
            "root        : INFO     Epoch: 8, Batch: 560, Loss: 0.1135\n",
            "root        : INFO     Epoch: 8, Batch: 580, Loss: 0.0711\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.1363\n",
            "root        : INFO     Epoch: 8, Batch: 620, Loss: 0.0386\n",
            "root        : INFO     Epoch: 8, Batch: 640, Loss: 0.0560\n",
            "root        : INFO     Epoch: 8, Batch: 660, Loss: 0.0501\n",
            "root        : INFO     Epoch: 8, Batch: 680, Loss: 0.1008\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.1345\n",
            "root        : INFO     Epoch: 8, Batch: 720, Loss: 0.0582\n",
            "root        : INFO     Epoch: 8, Batch: 740, Loss: 0.0699\n",
            "root        : INFO     Epoch: 8, Batch: 760, Loss: 0.0578\n",
            "root        : INFO     Epoch: 8, Batch: 780, Loss: 0.1088\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0844\n",
            "root        : INFO     Epoch: 8, Batch: 820, Loss: 0.0774\n",
            "root        : INFO     Epoch: 8, Batch: 840, Loss: 0.1144\n",
            "root        : INFO     Epoch: 8, Batch: 860, Loss: 0.0734\n",
            "root        : INFO     Epoch: 8, Batch: 880, Loss: 0.0718\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.1200\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.1053\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.1456\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.1017\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0816\n",
            "root        : INFO     Epoch: 9, Batch: 120, Loss: 0.0916\n",
            "root        : INFO     Epoch: 9, Batch: 140, Loss: 0.0925\n",
            "root        : INFO     Epoch: 9, Batch: 160, Loss: 0.0698\n",
            "root        : INFO     Epoch: 9, Batch: 180, Loss: 0.0914\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0860\n",
            "root        : INFO     Epoch: 9, Batch: 220, Loss: 0.0789\n",
            "root        : INFO     Epoch: 9, Batch: 240, Loss: 0.0972\n",
            "root        : INFO     Epoch: 9, Batch: 260, Loss: 0.0900\n",
            "root        : INFO     Epoch: 9, Batch: 280, Loss: 0.1499\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.1218\n",
            "root        : INFO     Epoch: 9, Batch: 320, Loss: 0.1033\n",
            "root        : INFO     Epoch: 9, Batch: 340, Loss: 0.1081\n",
            "root        : INFO     Epoch: 9, Batch: 360, Loss: 0.0631\n",
            "root        : INFO     Epoch: 9, Batch: 380, Loss: 0.0799\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0484\n",
            "root        : INFO     Epoch: 9, Batch: 420, Loss: 0.1256\n",
            "root        : INFO     Epoch: 9, Batch: 440, Loss: 0.0958\n",
            "root        : INFO     Epoch: 9, Batch: 460, Loss: 0.0978\n",
            "root        : INFO     Epoch: 9, Batch: 480, Loss: 0.1191\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0720\n",
            "root        : INFO     Epoch: 9, Batch: 520, Loss: 0.0888\n",
            "root        : INFO     Epoch: 9, Batch: 540, Loss: 0.0680\n",
            "root        : INFO     Epoch: 9, Batch: 560, Loss: 0.0704\n",
            "root        : INFO     Epoch: 9, Batch: 580, Loss: 0.0669\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0767\n",
            "root        : INFO     Epoch: 9, Batch: 620, Loss: 0.0685\n",
            "root        : INFO     Epoch: 9, Batch: 640, Loss: 0.0543\n",
            "root        : INFO     Epoch: 9, Batch: 660, Loss: 0.0548\n",
            "root        : INFO     Epoch: 9, Batch: 680, Loss: 0.0536\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.1743\n",
            "root        : INFO     Epoch: 9, Batch: 720, Loss: 0.0393\n",
            "root        : INFO     Epoch: 9, Batch: 740, Loss: 0.1083\n",
            "root        : INFO     Epoch: 9, Batch: 760, Loss: 0.0603\n",
            "root        : INFO     Epoch: 9, Batch: 780, Loss: 0.0533\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0560\n",
            "root        : INFO     Epoch: 9, Batch: 820, Loss: 0.0771\n",
            "root        : INFO     Epoch: 9, Batch: 840, Loss: 0.1188\n",
            "root        : INFO     Epoch: 9, Batch: 860, Loss: 0.1435\n",
            "root        : INFO     Epoch: 9, Batch: 880, Loss: 0.0684\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.0405\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.0815\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.0692\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.0692\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0670\n",
            "root        : INFO     Epoch: 10, Batch: 120, Loss: 0.1106\n",
            "root        : INFO     Epoch: 10, Batch: 140, Loss: 0.0740\n",
            "root        : INFO     Epoch: 10, Batch: 160, Loss: 0.0748\n",
            "root        : INFO     Epoch: 10, Batch: 180, Loss: 0.0499\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.1002\n",
            "root        : INFO     Epoch: 10, Batch: 220, Loss: 0.1594\n",
            "root        : INFO     Epoch: 10, Batch: 240, Loss: 0.0915\n",
            "root        : INFO     Epoch: 10, Batch: 260, Loss: 0.1052\n",
            "root        : INFO     Epoch: 10, Batch: 280, Loss: 0.1048\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0841\n",
            "root        : INFO     Epoch: 10, Batch: 320, Loss: 0.0491\n",
            "root        : INFO     Epoch: 10, Batch: 340, Loss: 0.0607\n",
            "root        : INFO     Epoch: 10, Batch: 360, Loss: 0.0615\n",
            "root        : INFO     Epoch: 10, Batch: 380, Loss: 0.0927\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0724\n",
            "root        : INFO     Epoch: 10, Batch: 420, Loss: 0.1040\n",
            "root        : INFO     Epoch: 10, Batch: 440, Loss: 0.0873\n",
            "root        : INFO     Epoch: 10, Batch: 460, Loss: 0.0675\n",
            "root        : INFO     Epoch: 10, Batch: 480, Loss: 0.0433\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0798\n",
            "root        : INFO     Epoch: 10, Batch: 520, Loss: 0.0947\n",
            "root        : INFO     Epoch: 10, Batch: 540, Loss: 0.1078\n",
            "root        : INFO     Epoch: 10, Batch: 560, Loss: 0.0667\n",
            "root        : INFO     Epoch: 10, Batch: 580, Loss: 0.0977\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0663\n",
            "root        : INFO     Epoch: 10, Batch: 620, Loss: 0.0869\n",
            "root        : INFO     Epoch: 10, Batch: 640, Loss: 0.0412\n",
            "root        : INFO     Epoch: 10, Batch: 660, Loss: 0.0567\n",
            "root        : INFO     Epoch: 10, Batch: 680, Loss: 0.1136\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0828\n",
            "root        : INFO     Epoch: 10, Batch: 720, Loss: 0.0570\n",
            "root        : INFO     Epoch: 10, Batch: 740, Loss: 0.0678\n",
            "root        : INFO     Epoch: 10, Batch: 760, Loss: 0.0467\n",
            "root        : INFO     Epoch: 10, Batch: 780, Loss: 0.1084\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.1035\n",
            "root        : INFO     Epoch: 10, Batch: 820, Loss: 0.0439\n",
            "root        : INFO     Epoch: 10, Batch: 840, Loss: 0.0404\n",
            "root        : INFO     Epoch: 10, Batch: 860, Loss: 0.0922\n",
            "root        : INFO     Epoch: 10, Batch: 880, Loss: 0.0798\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     156/177 = 0.881356\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.0583\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0619\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0756\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.0947\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.1071\n",
            "root        : INFO     Epoch: 11, Batch: 120, Loss: 0.0755\n",
            "root        : INFO     Epoch: 11, Batch: 140, Loss: 0.1077\n",
            "root        : INFO     Epoch: 11, Batch: 160, Loss: 0.0769\n",
            "root        : INFO     Epoch: 11, Batch: 180, Loss: 0.0585\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.1351\n",
            "root        : INFO     Epoch: 11, Batch: 220, Loss: 0.0465\n",
            "root        : INFO     Epoch: 11, Batch: 240, Loss: 0.0511\n",
            "root        : INFO     Epoch: 11, Batch: 260, Loss: 0.0752\n",
            "root        : INFO     Epoch: 11, Batch: 280, Loss: 0.0569\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0757\n",
            "root        : INFO     Epoch: 11, Batch: 320, Loss: 0.0963\n",
            "root        : INFO     Epoch: 11, Batch: 340, Loss: 0.1170\n",
            "root        : INFO     Epoch: 11, Batch: 360, Loss: 0.1301\n",
            "root        : INFO     Epoch: 11, Batch: 380, Loss: 0.0937\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0475\n",
            "root        : INFO     Epoch: 11, Batch: 420, Loss: 0.0759\n",
            "root        : INFO     Epoch: 11, Batch: 440, Loss: 0.1483\n",
            "root        : INFO     Epoch: 11, Batch: 460, Loss: 0.0496\n",
            "root        : INFO     Epoch: 11, Batch: 480, Loss: 0.0726\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.1177\n",
            "root        : INFO     Epoch: 11, Batch: 520, Loss: 0.0975\n",
            "root        : INFO     Epoch: 11, Batch: 540, Loss: 0.0696\n",
            "root        : INFO     Epoch: 11, Batch: 560, Loss: 0.0883\n",
            "root        : INFO     Epoch: 11, Batch: 580, Loss: 0.0779\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.1102\n",
            "root        : INFO     Epoch: 11, Batch: 620, Loss: 0.0346\n",
            "root        : INFO     Epoch: 11, Batch: 640, Loss: 0.0861\n",
            "root        : INFO     Epoch: 11, Batch: 660, Loss: 0.0666\n",
            "root        : INFO     Epoch: 11, Batch: 680, Loss: 0.0571\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0992\n",
            "root        : INFO     Epoch: 11, Batch: 720, Loss: 0.0759\n",
            "root        : INFO     Epoch: 11, Batch: 740, Loss: 0.0888\n",
            "root        : INFO     Epoch: 11, Batch: 760, Loss: 0.0462\n",
            "root        : INFO     Epoch: 11, Batch: 780, Loss: 0.0855\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0802\n",
            "root        : INFO     Epoch: 11, Batch: 820, Loss: 0.0835\n",
            "root        : INFO     Epoch: 11, Batch: 840, Loss: 0.0546\n",
            "root        : INFO     Epoch: 11, Batch: 860, Loss: 0.0606\n",
            "root        : INFO     Epoch: 11, Batch: 880, Loss: 0.1626\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.0839\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.0757\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0984\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.1017\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0733\n",
            "root        : INFO     Epoch: 12, Batch: 120, Loss: 0.0676\n",
            "root        : INFO     Epoch: 12, Batch: 140, Loss: 0.0891\n",
            "root        : INFO     Epoch: 12, Batch: 160, Loss: 0.1293\n",
            "root        : INFO     Epoch: 12, Batch: 180, Loss: 0.1192\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0911\n",
            "root        : INFO     Epoch: 12, Batch: 220, Loss: 0.0730\n",
            "root        : INFO     Epoch: 12, Batch: 240, Loss: 0.0476\n",
            "root        : INFO     Epoch: 12, Batch: 260, Loss: 0.0787\n",
            "root        : INFO     Epoch: 12, Batch: 280, Loss: 0.0588\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0867\n",
            "root        : INFO     Epoch: 12, Batch: 320, Loss: 0.0982\n",
            "root        : INFO     Epoch: 12, Batch: 340, Loss: 0.0674\n",
            "root        : INFO     Epoch: 12, Batch: 360, Loss: 0.0788\n",
            "root        : INFO     Epoch: 12, Batch: 380, Loss: 0.0915\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0882\n",
            "root        : INFO     Epoch: 12, Batch: 420, Loss: 0.0737\n",
            "root        : INFO     Epoch: 12, Batch: 440, Loss: 0.0824\n",
            "root        : INFO     Epoch: 12, Batch: 460, Loss: 0.1084\n",
            "root        : INFO     Epoch: 12, Batch: 480, Loss: 0.0458\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0959\n",
            "root        : INFO     Epoch: 12, Batch: 520, Loss: 0.0763\n",
            "root        : INFO     Epoch: 12, Batch: 540, Loss: 0.1135\n",
            "root        : INFO     Epoch: 12, Batch: 560, Loss: 0.0762\n",
            "root        : INFO     Epoch: 12, Batch: 580, Loss: 0.0376\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0582\n",
            "root        : INFO     Epoch: 12, Batch: 620, Loss: 0.0573\n",
            "root        : INFO     Epoch: 12, Batch: 640, Loss: 0.0554\n",
            "root        : INFO     Epoch: 12, Batch: 660, Loss: 0.1047\n",
            "root        : INFO     Epoch: 12, Batch: 680, Loss: 0.1031\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0576\n",
            "root        : INFO     Epoch: 12, Batch: 720, Loss: 0.1227\n",
            "root        : INFO     Epoch: 12, Batch: 740, Loss: 0.0554\n",
            "root        : INFO     Epoch: 12, Batch: 760, Loss: 0.0886\n",
            "root        : INFO     Epoch: 12, Batch: 780, Loss: 0.0834\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0840\n",
            "root        : INFO     Epoch: 12, Batch: 820, Loss: 0.0613\n",
            "root        : INFO     Epoch: 12, Batch: 840, Loss: 0.1411\n",
            "root        : INFO     Epoch: 12, Batch: 860, Loss: 0.0808\n",
            "root        : INFO     Epoch: 12, Batch: 880, Loss: 0.0652\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     119/177 = 0.672316\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.0991\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.0908\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.0891\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.1258\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0571\n",
            "root        : INFO     Epoch: 13, Batch: 120, Loss: 0.1021\n",
            "root        : INFO     Epoch: 13, Batch: 140, Loss: 0.1243\n",
            "root        : INFO     Epoch: 13, Batch: 160, Loss: 0.1263\n",
            "root        : INFO     Epoch: 13, Batch: 180, Loss: 0.0350\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0949\n",
            "root        : INFO     Epoch: 13, Batch: 220, Loss: 0.0811\n",
            "root        : INFO     Epoch: 13, Batch: 240, Loss: 0.0523\n",
            "root        : INFO     Epoch: 13, Batch: 260, Loss: 0.0981\n",
            "root        : INFO     Epoch: 13, Batch: 280, Loss: 0.0479\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0783\n",
            "root        : INFO     Epoch: 13, Batch: 320, Loss: 0.0531\n",
            "root        : INFO     Epoch: 13, Batch: 340, Loss: 0.0903\n",
            "root        : INFO     Epoch: 13, Batch: 360, Loss: 0.0426\n",
            "root        : INFO     Epoch: 13, Batch: 380, Loss: 0.0837\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.1008\n",
            "root        : INFO     Epoch: 13, Batch: 420, Loss: 0.0604\n",
            "root        : INFO     Epoch: 13, Batch: 440, Loss: 0.1181\n",
            "root        : INFO     Epoch: 13, Batch: 460, Loss: 0.0524\n",
            "root        : INFO     Epoch: 13, Batch: 480, Loss: 0.0460\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0662\n",
            "root        : INFO     Epoch: 13, Batch: 520, Loss: 0.0939\n",
            "root        : INFO     Epoch: 13, Batch: 540, Loss: 0.0575\n",
            "root        : INFO     Epoch: 13, Batch: 560, Loss: 0.0908\n",
            "root        : INFO     Epoch: 13, Batch: 580, Loss: 0.1095\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.1185\n",
            "root        : INFO     Epoch: 13, Batch: 620, Loss: 0.0766\n",
            "root        : INFO     Epoch: 13, Batch: 640, Loss: 0.1332\n",
            "root        : INFO     Epoch: 13, Batch: 660, Loss: 0.0572\n",
            "root        : INFO     Epoch: 13, Batch: 680, Loss: 0.0359\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0837\n",
            "root        : INFO     Epoch: 13, Batch: 720, Loss: 0.0792\n",
            "root        : INFO     Epoch: 13, Batch: 740, Loss: 0.0841\n",
            "root        : INFO     Epoch: 13, Batch: 760, Loss: 0.0886\n",
            "root        : INFO     Epoch: 13, Batch: 780, Loss: 0.1326\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0713\n",
            "root        : INFO     Epoch: 13, Batch: 820, Loss: 0.0745\n",
            "root        : INFO     Epoch: 13, Batch: 840, Loss: 0.0663\n",
            "root        : INFO     Epoch: 13, Batch: 860, Loss: 0.0915\n",
            "root        : INFO     Epoch: 13, Batch: 880, Loss: 0.1888\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.0560\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0847\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0665\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.0578\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0720\n",
            "root        : INFO     Epoch: 14, Batch: 120, Loss: 0.0521\n",
            "root        : INFO     Epoch: 14, Batch: 140, Loss: 0.1021\n",
            "root        : INFO     Epoch: 14, Batch: 160, Loss: 0.1280\n",
            "root        : INFO     Epoch: 14, Batch: 180, Loss: 0.0688\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0676\n",
            "root        : INFO     Epoch: 14, Batch: 220, Loss: 0.0724\n",
            "root        : INFO     Epoch: 14, Batch: 240, Loss: 0.0687\n",
            "root        : INFO     Epoch: 14, Batch: 260, Loss: 0.1095\n",
            "root        : INFO     Epoch: 14, Batch: 280, Loss: 0.0651\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0824\n",
            "root        : INFO     Epoch: 14, Batch: 320, Loss: 0.0871\n",
            "root        : INFO     Epoch: 14, Batch: 340, Loss: 0.0865\n",
            "root        : INFO     Epoch: 14, Batch: 360, Loss: 0.0590\n",
            "root        : INFO     Epoch: 14, Batch: 380, Loss: 0.0537\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0684\n",
            "root        : INFO     Epoch: 14, Batch: 420, Loss: 0.1066\n",
            "root        : INFO     Epoch: 14, Batch: 440, Loss: 0.1324\n",
            "root        : INFO     Epoch: 14, Batch: 460, Loss: 0.0654\n",
            "root        : INFO     Epoch: 14, Batch: 480, Loss: 0.0429\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0429\n",
            "root        : INFO     Epoch: 14, Batch: 520, Loss: 0.0513\n",
            "root        : INFO     Epoch: 14, Batch: 540, Loss: 0.0488\n",
            "root        : INFO     Epoch: 14, Batch: 560, Loss: 0.0655\n",
            "root        : INFO     Epoch: 14, Batch: 580, Loss: 0.0633\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0610\n",
            "root        : INFO     Epoch: 14, Batch: 620, Loss: 0.0999\n",
            "root        : INFO     Epoch: 14, Batch: 640, Loss: 0.1074\n",
            "root        : INFO     Epoch: 14, Batch: 660, Loss: 0.0612\n",
            "root        : INFO     Epoch: 14, Batch: 680, Loss: 0.1204\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0910\n",
            "root        : INFO     Epoch: 14, Batch: 720, Loss: 0.0653\n",
            "root        : INFO     Epoch: 14, Batch: 740, Loss: 0.0746\n",
            "root        : INFO     Epoch: 14, Batch: 760, Loss: 0.0954\n",
            "root        : INFO     Epoch: 14, Batch: 780, Loss: 0.0998\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.1086\n",
            "root        : INFO     Epoch: 14, Batch: 820, Loss: 0.0615\n",
            "root        : INFO     Epoch: 14, Batch: 840, Loss: 0.0559\n",
            "root        : INFO     Epoch: 14, Batch: 860, Loss: 0.0459\n",
            "root        : INFO     Epoch: 14, Batch: 880, Loss: 0.1182\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     152/177 = 0.858757\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.1069\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.0813\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0687\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.0610\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0688\n",
            "root        : INFO     Epoch: 15, Batch: 120, Loss: 0.0562\n",
            "root        : INFO     Epoch: 15, Batch: 140, Loss: 0.0856\n",
            "root        : INFO     Epoch: 15, Batch: 160, Loss: 0.0979\n",
            "root        : INFO     Epoch: 15, Batch: 180, Loss: 0.0829\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0684\n",
            "root        : INFO     Epoch: 15, Batch: 220, Loss: 0.0887\n",
            "root        : INFO     Epoch: 15, Batch: 240, Loss: 0.1077\n",
            "root        : INFO     Epoch: 15, Batch: 260, Loss: 0.0868\n",
            "root        : INFO     Epoch: 15, Batch: 280, Loss: 0.0445\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0722\n",
            "root        : INFO     Epoch: 15, Batch: 320, Loss: 0.0654\n",
            "root        : INFO     Epoch: 15, Batch: 340, Loss: 0.0693\n",
            "root        : INFO     Epoch: 15, Batch: 360, Loss: 0.0964\n",
            "root        : INFO     Epoch: 15, Batch: 380, Loss: 0.0764\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0506\n",
            "root        : INFO     Epoch: 15, Batch: 420, Loss: 0.0516\n",
            "root        : INFO     Epoch: 15, Batch: 440, Loss: 0.1042\n",
            "root        : INFO     Epoch: 15, Batch: 460, Loss: 0.0512\n",
            "root        : INFO     Epoch: 15, Batch: 480, Loss: 0.0916\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0690\n",
            "root        : INFO     Epoch: 15, Batch: 520, Loss: 0.0673\n",
            "root        : INFO     Epoch: 15, Batch: 540, Loss: 0.0562\n",
            "root        : INFO     Epoch: 15, Batch: 560, Loss: 0.0794\n",
            "root        : INFO     Epoch: 15, Batch: 580, Loss: 0.0786\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0710\n",
            "root        : INFO     Epoch: 15, Batch: 620, Loss: 0.0578\n",
            "root        : INFO     Epoch: 15, Batch: 640, Loss: 0.0947\n",
            "root        : INFO     Epoch: 15, Batch: 660, Loss: 0.1096\n",
            "root        : INFO     Epoch: 15, Batch: 680, Loss: 0.0510\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0624\n",
            "root        : INFO     Epoch: 15, Batch: 720, Loss: 0.0592\n",
            "root        : INFO     Epoch: 15, Batch: 740, Loss: 0.0480\n",
            "root        : INFO     Epoch: 15, Batch: 760, Loss: 0.0743\n",
            "root        : INFO     Epoch: 15, Batch: 780, Loss: 0.0969\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0675\n",
            "root        : INFO     Epoch: 15, Batch: 820, Loss: 0.0921\n",
            "root        : INFO     Epoch: 15, Batch: 840, Loss: 0.0601\n",
            "root        : INFO     Epoch: 15, Batch: 860, Loss: 0.0601\n",
            "root        : INFO     Epoch: 15, Batch: 880, Loss: 0.0803\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     148/177 = 0.836158\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.0681\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.0807\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0505\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0577\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0693\n",
            "root        : INFO     Epoch: 16, Batch: 120, Loss: 0.0841\n",
            "root        : INFO     Epoch: 16, Batch: 140, Loss: 0.0606\n",
            "root        : INFO     Epoch: 16, Batch: 160, Loss: 0.0646\n",
            "root        : INFO     Epoch: 16, Batch: 180, Loss: 0.1100\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0536\n",
            "root        : INFO     Epoch: 16, Batch: 220, Loss: 0.1005\n",
            "root        : INFO     Epoch: 16, Batch: 240, Loss: 0.1104\n",
            "root        : INFO     Epoch: 16, Batch: 260, Loss: 0.0875\n",
            "root        : INFO     Epoch: 16, Batch: 280, Loss: 0.0340\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0949\n",
            "root        : INFO     Epoch: 16, Batch: 320, Loss: 0.0551\n",
            "root        : INFO     Epoch: 16, Batch: 340, Loss: 0.1014\n",
            "root        : INFO     Epoch: 16, Batch: 360, Loss: 0.1087\n",
            "root        : INFO     Epoch: 16, Batch: 380, Loss: 0.0674\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0843\n",
            "root        : INFO     Epoch: 16, Batch: 420, Loss: 0.0972\n",
            "root        : INFO     Epoch: 16, Batch: 440, Loss: 0.0365\n",
            "root        : INFO     Epoch: 16, Batch: 460, Loss: 0.0702\n",
            "root        : INFO     Epoch: 16, Batch: 480, Loss: 0.0882\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0445\n",
            "root        : INFO     Epoch: 16, Batch: 520, Loss: 0.1202\n",
            "root        : INFO     Epoch: 16, Batch: 540, Loss: 0.0705\n",
            "root        : INFO     Epoch: 16, Batch: 560, Loss: 0.0582\n",
            "root        : INFO     Epoch: 16, Batch: 580, Loss: 0.0670\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0638\n",
            "root        : INFO     Epoch: 16, Batch: 620, Loss: 0.0496\n",
            "root        : INFO     Epoch: 16, Batch: 640, Loss: 0.0928\n",
            "root        : INFO     Epoch: 16, Batch: 660, Loss: 0.1020\n",
            "root        : INFO     Epoch: 16, Batch: 680, Loss: 0.0733\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0666\n",
            "root        : INFO     Epoch: 16, Batch: 720, Loss: 0.0708\n",
            "root        : INFO     Epoch: 16, Batch: 740, Loss: 0.0624\n",
            "root        : INFO     Epoch: 16, Batch: 760, Loss: 0.0652\n",
            "root        : INFO     Epoch: 16, Batch: 780, Loss: 0.0598\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0497\n",
            "root        : INFO     Epoch: 16, Batch: 820, Loss: 0.0764\n",
            "root        : INFO     Epoch: 16, Batch: 840, Loss: 0.0625\n",
            "root        : INFO     Epoch: 16, Batch: 860, Loss: 0.1038\n",
            "root        : INFO     Epoch: 16, Batch: 880, Loss: 0.0484\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0991\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.0694\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0590\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.0765\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.1002\n",
            "root        : INFO     Epoch: 17, Batch: 120, Loss: 0.0595\n",
            "root        : INFO     Epoch: 17, Batch: 140, Loss: 0.1032\n",
            "root        : INFO     Epoch: 17, Batch: 160, Loss: 0.1130\n",
            "root        : INFO     Epoch: 17, Batch: 180, Loss: 0.0745\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.1013\n",
            "root        : INFO     Epoch: 17, Batch: 220, Loss: 0.0808\n",
            "root        : INFO     Epoch: 17, Batch: 240, Loss: 0.0678\n",
            "root        : INFO     Epoch: 17, Batch: 260, Loss: 0.0987\n",
            "root        : INFO     Epoch: 17, Batch: 280, Loss: 0.0753\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0571\n",
            "root        : INFO     Epoch: 17, Batch: 320, Loss: 0.0811\n",
            "root        : INFO     Epoch: 17, Batch: 340, Loss: 0.0934\n",
            "root        : INFO     Epoch: 17, Batch: 360, Loss: 0.0664\n",
            "root        : INFO     Epoch: 17, Batch: 380, Loss: 0.0683\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0757\n",
            "root        : INFO     Epoch: 17, Batch: 420, Loss: 0.0942\n",
            "root        : INFO     Epoch: 17, Batch: 440, Loss: 0.0622\n",
            "root        : INFO     Epoch: 17, Batch: 460, Loss: 0.0765\n",
            "root        : INFO     Epoch: 17, Batch: 480, Loss: 0.0696\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0469\n",
            "root        : INFO     Epoch: 17, Batch: 520, Loss: 0.0864\n",
            "root        : INFO     Epoch: 17, Batch: 540, Loss: 0.0586\n",
            "root        : INFO     Epoch: 17, Batch: 560, Loss: 0.0622\n",
            "root        : INFO     Epoch: 17, Batch: 580, Loss: 0.0961\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0922\n",
            "root        : INFO     Epoch: 17, Batch: 620, Loss: 0.0551\n",
            "root        : INFO     Epoch: 17, Batch: 640, Loss: 0.0898\n",
            "root        : INFO     Epoch: 17, Batch: 660, Loss: 0.0505\n",
            "root        : INFO     Epoch: 17, Batch: 680, Loss: 0.1048\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.1050\n",
            "root        : INFO     Epoch: 17, Batch: 720, Loss: 0.0928\n",
            "root        : INFO     Epoch: 17, Batch: 740, Loss: 0.0699\n",
            "root        : INFO     Epoch: 17, Batch: 760, Loss: 0.1528\n",
            "root        : INFO     Epoch: 17, Batch: 780, Loss: 0.0687\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0654\n",
            "root        : INFO     Epoch: 17, Batch: 820, Loss: 0.0708\n",
            "root        : INFO     Epoch: 17, Batch: 840, Loss: 0.0710\n",
            "root        : INFO     Epoch: 17, Batch: 860, Loss: 0.1038\n",
            "root        : INFO     Epoch: 17, Batch: 880, Loss: 0.1040\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     153/177 = 0.864407\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0841\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.0788\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0654\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.0625\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0785\n",
            "root        : INFO     Epoch: 18, Batch: 120, Loss: 0.1005\n",
            "root        : INFO     Epoch: 18, Batch: 140, Loss: 0.0595\n",
            "root        : INFO     Epoch: 18, Batch: 160, Loss: 0.1203\n",
            "root        : INFO     Epoch: 18, Batch: 180, Loss: 0.0558\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0792\n",
            "root        : INFO     Epoch: 18, Batch: 220, Loss: 0.0889\n",
            "root        : INFO     Epoch: 18, Batch: 240, Loss: 0.0842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KygMXtwYZ6JC"
      },
      "source": [
        "**Poor performance**\n",
        "**Batch size =64, which is a lot larger than the optimal value.**  \n",
        "**Ignoring augmentaion also results in the poor performance.**   \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210326_0547_training_cornell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3vED1gD9BD2",
        "outputId": "6c402dda-3fdc-41c1-b6b1-c6ccbc18a21c"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs --ds-shuffle --num-workers 0 --batch-size 64 --batches-per-epoch 16  --epochs 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.90, ds-rotate = 0.00, number of workers = 0, random seed = 123.00\n",
            "root        : INFO     epochs = 50, batch size = 64, bacthes per epoch = 16, optimizer = adam\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 796\n",
            "root        : INFO     Validation size: 89\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 1, Loss: 2.2549\n",
            "root        : INFO     Epoch: 0, Batch: 2, Loss: 6.8150\n",
            "root        : INFO     Epoch: 0, Batch: 3, Loss: 3.2529\n",
            "root        : INFO     Epoch: 0, Batch: 4, Loss: 1.2224\n",
            "root        : INFO     Epoch: 0, Batch: 5, Loss: 0.9467\n",
            "root        : INFO     Epoch: 0, Batch: 6, Loss: 1.3225\n",
            "root        : INFO     Epoch: 0, Batch: 7, Loss: 1.2290\n",
            "root        : INFO     Epoch: 0, Batch: 8, Loss: 0.8768\n",
            "root        : INFO     Epoch: 0, Batch: 9, Loss: 0.6423\n",
            "root        : INFO     Epoch: 0, Batch: 10, Loss: 0.4105\n",
            "root        : INFO     Epoch: 0, Batch: 11, Loss: 0.3931\n",
            "root        : INFO     Epoch: 0, Batch: 12, Loss: 0.3932\n",
            "root        : INFO     Epoch: 0, Batch: 13, Loss: 0.3035\n",
            "root        : INFO     Epoch: 0, Batch: 14, Loss: 0.3886\n",
            "root        : INFO     Epoch: 0, Batch: 15, Loss: 0.3182\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     3/89 = 0.033708\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 1, Loss: 0.3419\n",
            "root        : INFO     Epoch: 1, Batch: 2, Loss: 0.2733\n",
            "root        : INFO     Epoch: 1, Batch: 3, Loss: 0.2667\n",
            "root        : INFO     Epoch: 1, Batch: 4, Loss: 0.2037\n",
            "root        : INFO     Epoch: 1, Batch: 5, Loss: 0.1812\n",
            "root        : INFO     Epoch: 1, Batch: 6, Loss: 0.1830\n",
            "root        : INFO     Epoch: 1, Batch: 7, Loss: 0.2030\n",
            "root        : INFO     Epoch: 1, Batch: 8, Loss: 0.1935\n",
            "root        : INFO     Epoch: 1, Batch: 9, Loss: 0.2136\n",
            "root        : INFO     Epoch: 1, Batch: 10, Loss: 0.2253\n",
            "root        : INFO     Epoch: 1, Batch: 11, Loss: 0.1918\n",
            "root        : INFO     Epoch: 1, Batch: 12, Loss: 0.1952\n",
            "root        : INFO     Epoch: 1, Batch: 13, Loss: 0.1861\n",
            "root        : INFO     Epoch: 1, Batch: 14, Loss: 0.2075\n",
            "root        : INFO     Epoch: 1, Batch: 15, Loss: 0.1614\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     0/89 = 0.000000\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 1, Loss: 0.1543\n",
            "root        : INFO     Epoch: 2, Batch: 2, Loss: 0.1535\n",
            "root        : INFO     Epoch: 2, Batch: 3, Loss: 0.1536\n",
            "root        : INFO     Epoch: 2, Batch: 4, Loss: 0.1447\n",
            "root        : INFO     Epoch: 2, Batch: 5, Loss: 0.1423\n",
            "root        : INFO     Epoch: 2, Batch: 6, Loss: 0.1511\n",
            "root        : INFO     Epoch: 2, Batch: 7, Loss: 0.2018\n",
            "root        : INFO     Epoch: 2, Batch: 8, Loss: 0.1631\n",
            "root        : INFO     Epoch: 2, Batch: 9, Loss: 0.1558\n",
            "root        : INFO     Epoch: 2, Batch: 10, Loss: 0.1639\n",
            "root        : INFO     Epoch: 2, Batch: 11, Loss: 0.1531\n",
            "root        : INFO     Epoch: 2, Batch: 12, Loss: 0.1527\n",
            "root        : INFO     Epoch: 2, Batch: 13, Loss: 0.1384\n",
            "root        : INFO     Epoch: 2, Batch: 14, Loss: 0.1711\n",
            "root        : INFO     Epoch: 2, Batch: 15, Loss: 0.1470\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     0/89 = 0.000000\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 1, Loss: 0.1396\n",
            "root        : INFO     Epoch: 3, Batch: 2, Loss: 0.1583\n",
            "root        : INFO     Epoch: 3, Batch: 3, Loss: 0.1431\n",
            "root        : INFO     Epoch: 3, Batch: 4, Loss: 0.1384\n",
            "root        : INFO     Epoch: 3, Batch: 5, Loss: 0.1325\n",
            "root        : INFO     Epoch: 3, Batch: 6, Loss: 0.1152\n",
            "root        : INFO     Epoch: 3, Batch: 7, Loss: 0.1356\n",
            "root        : INFO     Epoch: 3, Batch: 8, Loss: 0.1365\n",
            "root        : INFO     Epoch: 3, Batch: 9, Loss: 0.1287\n",
            "root        : INFO     Epoch: 3, Batch: 10, Loss: 0.1248\n",
            "root        : INFO     Epoch: 3, Batch: 11, Loss: 0.1160\n",
            "root        : INFO     Epoch: 3, Batch: 12, Loss: 0.1245\n",
            "root        : INFO     Epoch: 3, Batch: 13, Loss: 0.1683\n",
            "root        : INFO     Epoch: 3, Batch: 14, Loss: 0.1303\n",
            "root        : INFO     Epoch: 3, Batch: 15, Loss: 0.1163\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     26/89 = 0.292135\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 1, Loss: 0.1608\n",
            "root        : INFO     Epoch: 4, Batch: 2, Loss: 0.1492\n",
            "root        : INFO     Epoch: 4, Batch: 3, Loss: 0.1122\n",
            "root        : INFO     Epoch: 4, Batch: 4, Loss: 0.1213\n",
            "root        : INFO     Epoch: 4, Batch: 5, Loss: 0.1347\n",
            "root        : INFO     Epoch: 4, Batch: 6, Loss: 0.1481\n",
            "root        : INFO     Epoch: 4, Batch: 7, Loss: 0.1156\n",
            "root        : INFO     Epoch: 4, Batch: 8, Loss: 0.1476\n",
            "root        : INFO     Epoch: 4, Batch: 9, Loss: 0.1200\n",
            "root        : INFO     Epoch: 4, Batch: 10, Loss: 0.1234\n",
            "root        : INFO     Epoch: 4, Batch: 11, Loss: 0.1163\n",
            "root        : INFO     Epoch: 4, Batch: 12, Loss: 0.1199\n",
            "root        : INFO     Epoch: 4, Batch: 13, Loss: 0.0962\n",
            "root        : INFO     Epoch: 4, Batch: 14, Loss: 0.1172\n",
            "root        : INFO     Epoch: 4, Batch: 15, Loss: 0.1288\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     26/89 = 0.292135\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 1, Loss: 0.1243\n",
            "root        : INFO     Epoch: 5, Batch: 2, Loss: 0.1165\n",
            "root        : INFO     Epoch: 5, Batch: 3, Loss: 0.1350\n",
            "root        : INFO     Epoch: 5, Batch: 4, Loss: 0.1163\n",
            "root        : INFO     Epoch: 5, Batch: 5, Loss: 0.1262\n",
            "root        : INFO     Epoch: 5, Batch: 6, Loss: 0.1015\n",
            "root        : INFO     Epoch: 5, Batch: 7, Loss: 0.1420\n",
            "root        : INFO     Epoch: 5, Batch: 8, Loss: 0.1224\n",
            "root        : INFO     Epoch: 5, Batch: 9, Loss: 0.1123\n",
            "root        : INFO     Epoch: 5, Batch: 10, Loss: 0.1341\n",
            "root        : INFO     Epoch: 5, Batch: 11, Loss: 0.1165\n",
            "root        : INFO     Epoch: 5, Batch: 12, Loss: 0.1170\n",
            "root        : INFO     Epoch: 5, Batch: 13, Loss: 0.1116\n",
            "root        : INFO     Epoch: 5, Batch: 14, Loss: 0.1267\n",
            "root        : INFO     Epoch: 5, Batch: 15, Loss: 0.1267\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     31/89 = 0.348315\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 1, Loss: 0.1114\n",
            "root        : INFO     Epoch: 6, Batch: 2, Loss: 0.1243\n",
            "root        : INFO     Epoch: 6, Batch: 3, Loss: 0.1209\n",
            "root        : INFO     Epoch: 6, Batch: 4, Loss: 0.1293\n",
            "root        : INFO     Epoch: 6, Batch: 5, Loss: 0.1313\n",
            "root        : INFO     Epoch: 6, Batch: 6, Loss: 0.1230\n",
            "root        : INFO     Epoch: 6, Batch: 7, Loss: 0.1320\n",
            "root        : INFO     Epoch: 6, Batch: 8, Loss: 0.1241\n",
            "root        : INFO     Epoch: 6, Batch: 9, Loss: 0.1185\n",
            "root        : INFO     Epoch: 6, Batch: 10, Loss: 0.1413\n",
            "root        : INFO     Epoch: 6, Batch: 11, Loss: 0.0995\n",
            "root        : INFO     Epoch: 6, Batch: 12, Loss: 0.1145\n",
            "root        : INFO     Epoch: 6, Batch: 13, Loss: 0.1267\n",
            "root        : INFO     Epoch: 6, Batch: 14, Loss: 0.1216\n",
            "root        : INFO     Epoch: 6, Batch: 15, Loss: 0.1100\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     34/89 = 0.382022\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 1, Loss: 0.1050\n",
            "root        : INFO     Epoch: 7, Batch: 2, Loss: 0.1150\n",
            "root        : INFO     Epoch: 7, Batch: 3, Loss: 0.1265\n",
            "root        : INFO     Epoch: 7, Batch: 4, Loss: 0.1029\n",
            "root        : INFO     Epoch: 7, Batch: 5, Loss: 0.1345\n",
            "root        : INFO     Epoch: 7, Batch: 6, Loss: 0.1445\n",
            "root        : INFO     Epoch: 7, Batch: 7, Loss: 0.1144\n",
            "root        : INFO     Epoch: 7, Batch: 8, Loss: 0.1231\n",
            "root        : INFO     Epoch: 7, Batch: 9, Loss: 0.1318\n",
            "root        : INFO     Epoch: 7, Batch: 10, Loss: 0.1377\n",
            "root        : INFO     Epoch: 7, Batch: 11, Loss: 0.1056\n",
            "root        : INFO     Epoch: 7, Batch: 12, Loss: 0.1199\n",
            "root        : INFO     Epoch: 7, Batch: 13, Loss: 0.1332\n",
            "root        : INFO     Epoch: 7, Batch: 14, Loss: 0.1331\n",
            "root        : INFO     Epoch: 7, Batch: 15, Loss: 0.1154\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     41/89 = 0.460674\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 1, Loss: 0.1003\n",
            "root        : INFO     Epoch: 8, Batch: 2, Loss: 0.1259\n",
            "root        : INFO     Epoch: 8, Batch: 3, Loss: 0.1136\n",
            "root        : INFO     Epoch: 8, Batch: 4, Loss: 0.1151\n",
            "root        : INFO     Epoch: 8, Batch: 5, Loss: 0.1297\n",
            "root        : INFO     Epoch: 8, Batch: 6, Loss: 0.1187\n",
            "root        : INFO     Epoch: 8, Batch: 7, Loss: 0.1063\n",
            "root        : INFO     Epoch: 8, Batch: 8, Loss: 0.1345\n",
            "root        : INFO     Epoch: 8, Batch: 9, Loss: 0.1070\n",
            "root        : INFO     Epoch: 8, Batch: 10, Loss: 0.1262\n",
            "root        : INFO     Epoch: 8, Batch: 11, Loss: 0.1244\n",
            "root        : INFO     Epoch: 8, Batch: 12, Loss: 0.1183\n",
            "root        : INFO     Epoch: 8, Batch: 13, Loss: 0.1157\n",
            "root        : INFO     Epoch: 8, Batch: 14, Loss: 0.1225\n",
            "root        : INFO     Epoch: 8, Batch: 15, Loss: 0.1363\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     28/89 = 0.314607\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 1, Loss: 0.1197\n",
            "root        : INFO     Epoch: 9, Batch: 2, Loss: 0.1111\n",
            "root        : INFO     Epoch: 9, Batch: 3, Loss: 0.1029\n",
            "root        : INFO     Epoch: 9, Batch: 4, Loss: 0.1234\n",
            "root        : INFO     Epoch: 9, Batch: 5, Loss: 0.1141\n",
            "root        : INFO     Epoch: 9, Batch: 6, Loss: 0.1195\n",
            "root        : INFO     Epoch: 9, Batch: 7, Loss: 0.1015\n",
            "root        : INFO     Epoch: 9, Batch: 8, Loss: 0.1099\n",
            "root        : INFO     Epoch: 9, Batch: 9, Loss: 0.1488\n",
            "root        : INFO     Epoch: 9, Batch: 10, Loss: 0.1007\n",
            "root        : INFO     Epoch: 9, Batch: 11, Loss: 0.1064\n",
            "root        : INFO     Epoch: 9, Batch: 12, Loss: 0.1123\n",
            "root        : INFO     Epoch: 9, Batch: 13, Loss: 0.1120\n",
            "root        : INFO     Epoch: 9, Batch: 14, Loss: 0.1056\n",
            "root        : INFO     Epoch: 9, Batch: 15, Loss: 0.1280\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     32/89 = 0.359551\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 1, Loss: 0.1297\n",
            "root        : INFO     Epoch: 10, Batch: 2, Loss: 0.1069\n",
            "root        : INFO     Epoch: 10, Batch: 3, Loss: 0.1121\n",
            "root        : INFO     Epoch: 10, Batch: 4, Loss: 0.1018\n",
            "root        : INFO     Epoch: 10, Batch: 5, Loss: 0.1268\n",
            "root        : INFO     Epoch: 10, Batch: 6, Loss: 0.1080\n",
            "root        : INFO     Epoch: 10, Batch: 7, Loss: 0.1234\n",
            "root        : INFO     Epoch: 10, Batch: 8, Loss: 0.1247\n",
            "root        : INFO     Epoch: 10, Batch: 9, Loss: 0.0995\n",
            "root        : INFO     Epoch: 10, Batch: 10, Loss: 0.1046\n",
            "root        : INFO     Epoch: 10, Batch: 11, Loss: 0.1040\n",
            "root        : INFO     Epoch: 10, Batch: 12, Loss: 0.1149\n",
            "root        : INFO     Epoch: 10, Batch: 13, Loss: 0.1326\n",
            "root        : INFO     Epoch: 10, Batch: 14, Loss: 0.1204\n",
            "root        : INFO     Epoch: 10, Batch: 15, Loss: 0.1109\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     29/89 = 0.325843\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 1, Loss: 0.1106\n",
            "root        : INFO     Epoch: 11, Batch: 2, Loss: 0.1317\n",
            "root        : INFO     Epoch: 11, Batch: 3, Loss: 0.1093\n",
            "root        : INFO     Epoch: 11, Batch: 4, Loss: 0.1125\n",
            "root        : INFO     Epoch: 11, Batch: 5, Loss: 0.1225\n",
            "root        : INFO     Epoch: 11, Batch: 6, Loss: 0.1195\n",
            "root        : INFO     Epoch: 11, Batch: 7, Loss: 0.1053\n",
            "root        : INFO     Epoch: 11, Batch: 8, Loss: 0.1099\n",
            "root        : INFO     Epoch: 11, Batch: 9, Loss: 0.0976\n",
            "root        : INFO     Epoch: 11, Batch: 10, Loss: 0.1290\n",
            "root        : INFO     Epoch: 11, Batch: 11, Loss: 0.1271\n",
            "root        : INFO     Epoch: 11, Batch: 12, Loss: 0.1114\n",
            "root        : INFO     Epoch: 11, Batch: 13, Loss: 0.0927\n",
            "root        : INFO     Epoch: 11, Batch: 14, Loss: 0.1098\n",
            "root        : INFO     Epoch: 11, Batch: 15, Loss: 0.1054\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     36/89 = 0.404494\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 1, Loss: 0.1002\n",
            "root        : INFO     Epoch: 12, Batch: 2, Loss: 0.1183\n",
            "root        : INFO     Epoch: 12, Batch: 3, Loss: 0.1002\n",
            "root        : INFO     Epoch: 12, Batch: 4, Loss: 0.1042\n",
            "root        : INFO     Epoch: 12, Batch: 5, Loss: 0.0981\n",
            "root        : INFO     Epoch: 12, Batch: 6, Loss: 0.0999\n",
            "root        : INFO     Epoch: 12, Batch: 7, Loss: 0.1219\n",
            "root        : INFO     Epoch: 12, Batch: 8, Loss: 0.1040\n",
            "root        : INFO     Epoch: 12, Batch: 9, Loss: 0.1155\n",
            "root        : INFO     Epoch: 12, Batch: 10, Loss: 0.1294\n",
            "root        : INFO     Epoch: 12, Batch: 11, Loss: 0.1370\n",
            "root        : INFO     Epoch: 12, Batch: 12, Loss: 0.1215\n",
            "root        : INFO     Epoch: 12, Batch: 13, Loss: 0.0959\n",
            "root        : INFO     Epoch: 12, Batch: 14, Loss: 0.1108\n",
            "root        : INFO     Epoch: 12, Batch: 15, Loss: 0.1007\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     29/89 = 0.325843\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 1, Loss: 0.1164\n",
            "root        : INFO     Epoch: 13, Batch: 2, Loss: 0.1275\n",
            "root        : INFO     Epoch: 13, Batch: 3, Loss: 0.1026\n",
            "root        : INFO     Epoch: 13, Batch: 4, Loss: 0.0996\n",
            "root        : INFO     Epoch: 13, Batch: 5, Loss: 0.1044\n",
            "root        : INFO     Epoch: 13, Batch: 6, Loss: 0.1234\n",
            "root        : INFO     Epoch: 13, Batch: 7, Loss: 0.1149\n",
            "root        : INFO     Epoch: 13, Batch: 8, Loss: 0.1060\n",
            "root        : INFO     Epoch: 13, Batch: 9, Loss: 0.1144\n",
            "root        : INFO     Epoch: 13, Batch: 10, Loss: 0.1219\n",
            "root        : INFO     Epoch: 13, Batch: 11, Loss: 0.0886\n",
            "root        : INFO     Epoch: 13, Batch: 12, Loss: 0.1312\n",
            "root        : INFO     Epoch: 13, Batch: 13, Loss: 0.0991\n",
            "root        : INFO     Epoch: 13, Batch: 14, Loss: 0.1075\n",
            "root        : INFO     Epoch: 13, Batch: 15, Loss: 0.1251\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     47/89 = 0.528090\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 1, Loss: 0.1143\n",
            "root        : INFO     Epoch: 14, Batch: 2, Loss: 0.1219\n",
            "root        : INFO     Epoch: 14, Batch: 3, Loss: 0.1163\n",
            "root        : INFO     Epoch: 14, Batch: 4, Loss: 0.1235\n",
            "root        : INFO     Epoch: 14, Batch: 5, Loss: 0.1178\n",
            "root        : INFO     Epoch: 14, Batch: 6, Loss: 0.1125\n",
            "root        : INFO     Epoch: 14, Batch: 7, Loss: 0.1063\n",
            "root        : INFO     Epoch: 14, Batch: 8, Loss: 0.1078\n",
            "root        : INFO     Epoch: 14, Batch: 9, Loss: 0.1130\n",
            "root        : INFO     Epoch: 14, Batch: 10, Loss: 0.1088\n",
            "root        : INFO     Epoch: 14, Batch: 11, Loss: 0.1200\n",
            "root        : INFO     Epoch: 14, Batch: 12, Loss: 0.1118\n",
            "root        : INFO     Epoch: 14, Batch: 13, Loss: 0.1117\n",
            "root        : INFO     Epoch: 14, Batch: 14, Loss: 0.1165\n",
            "root        : INFO     Epoch: 14, Batch: 15, Loss: 0.1098\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     41/89 = 0.460674\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 1, Loss: 0.1000\n",
            "root        : INFO     Epoch: 15, Batch: 2, Loss: 0.1096\n",
            "root        : INFO     Epoch: 15, Batch: 3, Loss: 0.1075\n",
            "root        : INFO     Epoch: 15, Batch: 4, Loss: 0.1072\n",
            "root        : INFO     Epoch: 15, Batch: 5, Loss: 0.1003\n",
            "root        : INFO     Epoch: 15, Batch: 6, Loss: 0.1179\n",
            "root        : INFO     Epoch: 15, Batch: 7, Loss: 0.1132\n",
            "root        : INFO     Epoch: 15, Batch: 8, Loss: 0.1164\n",
            "root        : INFO     Epoch: 15, Batch: 9, Loss: 0.1174\n",
            "root        : INFO     Epoch: 15, Batch: 10, Loss: 0.1052\n",
            "root        : INFO     Epoch: 15, Batch: 11, Loss: 0.1087\n",
            "root        : INFO     Epoch: 15, Batch: 12, Loss: 0.0826\n",
            "root        : INFO     Epoch: 15, Batch: 13, Loss: 0.0949\n",
            "root        : INFO     Epoch: 15, Batch: 14, Loss: 0.0863\n",
            "root        : INFO     Epoch: 15, Batch: 15, Loss: 0.1109\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     39/89 = 0.438202\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 1, Loss: 0.1072\n",
            "root        : INFO     Epoch: 16, Batch: 2, Loss: 0.0933\n",
            "root        : INFO     Epoch: 16, Batch: 3, Loss: 0.1142\n",
            "root        : INFO     Epoch: 16, Batch: 4, Loss: 0.1213\n",
            "root        : INFO     Epoch: 16, Batch: 5, Loss: 0.1245\n",
            "root        : INFO     Epoch: 16, Batch: 6, Loss: 0.0872\n",
            "root        : INFO     Epoch: 16, Batch: 7, Loss: 0.1109\n",
            "root        : INFO     Epoch: 16, Batch: 8, Loss: 0.1011\n",
            "root        : INFO     Epoch: 16, Batch: 9, Loss: 0.0988\n",
            "root        : INFO     Epoch: 16, Batch: 10, Loss: 0.1158\n",
            "root        : INFO     Epoch: 16, Batch: 11, Loss: 0.1152\n",
            "root        : INFO     Epoch: 16, Batch: 12, Loss: 0.0996\n",
            "root        : INFO     Epoch: 16, Batch: 13, Loss: 0.1197\n",
            "root        : INFO     Epoch: 16, Batch: 14, Loss: 0.1091\n",
            "root        : INFO     Epoch: 16, Batch: 15, Loss: 0.1003\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     53/89 = 0.595506\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 1, Loss: 0.1077\n",
            "root        : INFO     Epoch: 17, Batch: 2, Loss: 0.0894\n",
            "root        : INFO     Epoch: 17, Batch: 3, Loss: 0.1083\n",
            "root        : INFO     Epoch: 17, Batch: 4, Loss: 0.1319\n",
            "root        : INFO     Epoch: 17, Batch: 5, Loss: 0.1187\n",
            "root        : INFO     Epoch: 17, Batch: 6, Loss: 0.1020\n",
            "root        : INFO     Epoch: 17, Batch: 7, Loss: 0.1131\n",
            "root        : INFO     Epoch: 17, Batch: 8, Loss: 0.1105\n",
            "root        : INFO     Epoch: 17, Batch: 9, Loss: 0.0956\n",
            "root        : INFO     Epoch: 17, Batch: 10, Loss: 0.1081\n",
            "root        : INFO     Epoch: 17, Batch: 11, Loss: 0.1040\n",
            "root        : INFO     Epoch: 17, Batch: 12, Loss: 0.1166\n",
            "root        : INFO     Epoch: 17, Batch: 13, Loss: 0.0822\n",
            "root        : INFO     Epoch: 17, Batch: 14, Loss: 0.0997\n",
            "root        : INFO     Epoch: 17, Batch: 15, Loss: 0.1064\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     53/89 = 0.595506\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 1, Loss: 0.1247\n",
            "root        : INFO     Epoch: 18, Batch: 2, Loss: 0.1279\n",
            "root        : INFO     Epoch: 18, Batch: 3, Loss: 0.0882\n",
            "root        : INFO     Epoch: 18, Batch: 4, Loss: 0.1069\n",
            "root        : INFO     Epoch: 18, Batch: 5, Loss: 0.1115\n",
            "root        : INFO     Epoch: 18, Batch: 6, Loss: 0.1015\n",
            "root        : INFO     Epoch: 18, Batch: 7, Loss: 0.1028\n",
            "root        : INFO     Epoch: 18, Batch: 8, Loss: 0.1016\n",
            "root        : INFO     Epoch: 18, Batch: 9, Loss: 0.1091\n",
            "root        : INFO     Epoch: 18, Batch: 10, Loss: 0.0939\n",
            "root        : INFO     Epoch: 18, Batch: 11, Loss: 0.1101\n",
            "root        : INFO     Epoch: 18, Batch: 12, Loss: 0.1047\n",
            "root        : INFO     Epoch: 18, Batch: 13, Loss: 0.0960\n",
            "root        : INFO     Epoch: 18, Batch: 14, Loss: 0.1368\n",
            "root        : INFO     Epoch: 18, Batch: 15, Loss: 0.1111\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     42/89 = 0.471910\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 1, Loss: 0.1290\n",
            "root        : INFO     Epoch: 19, Batch: 2, Loss: 0.1298\n",
            "root        : INFO     Epoch: 19, Batch: 3, Loss: 0.0909\n",
            "root        : INFO     Epoch: 19, Batch: 4, Loss: 0.1254\n",
            "root        : INFO     Epoch: 19, Batch: 5, Loss: 0.0958\n",
            "root        : INFO     Epoch: 19, Batch: 6, Loss: 0.1122\n",
            "root        : INFO     Epoch: 19, Batch: 7, Loss: 0.1258\n",
            "root        : INFO     Epoch: 19, Batch: 8, Loss: 0.0974\n",
            "root        : INFO     Epoch: 19, Batch: 9, Loss: 0.1129\n",
            "root        : INFO     Epoch: 19, Batch: 10, Loss: 0.1082\n",
            "root        : INFO     Epoch: 19, Batch: 11, Loss: 0.1030\n",
            "root        : INFO     Epoch: 19, Batch: 12, Loss: 0.1208\n",
            "root        : INFO     Epoch: 19, Batch: 13, Loss: 0.1178\n",
            "root        : INFO     Epoch: 19, Batch: 14, Loss: 0.1235\n",
            "root        : INFO     Epoch: 19, Batch: 15, Loss: 0.1268\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     49/89 = 0.550562\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 1, Loss: 0.1084\n",
            "root        : INFO     Epoch: 20, Batch: 2, Loss: 0.1306\n",
            "root        : INFO     Epoch: 20, Batch: 3, Loss: 0.0981\n",
            "root        : INFO     Epoch: 20, Batch: 4, Loss: 0.1325\n",
            "root        : INFO     Epoch: 20, Batch: 5, Loss: 0.1163\n",
            "root        : INFO     Epoch: 20, Batch: 6, Loss: 0.1024\n",
            "root        : INFO     Epoch: 20, Batch: 7, Loss: 0.1130\n",
            "root        : INFO     Epoch: 20, Batch: 8, Loss: 0.1013\n",
            "root        : INFO     Epoch: 20, Batch: 9, Loss: 0.1202\n",
            "root        : INFO     Epoch: 20, Batch: 10, Loss: 0.1062\n",
            "root        : INFO     Epoch: 20, Batch: 11, Loss: 0.1079\n",
            "root        : INFO     Epoch: 20, Batch: 12, Loss: 0.0981\n",
            "root        : INFO     Epoch: 20, Batch: 13, Loss: 0.1285\n",
            "root        : INFO     Epoch: 20, Batch: 14, Loss: 0.1017\n",
            "root        : INFO     Epoch: 20, Batch: 15, Loss: 0.1103\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     43/89 = 0.483146\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 1, Loss: 0.1044\n",
            "root        : INFO     Epoch: 21, Batch: 2, Loss: 0.1407\n",
            "root        : INFO     Epoch: 21, Batch: 3, Loss: 0.1011\n",
            "root        : INFO     Epoch: 21, Batch: 4, Loss: 0.1112\n",
            "root        : INFO     Epoch: 21, Batch: 5, Loss: 0.1248\n",
            "root        : INFO     Epoch: 21, Batch: 6, Loss: 0.1084\n",
            "root        : INFO     Epoch: 21, Batch: 7, Loss: 0.1162\n",
            "root        : INFO     Epoch: 21, Batch: 8, Loss: 0.0979\n",
            "root        : INFO     Epoch: 21, Batch: 9, Loss: 0.1103\n",
            "root        : INFO     Epoch: 21, Batch: 10, Loss: 0.1105\n",
            "root        : INFO     Epoch: 21, Batch: 11, Loss: 0.1043\n",
            "root        : INFO     Epoch: 21, Batch: 12, Loss: 0.1174\n",
            "root        : INFO     Epoch: 21, Batch: 13, Loss: 0.1070\n",
            "root        : INFO     Epoch: 21, Batch: 14, Loss: 0.1203\n",
            "root        : INFO     Epoch: 21, Batch: 15, Loss: 0.1102\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     58/89 = 0.651685\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 1, Loss: 0.1025\n",
            "root        : INFO     Epoch: 22, Batch: 2, Loss: 0.1057\n",
            "root        : INFO     Epoch: 22, Batch: 3, Loss: 0.1169\n",
            "root        : INFO     Epoch: 22, Batch: 4, Loss: 0.1173\n",
            "root        : INFO     Epoch: 22, Batch: 5, Loss: 0.1045\n",
            "root        : INFO     Epoch: 22, Batch: 6, Loss: 0.1184\n",
            "root        : INFO     Epoch: 22, Batch: 7, Loss: 0.1100\n",
            "root        : INFO     Epoch: 22, Batch: 8, Loss: 0.0796\n",
            "root        : INFO     Epoch: 22, Batch: 9, Loss: 0.0960\n",
            "root        : INFO     Epoch: 22, Batch: 10, Loss: 0.1256\n",
            "root        : INFO     Epoch: 22, Batch: 11, Loss: 0.1126\n",
            "root        : INFO     Epoch: 22, Batch: 12, Loss: 0.0920\n",
            "root        : INFO     Epoch: 22, Batch: 13, Loss: 0.0960\n",
            "root        : INFO     Epoch: 22, Batch: 14, Loss: 0.0916\n",
            "root        : INFO     Epoch: 22, Batch: 15, Loss: 0.1091\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     47/89 = 0.528090\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 1, Loss: 0.1104\n",
            "root        : INFO     Epoch: 23, Batch: 2, Loss: 0.1011\n",
            "root        : INFO     Epoch: 23, Batch: 3, Loss: 0.1259\n",
            "root        : INFO     Epoch: 23, Batch: 4, Loss: 0.1028\n",
            "root        : INFO     Epoch: 23, Batch: 5, Loss: 0.0959\n",
            "root        : INFO     Epoch: 23, Batch: 6, Loss: 0.0948\n",
            "root        : INFO     Epoch: 23, Batch: 7, Loss: 0.1099\n",
            "root        : INFO     Epoch: 23, Batch: 8, Loss: 0.1068\n",
            "root        : INFO     Epoch: 23, Batch: 9, Loss: 0.1304\n",
            "root        : INFO     Epoch: 23, Batch: 10, Loss: 0.0943\n",
            "root        : INFO     Epoch: 23, Batch: 11, Loss: 0.0998\n",
            "root        : INFO     Epoch: 23, Batch: 12, Loss: 0.1174\n",
            "root        : INFO     Epoch: 23, Batch: 13, Loss: 0.1499\n",
            "root        : INFO     Epoch: 23, Batch: 14, Loss: 0.0863\n",
            "root        : INFO     Epoch: 23, Batch: 15, Loss: 0.0964\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     46/89 = 0.516854\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 1, Loss: 0.1122\n",
            "root        : INFO     Epoch: 24, Batch: 2, Loss: 0.1036\n",
            "root        : INFO     Epoch: 24, Batch: 3, Loss: 0.1079\n",
            "root        : INFO     Epoch: 24, Batch: 4, Loss: 0.1059\n",
            "root        : INFO     Epoch: 24, Batch: 5, Loss: 0.0841\n",
            "root        : INFO     Epoch: 24, Batch: 6, Loss: 0.1045\n",
            "root        : INFO     Epoch: 24, Batch: 7, Loss: 0.1122\n",
            "root        : INFO     Epoch: 24, Batch: 8, Loss: 0.0880\n",
            "root        : INFO     Epoch: 24, Batch: 9, Loss: 0.1060\n",
            "root        : INFO     Epoch: 24, Batch: 10, Loss: 0.1177\n",
            "root        : INFO     Epoch: 24, Batch: 11, Loss: 0.1160\n",
            "root        : INFO     Epoch: 24, Batch: 12, Loss: 0.1043\n",
            "root        : INFO     Epoch: 24, Batch: 13, Loss: 0.0897\n",
            "root        : INFO     Epoch: 24, Batch: 14, Loss: 0.1079\n",
            "root        : INFO     Epoch: 24, Batch: 15, Loss: 0.1023\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/89 = 0.707865\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 1, Loss: 0.1058\n",
            "root        : INFO     Epoch: 25, Batch: 2, Loss: 0.1059\n",
            "root        : INFO     Epoch: 25, Batch: 3, Loss: 0.1055\n",
            "root        : INFO     Epoch: 25, Batch: 4, Loss: 0.1340\n",
            "root        : INFO     Epoch: 25, Batch: 5, Loss: 0.1231\n",
            "root        : INFO     Epoch: 25, Batch: 6, Loss: 0.1047\n",
            "root        : INFO     Epoch: 25, Batch: 7, Loss: 0.1021\n",
            "root        : INFO     Epoch: 25, Batch: 8, Loss: 0.1352\n",
            "root        : INFO     Epoch: 25, Batch: 9, Loss: 0.1024\n",
            "root        : INFO     Epoch: 25, Batch: 10, Loss: 0.0902\n",
            "root        : INFO     Epoch: 25, Batch: 11, Loss: 0.0973\n",
            "root        : INFO     Epoch: 25, Batch: 12, Loss: 0.0900\n",
            "root        : INFO     Epoch: 25, Batch: 13, Loss: 0.1058\n",
            "root        : INFO     Epoch: 25, Batch: 14, Loss: 0.0942\n",
            "root        : INFO     Epoch: 25, Batch: 15, Loss: 0.1217\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     57/89 = 0.640449\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 1, Loss: 0.1016\n",
            "root        : INFO     Epoch: 26, Batch: 2, Loss: 0.1093\n",
            "root        : INFO     Epoch: 26, Batch: 3, Loss: 0.0942\n",
            "root        : INFO     Epoch: 26, Batch: 4, Loss: 0.1127\n",
            "root        : INFO     Epoch: 26, Batch: 5, Loss: 0.0918\n",
            "root        : INFO     Epoch: 26, Batch: 6, Loss: 0.1237\n",
            "root        : INFO     Epoch: 26, Batch: 7, Loss: 0.0987\n",
            "root        : INFO     Epoch: 26, Batch: 8, Loss: 0.0919\n",
            "root        : INFO     Epoch: 26, Batch: 9, Loss: 0.0888\n",
            "root        : INFO     Epoch: 26, Batch: 10, Loss: 0.1093\n",
            "root        : INFO     Epoch: 26, Batch: 11, Loss: 0.1194\n",
            "root        : INFO     Epoch: 26, Batch: 12, Loss: 0.1036\n",
            "root        : INFO     Epoch: 26, Batch: 13, Loss: 0.1066\n",
            "root        : INFO     Epoch: 26, Batch: 14, Loss: 0.1008\n",
            "root        : INFO     Epoch: 26, Batch: 15, Loss: 0.1089\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     68/89 = 0.764045\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 1, Loss: 0.1040\n",
            "root        : INFO     Epoch: 27, Batch: 2, Loss: 0.0949\n",
            "root        : INFO     Epoch: 27, Batch: 3, Loss: 0.1092\n",
            "root        : INFO     Epoch: 27, Batch: 4, Loss: 0.1013\n",
            "root        : INFO     Epoch: 27, Batch: 5, Loss: 0.1051\n",
            "root        : INFO     Epoch: 27, Batch: 6, Loss: 0.0913\n",
            "root        : INFO     Epoch: 27, Batch: 7, Loss: 0.0972\n",
            "root        : INFO     Epoch: 27, Batch: 8, Loss: 0.0982\n",
            "root        : INFO     Epoch: 27, Batch: 9, Loss: 0.0922\n",
            "root        : INFO     Epoch: 27, Batch: 10, Loss: 0.0994\n",
            "root        : INFO     Epoch: 27, Batch: 11, Loss: 0.1126\n",
            "root        : INFO     Epoch: 27, Batch: 12, Loss: 0.0967\n",
            "root        : INFO     Epoch: 27, Batch: 13, Loss: 0.1175\n",
            "root        : INFO     Epoch: 27, Batch: 14, Loss: 0.0968\n",
            "root        : INFO     Epoch: 27, Batch: 15, Loss: 0.0980\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     55/89 = 0.617978\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 1, Loss: 0.0950\n",
            "root        : INFO     Epoch: 28, Batch: 2, Loss: 0.0992\n",
            "root        : INFO     Epoch: 28, Batch: 3, Loss: 0.1088\n",
            "root        : INFO     Epoch: 28, Batch: 4, Loss: 0.1097\n",
            "root        : INFO     Epoch: 28, Batch: 5, Loss: 0.0995\n",
            "root        : INFO     Epoch: 28, Batch: 6, Loss: 0.0877\n",
            "root        : INFO     Epoch: 28, Batch: 7, Loss: 0.1040\n",
            "root        : INFO     Epoch: 28, Batch: 8, Loss: 0.1052\n",
            "root        : INFO     Epoch: 28, Batch: 9, Loss: 0.0991\n",
            "root        : INFO     Epoch: 28, Batch: 10, Loss: 0.1070\n",
            "root        : INFO     Epoch: 28, Batch: 11, Loss: 0.1138\n",
            "root        : INFO     Epoch: 28, Batch: 12, Loss: 0.1036\n",
            "root        : INFO     Epoch: 28, Batch: 13, Loss: 0.1021\n",
            "root        : INFO     Epoch: 28, Batch: 14, Loss: 0.0936\n",
            "root        : INFO     Epoch: 28, Batch: 15, Loss: 0.0997\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     60/89 = 0.674157\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 1, Loss: 0.0963\n",
            "root        : INFO     Epoch: 29, Batch: 2, Loss: 0.0941\n",
            "root        : INFO     Epoch: 29, Batch: 3, Loss: 0.1109\n",
            "root        : INFO     Epoch: 29, Batch: 4, Loss: 0.1130\n",
            "root        : INFO     Epoch: 29, Batch: 5, Loss: 0.1017\n",
            "root        : INFO     Epoch: 29, Batch: 6, Loss: 0.0876\n",
            "root        : INFO     Epoch: 29, Batch: 7, Loss: 0.0973\n",
            "root        : INFO     Epoch: 29, Batch: 8, Loss: 0.1067\n",
            "root        : INFO     Epoch: 29, Batch: 9, Loss: 0.0990\n",
            "root        : INFO     Epoch: 29, Batch: 10, Loss: 0.1137\n",
            "root        : INFO     Epoch: 29, Batch: 11, Loss: 0.1098\n",
            "root        : INFO     Epoch: 29, Batch: 12, Loss: 0.1056\n",
            "root        : INFO     Epoch: 29, Batch: 13, Loss: 0.0858\n",
            "root        : INFO     Epoch: 29, Batch: 14, Loss: 0.0946\n",
            "root        : INFO     Epoch: 29, Batch: 15, Loss: 0.0818\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     50/89 = 0.561798\n",
            "root        : INFO     Beginning Epoch 30\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 30, Batch: 1, Loss: 0.1148\n",
            "root        : INFO     Epoch: 30, Batch: 2, Loss: 0.1003\n",
            "root        : INFO     Epoch: 30, Batch: 3, Loss: 0.1045\n",
            "root        : INFO     Epoch: 30, Batch: 4, Loss: 0.1020\n",
            "root        : INFO     Epoch: 30, Batch: 5, Loss: 0.1071\n",
            "root        : INFO     Epoch: 30, Batch: 6, Loss: 0.1143\n",
            "root        : INFO     Epoch: 30, Batch: 7, Loss: 0.0951\n",
            "root        : INFO     Epoch: 30, Batch: 8, Loss: 0.1133\n",
            "root        : INFO     Epoch: 30, Batch: 9, Loss: 0.0974\n",
            "root        : INFO     Epoch: 30, Batch: 10, Loss: 0.0988\n",
            "root        : INFO     Epoch: 30, Batch: 11, Loss: 0.1157\n",
            "root        : INFO     Epoch: 30, Batch: 12, Loss: 0.1093\n",
            "root        : INFO     Epoch: 30, Batch: 13, Loss: 0.0682\n",
            "root        : INFO     Epoch: 30, Batch: 14, Loss: 0.0863\n",
            "root        : INFO     Epoch: 30, Batch: 15, Loss: 0.0994\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     49/89 = 0.550562\n",
            "root        : INFO     Beginning Epoch 31\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 31, Batch: 1, Loss: 0.1005\n",
            "root        : INFO     Epoch: 31, Batch: 2, Loss: 0.1037\n",
            "root        : INFO     Epoch: 31, Batch: 3, Loss: 0.0861\n",
            "root        : INFO     Epoch: 31, Batch: 4, Loss: 0.0895\n",
            "root        : INFO     Epoch: 31, Batch: 5, Loss: 0.1075\n",
            "root        : INFO     Epoch: 31, Batch: 6, Loss: 0.0941\n",
            "root        : INFO     Epoch: 31, Batch: 7, Loss: 0.1040\n",
            "root        : INFO     Epoch: 31, Batch: 8, Loss: 0.1062\n",
            "root        : INFO     Epoch: 31, Batch: 9, Loss: 0.1131\n",
            "root        : INFO     Epoch: 31, Batch: 10, Loss: 0.0917\n",
            "root        : INFO     Epoch: 31, Batch: 11, Loss: 0.1078\n",
            "root        : INFO     Epoch: 31, Batch: 12, Loss: 0.1128\n",
            "root        : INFO     Epoch: 31, Batch: 13, Loss: 0.1344\n",
            "root        : INFO     Epoch: 31, Batch: 14, Loss: 0.1048\n",
            "root        : INFO     Epoch: 31, Batch: 15, Loss: 0.0927\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     61/89 = 0.685393\n",
            "root        : INFO     Beginning Epoch 32\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 32, Batch: 1, Loss: 0.1035\n",
            "root        : INFO     Epoch: 32, Batch: 2, Loss: 0.0894\n",
            "root        : INFO     Epoch: 32, Batch: 3, Loss: 0.1077\n",
            "root        : INFO     Epoch: 32, Batch: 4, Loss: 0.0947\n",
            "root        : INFO     Epoch: 32, Batch: 5, Loss: 0.0891\n",
            "root        : INFO     Epoch: 32, Batch: 6, Loss: 0.1222\n",
            "root        : INFO     Epoch: 32, Batch: 7, Loss: 0.1048\n",
            "root        : INFO     Epoch: 32, Batch: 8, Loss: 0.1189\n",
            "root        : INFO     Epoch: 32, Batch: 9, Loss: 0.0904\n",
            "root        : INFO     Epoch: 32, Batch: 10, Loss: 0.0982\n",
            "root        : INFO     Epoch: 32, Batch: 11, Loss: 0.1082\n",
            "root        : INFO     Epoch: 32, Batch: 12, Loss: 0.1163\n",
            "root        : INFO     Epoch: 32, Batch: 13, Loss: 0.1203\n",
            "root        : INFO     Epoch: 32, Batch: 14, Loss: 0.0864\n",
            "root        : INFO     Epoch: 32, Batch: 15, Loss: 0.1117\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     51/89 = 0.573034\n",
            "root        : INFO     Beginning Epoch 33\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 33, Batch: 1, Loss: 0.0861\n",
            "root        : INFO     Epoch: 33, Batch: 2, Loss: 0.1231\n",
            "root        : INFO     Epoch: 33, Batch: 3, Loss: 0.1007\n",
            "root        : INFO     Epoch: 33, Batch: 4, Loss: 0.1120\n",
            "root        : INFO     Epoch: 33, Batch: 5, Loss: 0.0906\n",
            "root        : INFO     Epoch: 33, Batch: 6, Loss: 0.0926\n",
            "root        : INFO     Epoch: 33, Batch: 7, Loss: 0.1102\n",
            "root        : INFO     Epoch: 33, Batch: 8, Loss: 0.1015\n",
            "root        : INFO     Epoch: 33, Batch: 9, Loss: 0.1115\n",
            "root        : INFO     Epoch: 33, Batch: 10, Loss: 0.0891\n",
            "root        : INFO     Epoch: 33, Batch: 11, Loss: 0.1039\n",
            "root        : INFO     Epoch: 33, Batch: 12, Loss: 0.1042\n",
            "root        : INFO     Epoch: 33, Batch: 13, Loss: 0.0902\n",
            "root        : INFO     Epoch: 33, Batch: 14, Loss: 0.1110\n",
            "root        : INFO     Epoch: 33, Batch: 15, Loss: 0.1079\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     52/89 = 0.584270\n",
            "root        : INFO     Beginning Epoch 34\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 34, Batch: 1, Loss: 0.1117\n",
            "root        : INFO     Epoch: 34, Batch: 2, Loss: 0.1217\n",
            "root        : INFO     Epoch: 34, Batch: 3, Loss: 0.0861\n",
            "root        : INFO     Epoch: 34, Batch: 4, Loss: 0.1007\n",
            "root        : INFO     Epoch: 34, Batch: 5, Loss: 0.0929\n",
            "root        : INFO     Epoch: 34, Batch: 6, Loss: 0.0854\n",
            "root        : INFO     Epoch: 34, Batch: 7, Loss: 0.1051\n",
            "root        : INFO     Epoch: 34, Batch: 8, Loss: 0.1183\n",
            "root        : INFO     Epoch: 34, Batch: 9, Loss: 0.1089\n",
            "root        : INFO     Epoch: 34, Batch: 10, Loss: 0.0987\n",
            "root        : INFO     Epoch: 34, Batch: 11, Loss: 0.0873\n",
            "root        : INFO     Epoch: 34, Batch: 12, Loss: 0.1086\n",
            "root        : INFO     Epoch: 34, Batch: 13, Loss: 0.0848\n",
            "root        : INFO     Epoch: 34, Batch: 14, Loss: 0.0951\n",
            "root        : INFO     Epoch: 34, Batch: 15, Loss: 0.1126\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     62/89 = 0.696629\n",
            "root        : INFO     Beginning Epoch 35\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 35, Batch: 1, Loss: 0.0869\n",
            "root        : INFO     Epoch: 35, Batch: 2, Loss: 0.1169\n",
            "root        : INFO     Epoch: 35, Batch: 3, Loss: 0.0973\n",
            "root        : INFO     Epoch: 35, Batch: 4, Loss: 0.1079\n",
            "root        : INFO     Epoch: 35, Batch: 5, Loss: 0.0928\n",
            "root        : INFO     Epoch: 35, Batch: 6, Loss: 0.0852\n",
            "root        : INFO     Epoch: 35, Batch: 7, Loss: 0.0921\n",
            "root        : INFO     Epoch: 35, Batch: 8, Loss: 0.1097\n",
            "root        : INFO     Epoch: 35, Batch: 9, Loss: 0.1050\n",
            "root        : INFO     Epoch: 35, Batch: 10, Loss: 0.0815\n",
            "root        : INFO     Epoch: 35, Batch: 11, Loss: 0.0929\n",
            "root        : INFO     Epoch: 35, Batch: 12, Loss: 0.1179\n",
            "root        : INFO     Epoch: 35, Batch: 13, Loss: 0.1159\n",
            "root        : INFO     Epoch: 35, Batch: 14, Loss: 0.1007\n",
            "root        : INFO     Epoch: 35, Batch: 15, Loss: 0.1066\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/89 = 0.707865\n",
            "root        : INFO     Beginning Epoch 36\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 36, Batch: 1, Loss: 0.0725\n",
            "root        : INFO     Epoch: 36, Batch: 2, Loss: 0.0971\n",
            "root        : INFO     Epoch: 36, Batch: 3, Loss: 0.0987\n",
            "root        : INFO     Epoch: 36, Batch: 4, Loss: 0.1079\n",
            "root        : INFO     Epoch: 36, Batch: 5, Loss: 0.1084\n",
            "root        : INFO     Epoch: 36, Batch: 6, Loss: 0.1053\n",
            "root        : INFO     Epoch: 36, Batch: 7, Loss: 0.1010\n",
            "root        : INFO     Epoch: 36, Batch: 8, Loss: 0.0948\n",
            "root        : INFO     Epoch: 36, Batch: 9, Loss: 0.1088\n",
            "root        : INFO     Epoch: 36, Batch: 10, Loss: 0.1030\n",
            "root        : INFO     Epoch: 36, Batch: 11, Loss: 0.0988\n",
            "root        : INFO     Epoch: 36, Batch: 12, Loss: 0.1001\n",
            "root        : INFO     Epoch: 36, Batch: 13, Loss: 0.1084\n",
            "root        : INFO     Epoch: 36, Batch: 14, Loss: 0.1060\n",
            "root        : INFO     Epoch: 36, Batch: 15, Loss: 0.0962\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     54/89 = 0.606742\n",
            "root        : INFO     Beginning Epoch 37\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 37, Batch: 1, Loss: 0.0961\n",
            "root        : INFO     Epoch: 37, Batch: 2, Loss: 0.0963\n",
            "root        : INFO     Epoch: 37, Batch: 3, Loss: 0.0971\n",
            "root        : INFO     Epoch: 37, Batch: 4, Loss: 0.0998\n",
            "root        : INFO     Epoch: 37, Batch: 5, Loss: 0.0950\n",
            "root        : INFO     Epoch: 37, Batch: 6, Loss: 0.0897\n",
            "root        : INFO     Epoch: 37, Batch: 7, Loss: 0.1027\n",
            "root        : INFO     Epoch: 37, Batch: 8, Loss: 0.0931\n",
            "root        : INFO     Epoch: 37, Batch: 9, Loss: 0.1260\n",
            "root        : INFO     Epoch: 37, Batch: 10, Loss: 0.1029\n",
            "root        : INFO     Epoch: 37, Batch: 11, Loss: 0.1134\n",
            "root        : INFO     Epoch: 37, Batch: 12, Loss: 0.0865\n",
            "root        : INFO     Epoch: 37, Batch: 13, Loss: 0.1182\n",
            "root        : INFO     Epoch: 37, Batch: 14, Loss: 0.1011\n",
            "root        : INFO     Epoch: 37, Batch: 15, Loss: 0.1203\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     61/89 = 0.685393\n",
            "root        : INFO     Beginning Epoch 38\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 38, Batch: 1, Loss: 0.1104\n",
            "root        : INFO     Epoch: 38, Batch: 2, Loss: 0.0889\n",
            "root        : INFO     Epoch: 38, Batch: 3, Loss: 0.1003\n",
            "root        : INFO     Epoch: 38, Batch: 4, Loss: 0.0862\n",
            "root        : INFO     Epoch: 38, Batch: 5, Loss: 0.1118\n",
            "root        : INFO     Epoch: 38, Batch: 6, Loss: 0.0988\n",
            "root        : INFO     Epoch: 38, Batch: 7, Loss: 0.1017\n",
            "root        : INFO     Epoch: 38, Batch: 8, Loss: 0.1005\n",
            "root        : INFO     Epoch: 38, Batch: 9, Loss: 0.0900\n",
            "root        : INFO     Epoch: 38, Batch: 10, Loss: 0.0923\n",
            "root        : INFO     Epoch: 38, Batch: 11, Loss: 0.0853\n",
            "root        : INFO     Epoch: 38, Batch: 12, Loss: 0.0907\n",
            "root        : INFO     Epoch: 38, Batch: 13, Loss: 0.0887\n",
            "root        : INFO     Epoch: 38, Batch: 14, Loss: 0.0933\n",
            "root        : INFO     Epoch: 38, Batch: 15, Loss: 0.1126\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/89 = 0.707865\n",
            "root        : INFO     Beginning Epoch 39\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 39, Batch: 1, Loss: 0.0895\n",
            "root        : INFO     Epoch: 39, Batch: 2, Loss: 0.1066\n",
            "root        : INFO     Epoch: 39, Batch: 3, Loss: 0.1069\n",
            "root        : INFO     Epoch: 39, Batch: 4, Loss: 0.0960\n",
            "root        : INFO     Epoch: 39, Batch: 5, Loss: 0.0942\n",
            "root        : INFO     Epoch: 39, Batch: 6, Loss: 0.1005\n",
            "root        : INFO     Epoch: 39, Batch: 7, Loss: 0.0913\n",
            "root        : INFO     Epoch: 39, Batch: 8, Loss: 0.0931\n",
            "root        : INFO     Epoch: 39, Batch: 9, Loss: 0.0934\n",
            "root        : INFO     Epoch: 39, Batch: 10, Loss: 0.1084\n",
            "root        : INFO     Epoch: 39, Batch: 11, Loss: 0.0900\n",
            "root        : INFO     Epoch: 39, Batch: 12, Loss: 0.0983\n",
            "root        : INFO     Epoch: 39, Batch: 13, Loss: 0.1054\n",
            "root        : INFO     Epoch: 39, Batch: 14, Loss: 0.1037\n",
            "root        : INFO     Epoch: 39, Batch: 15, Loss: 0.0890\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     55/89 = 0.617978\n",
            "root        : INFO     Beginning Epoch 40\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 40, Batch: 1, Loss: 0.0780\n",
            "root        : INFO     Epoch: 40, Batch: 2, Loss: 0.1123\n",
            "root        : INFO     Epoch: 40, Batch: 3, Loss: 0.0965\n",
            "root        : INFO     Epoch: 40, Batch: 4, Loss: 0.1034\n",
            "root        : INFO     Epoch: 40, Batch: 5, Loss: 0.1088\n",
            "root        : INFO     Epoch: 40, Batch: 6, Loss: 0.0996\n",
            "root        : INFO     Epoch: 40, Batch: 7, Loss: 0.0914\n",
            "root        : INFO     Epoch: 40, Batch: 8, Loss: 0.1064\n",
            "root        : INFO     Epoch: 40, Batch: 9, Loss: 0.1067\n",
            "root        : INFO     Epoch: 40, Batch: 10, Loss: 0.0861\n",
            "root        : INFO     Epoch: 40, Batch: 11, Loss: 0.0979\n",
            "root        : INFO     Epoch: 40, Batch: 12, Loss: 0.0874\n",
            "root        : INFO     Epoch: 40, Batch: 13, Loss: 0.0935\n",
            "root        : INFO     Epoch: 40, Batch: 14, Loss: 0.0856\n",
            "root        : INFO     Epoch: 40, Batch: 15, Loss: 0.1049\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/89 = 0.707865\n",
            "root        : INFO     Beginning Epoch 41\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 41, Batch: 1, Loss: 0.0908\n",
            "root        : INFO     Epoch: 41, Batch: 2, Loss: 0.0925\n",
            "root        : INFO     Epoch: 41, Batch: 3, Loss: 0.0950\n",
            "root        : INFO     Epoch: 41, Batch: 4, Loss: 0.0867\n",
            "root        : INFO     Epoch: 41, Batch: 5, Loss: 0.1100\n",
            "root        : INFO     Epoch: 41, Batch: 6, Loss: 0.0929\n",
            "root        : INFO     Epoch: 41, Batch: 7, Loss: 0.0857\n",
            "root        : INFO     Epoch: 41, Batch: 8, Loss: 0.0943\n",
            "root        : INFO     Epoch: 41, Batch: 9, Loss: 0.0903\n",
            "root        : INFO     Epoch: 41, Batch: 10, Loss: 0.0922\n",
            "root        : INFO     Epoch: 41, Batch: 11, Loss: 0.0891\n",
            "root        : INFO     Epoch: 41, Batch: 12, Loss: 0.0849\n",
            "root        : INFO     Epoch: 41, Batch: 13, Loss: 0.1139\n",
            "root        : INFO     Epoch: 41, Batch: 14, Loss: 0.0835\n",
            "root        : INFO     Epoch: 41, Batch: 15, Loss: 0.1061\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     55/89 = 0.617978\n",
            "root        : INFO     Beginning Epoch 42\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 42, Batch: 1, Loss: 0.1019\n",
            "root        : INFO     Epoch: 42, Batch: 2, Loss: 0.0970\n",
            "root        : INFO     Epoch: 42, Batch: 3, Loss: 0.1011\n",
            "root        : INFO     Epoch: 42, Batch: 4, Loss: 0.0933\n",
            "root        : INFO     Epoch: 42, Batch: 5, Loss: 0.1017\n",
            "root        : INFO     Epoch: 42, Batch: 6, Loss: 0.0975\n",
            "root        : INFO     Epoch: 42, Batch: 7, Loss: 0.1001\n",
            "root        : INFO     Epoch: 42, Batch: 8, Loss: 0.0998\n",
            "root        : INFO     Epoch: 42, Batch: 9, Loss: 0.0880\n",
            "root        : INFO     Epoch: 42, Batch: 10, Loss: 0.0953\n",
            "root        : INFO     Epoch: 42, Batch: 11, Loss: 0.1004\n",
            "root        : INFO     Epoch: 42, Batch: 12, Loss: 0.1043\n",
            "root        : INFO     Epoch: 42, Batch: 13, Loss: 0.1047\n",
            "root        : INFO     Epoch: 42, Batch: 14, Loss: 0.0894\n",
            "root        : INFO     Epoch: 42, Batch: 15, Loss: 0.1004\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     57/89 = 0.640449\n",
            "root        : INFO     Beginning Epoch 43\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 43, Batch: 1, Loss: 0.0888\n",
            "root        : INFO     Epoch: 43, Batch: 2, Loss: 0.1032\n",
            "root        : INFO     Epoch: 43, Batch: 3, Loss: 0.1019\n",
            "root        : INFO     Epoch: 43, Batch: 4, Loss: 0.0964\n",
            "root        : INFO     Epoch: 43, Batch: 5, Loss: 0.0968\n",
            "root        : INFO     Epoch: 43, Batch: 6, Loss: 0.0840\n",
            "root        : INFO     Epoch: 43, Batch: 7, Loss: 0.0793\n",
            "root        : INFO     Epoch: 43, Batch: 8, Loss: 0.0900\n",
            "root        : INFO     Epoch: 43, Batch: 9, Loss: 0.0971\n",
            "root        : INFO     Epoch: 43, Batch: 10, Loss: 0.1026\n",
            "root        : INFO     Epoch: 43, Batch: 11, Loss: 0.1058\n",
            "root        : INFO     Epoch: 43, Batch: 12, Loss: 0.0870\n",
            "root        : INFO     Epoch: 43, Batch: 13, Loss: 0.0822\n",
            "root        : INFO     Epoch: 43, Batch: 14, Loss: 0.0847\n",
            "root        : INFO     Epoch: 43, Batch: 15, Loss: 0.0941\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     64/89 = 0.719101\n",
            "root        : INFO     Beginning Epoch 44\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 44, Batch: 1, Loss: 0.0972\n",
            "root        : INFO     Epoch: 44, Batch: 2, Loss: 0.1013\n",
            "root        : INFO     Epoch: 44, Batch: 3, Loss: 0.0955\n",
            "root        : INFO     Epoch: 44, Batch: 4, Loss: 0.0988\n",
            "root        : INFO     Epoch: 44, Batch: 5, Loss: 0.0825\n",
            "root        : INFO     Epoch: 44, Batch: 6, Loss: 0.0990\n",
            "root        : INFO     Epoch: 44, Batch: 7, Loss: 0.0928\n",
            "root        : INFO     Epoch: 44, Batch: 8, Loss: 0.0977\n",
            "root        : INFO     Epoch: 44, Batch: 9, Loss: 0.0892\n",
            "root        : INFO     Epoch: 44, Batch: 10, Loss: 0.0902\n",
            "root        : INFO     Epoch: 44, Batch: 11, Loss: 0.0898\n",
            "root        : INFO     Epoch: 44, Batch: 12, Loss: 0.1061\n",
            "root        : INFO     Epoch: 44, Batch: 13, Loss: 0.0846\n",
            "root        : INFO     Epoch: 44, Batch: 14, Loss: 0.0878\n",
            "root        : INFO     Epoch: 44, Batch: 15, Loss: 0.1048\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     59/89 = 0.662921\n",
            "root        : INFO     Beginning Epoch 45\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 45, Batch: 1, Loss: 0.1177\n",
            "root        : INFO     Epoch: 45, Batch: 2, Loss: 0.1079\n",
            "root        : INFO     Epoch: 45, Batch: 3, Loss: 0.0819\n",
            "root        : INFO     Epoch: 45, Batch: 4, Loss: 0.1071\n",
            "root        : INFO     Epoch: 45, Batch: 5, Loss: 0.0882\n",
            "root        : INFO     Epoch: 45, Batch: 6, Loss: 0.0865\n",
            "root        : INFO     Epoch: 45, Batch: 7, Loss: 0.1014\n",
            "root        : INFO     Epoch: 45, Batch: 8, Loss: 0.0890\n",
            "root        : INFO     Epoch: 45, Batch: 9, Loss: 0.0887\n",
            "root        : INFO     Epoch: 45, Batch: 10, Loss: 0.0890\n",
            "root        : INFO     Epoch: 45, Batch: 11, Loss: 0.0910\n",
            "root        : INFO     Epoch: 45, Batch: 12, Loss: 0.0894\n",
            "root        : INFO     Epoch: 45, Batch: 13, Loss: 0.0915\n",
            "root        : INFO     Epoch: 45, Batch: 14, Loss: 0.1034\n",
            "root        : INFO     Epoch: 45, Batch: 15, Loss: 0.0973\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/89 = 0.707865\n",
            "root        : INFO     Beginning Epoch 46\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 46, Batch: 1, Loss: 0.0989\n",
            "root        : INFO     Epoch: 46, Batch: 2, Loss: 0.0868\n",
            "root        : INFO     Epoch: 46, Batch: 3, Loss: 0.1042\n",
            "root        : INFO     Epoch: 46, Batch: 4, Loss: 0.0926\n",
            "root        : INFO     Epoch: 46, Batch: 5, Loss: 0.0939\n",
            "root        : INFO     Epoch: 46, Batch: 6, Loss: 0.0906\n",
            "root        : INFO     Epoch: 46, Batch: 7, Loss: 0.0812\n",
            "root        : INFO     Epoch: 46, Batch: 8, Loss: 0.0957\n",
            "root        : INFO     Epoch: 46, Batch: 9, Loss: 0.1024\n",
            "root        : INFO     Epoch: 46, Batch: 10, Loss: 0.1027\n",
            "root        : INFO     Epoch: 46, Batch: 11, Loss: 0.0850\n",
            "root        : INFO     Epoch: 46, Batch: 12, Loss: 0.1023\n",
            "root        : INFO     Epoch: 46, Batch: 13, Loss: 0.0840\n",
            "root        : INFO     Epoch: 46, Batch: 14, Loss: 0.0936\n",
            "root        : INFO     Epoch: 46, Batch: 15, Loss: 0.0972\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     58/89 = 0.651685\n",
            "root        : INFO     Beginning Epoch 47\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 47, Batch: 1, Loss: 0.1015\n",
            "root        : INFO     Epoch: 47, Batch: 2, Loss: 0.0922\n",
            "root        : INFO     Epoch: 47, Batch: 3, Loss: 0.0839\n",
            "root        : INFO     Epoch: 47, Batch: 4, Loss: 0.1017\n",
            "root        : INFO     Epoch: 47, Batch: 5, Loss: 0.0966\n",
            "root        : INFO     Epoch: 47, Batch: 6, Loss: 0.0916\n",
            "root        : INFO     Epoch: 47, Batch: 7, Loss: 0.0883\n",
            "root        : INFO     Epoch: 47, Batch: 8, Loss: 0.0908\n",
            "root        : INFO     Epoch: 47, Batch: 9, Loss: 0.0965\n",
            "root        : INFO     Epoch: 47, Batch: 10, Loss: 0.1052\n",
            "root        : INFO     Epoch: 47, Batch: 11, Loss: 0.0925\n",
            "root        : INFO     Epoch: 47, Batch: 12, Loss: 0.0854\n",
            "root        : INFO     Epoch: 47, Batch: 13, Loss: 0.0766\n",
            "root        : INFO     Epoch: 47, Batch: 14, Loss: 0.0970\n",
            "root        : INFO     Epoch: 47, Batch: 15, Loss: 0.0843\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     65/89 = 0.730337\n",
            "root        : INFO     Beginning Epoch 48\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 48, Batch: 1, Loss: 0.1061\n",
            "root        : INFO     Epoch: 48, Batch: 2, Loss: 0.0900\n",
            "root        : INFO     Epoch: 48, Batch: 3, Loss: 0.0763\n",
            "root        : INFO     Epoch: 48, Batch: 4, Loss: 0.0848\n",
            "root        : INFO     Epoch: 48, Batch: 5, Loss: 0.0910\n",
            "root        : INFO     Epoch: 48, Batch: 6, Loss: 0.0871\n",
            "root        : INFO     Epoch: 48, Batch: 7, Loss: 0.0942\n",
            "root        : INFO     Epoch: 48, Batch: 8, Loss: 0.0908\n",
            "root        : INFO     Epoch: 48, Batch: 9, Loss: 0.0922\n",
            "root        : INFO     Epoch: 48, Batch: 10, Loss: 0.0813\n",
            "root        : INFO     Epoch: 48, Batch: 11, Loss: 0.1058\n",
            "root        : INFO     Epoch: 48, Batch: 12, Loss: 0.0949\n",
            "root        : INFO     Epoch: 48, Batch: 13, Loss: 0.1502\n",
            "root        : INFO     Epoch: 48, Batch: 14, Loss: 0.0985\n",
            "root        : INFO     Epoch: 48, Batch: 15, Loss: 0.0817\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     63/89 = 0.707865\n",
            "root        : INFO     Beginning Epoch 49\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 49, Batch: 1, Loss: 0.0875\n",
            "root        : INFO     Epoch: 49, Batch: 2, Loss: 0.0854\n",
            "root        : INFO     Epoch: 49, Batch: 3, Loss: 0.0793\n",
            "root        : INFO     Epoch: 49, Batch: 4, Loss: 0.0869\n",
            "root        : INFO     Epoch: 49, Batch: 5, Loss: 0.0701\n",
            "root        : INFO     Epoch: 49, Batch: 6, Loss: 0.0753\n",
            "root        : INFO     Epoch: 49, Batch: 7, Loss: 0.1014\n",
            "root        : INFO     Epoch: 49, Batch: 8, Loss: 0.0785\n",
            "root        : INFO     Epoch: 49, Batch: 9, Loss: 0.1129\n",
            "root        : INFO     Epoch: 49, Batch: 10, Loss: 0.0968\n",
            "root        : INFO     Epoch: 49, Batch: 11, Loss: 0.1124\n",
            "root        : INFO     Epoch: 49, Batch: 12, Loss: 0.0956\n",
            "root        : INFO     Epoch: 49, Batch: 13, Loss: 0.1076\n",
            "root        : INFO     Epoch: 49, Batch: 14, Loss: 0.1018\n",
            "root        : INFO     Epoch: 49, Batch: 15, Loss: 0.0914\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     61/89 = 0.685393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVDNZKmnbJ-X"
      },
      "source": [
        "**Poor performance - Batch size =32, which is larger than the optimal value.**    \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210402_1537_training_cornell  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpcqF1cafuOJ",
        "outputId": "e7bead34-ac88-4c53-b9a3-6b3a2ca21e7b"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 32 --batches-per-epoch 224 --split 0.8  --ds-shuffle --ds-rotate 0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.20, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 32, bacthes per epoch = 224, optimizer = adam\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.4912\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.2166\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.1437\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.1247\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1631\n",
            "root        : INFO     Epoch: 0, Batch: 120, Loss: 0.1326\n",
            "root        : INFO     Epoch: 0, Batch: 140, Loss: 0.1398\n",
            "root        : INFO     Epoch: 0, Batch: 160, Loss: 0.1259\n",
            "root        : INFO     Epoch: 0, Batch: 180, Loss: 0.1201\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1113\n",
            "root        : INFO     Epoch: 0, Batch: 220, Loss: 0.1192\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     57/177 = 0.322034\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.1265\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.1415\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.1230\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0993\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1129\n",
            "root        : INFO     Epoch: 1, Batch: 120, Loss: 0.0994\n",
            "root        : INFO     Epoch: 1, Batch: 140, Loss: 0.1098\n",
            "root        : INFO     Epoch: 1, Batch: 160, Loss: 0.1208\n",
            "root        : INFO     Epoch: 1, Batch: 180, Loss: 0.1255\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0791\n",
            "root        : INFO     Epoch: 1, Batch: 220, Loss: 0.0876\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     56/177 = 0.316384\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.1401\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.1297\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.1181\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.1239\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1023\n",
            "root        : INFO     Epoch: 2, Batch: 120, Loss: 0.1034\n",
            "root        : INFO     Epoch: 2, Batch: 140, Loss: 0.1110\n",
            "root        : INFO     Epoch: 2, Batch: 160, Loss: 0.1222\n",
            "root        : INFO     Epoch: 2, Batch: 180, Loss: 0.1077\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.1296\n",
            "root        : INFO     Epoch: 2, Batch: 220, Loss: 0.1073\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     54/177 = 0.305085\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.1139\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.1098\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.1023\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.1039\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.1055\n",
            "root        : INFO     Epoch: 3, Batch: 120, Loss: 0.1682\n",
            "root        : INFO     Epoch: 3, Batch: 140, Loss: 0.1169\n",
            "root        : INFO     Epoch: 3, Batch: 160, Loss: 0.0876\n",
            "root        : INFO     Epoch: 3, Batch: 180, Loss: 0.1027\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.1053\n",
            "root        : INFO     Epoch: 3, Batch: 220, Loss: 0.1042\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     67/177 = 0.378531\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.1094\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.1107\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.1136\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.1098\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.1031\n",
            "root        : INFO     Epoch: 4, Batch: 120, Loss: 0.1074\n",
            "root        : INFO     Epoch: 4, Batch: 140, Loss: 0.1050\n",
            "root        : INFO     Epoch: 4, Batch: 160, Loss: 0.0958\n",
            "root        : INFO     Epoch: 4, Batch: 180, Loss: 0.0891\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.1050\n",
            "root        : INFO     Epoch: 4, Batch: 220, Loss: 0.1311\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0935\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.1573\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.1295\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.1443\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.1273\n",
            "root        : INFO     Epoch: 5, Batch: 120, Loss: 0.0932\n",
            "root        : INFO     Epoch: 5, Batch: 140, Loss: 0.0949\n",
            "root        : INFO     Epoch: 5, Batch: 160, Loss: 0.1359\n",
            "root        : INFO     Epoch: 5, Batch: 180, Loss: 0.1366\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.1229\n",
            "root        : INFO     Epoch: 5, Batch: 220, Loss: 0.1160\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     106/177 = 0.598870\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0835\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.1168\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.1311\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.1164\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.1187\n",
            "root        : INFO     Epoch: 6, Batch: 120, Loss: 0.1087\n",
            "root        : INFO     Epoch: 6, Batch: 140, Loss: 0.1033\n",
            "root        : INFO     Epoch: 6, Batch: 160, Loss: 0.1115\n",
            "root        : INFO     Epoch: 6, Batch: 180, Loss: 0.1035\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0967\n",
            "root        : INFO     Epoch: 6, Batch: 220, Loss: 0.1068\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     98/177 = 0.553672\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 20, Loss: 0.0802\n",
            "root        : INFO     Epoch: 7, Batch: 40, Loss: 0.0957\n",
            "root        : INFO     Epoch: 7, Batch: 60, Loss: 0.1066\n",
            "root        : INFO     Epoch: 7, Batch: 80, Loss: 0.1041\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.1077\n",
            "root        : INFO     Epoch: 7, Batch: 120, Loss: 0.1265\n",
            "root        : INFO     Epoch: 7, Batch: 140, Loss: 0.1037\n",
            "root        : INFO     Epoch: 7, Batch: 160, Loss: 0.1108\n",
            "root        : INFO     Epoch: 7, Batch: 180, Loss: 0.0985\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0963\n",
            "root        : INFO     Epoch: 7, Batch: 220, Loss: 0.0971\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     97/177 = 0.548023\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 20, Loss: 0.0961\n",
            "root        : INFO     Epoch: 8, Batch: 40, Loss: 0.1089\n",
            "root        : INFO     Epoch: 8, Batch: 60, Loss: 0.1148\n",
            "root        : INFO     Epoch: 8, Batch: 80, Loss: 0.1011\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.1229\n",
            "root        : INFO     Epoch: 8, Batch: 120, Loss: 0.0962\n",
            "root        : INFO     Epoch: 8, Batch: 140, Loss: 0.1067\n",
            "root        : INFO     Epoch: 8, Batch: 160, Loss: 0.0845\n",
            "root        : INFO     Epoch: 8, Batch: 180, Loss: 0.1189\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0868\n",
            "root        : INFO     Epoch: 8, Batch: 220, Loss: 0.1056\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     128/177 = 0.723164\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 20, Loss: 0.1273\n",
            "root        : INFO     Epoch: 9, Batch: 40, Loss: 0.0687\n",
            "root        : INFO     Epoch: 9, Batch: 60, Loss: 0.0974\n",
            "root        : INFO     Epoch: 9, Batch: 80, Loss: 0.1045\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.1072\n",
            "root        : INFO     Epoch: 9, Batch: 120, Loss: 0.0827\n",
            "root        : INFO     Epoch: 9, Batch: 140, Loss: 0.4755\n",
            "root        : INFO     Epoch: 9, Batch: 160, Loss: 0.1140\n",
            "root        : INFO     Epoch: 9, Batch: 180, Loss: 0.1089\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.1508\n",
            "root        : INFO     Epoch: 9, Batch: 220, Loss: 0.0970\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     45/177 = 0.254237\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 20, Loss: 0.1223\n",
            "root        : INFO     Epoch: 10, Batch: 40, Loss: 0.1122\n",
            "root        : INFO     Epoch: 10, Batch: 60, Loss: 0.1353\n",
            "root        : INFO     Epoch: 10, Batch: 80, Loss: 0.1188\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0990\n",
            "root        : INFO     Epoch: 10, Batch: 120, Loss: 0.0905\n",
            "root        : INFO     Epoch: 10, Batch: 140, Loss: 0.1280\n",
            "root        : INFO     Epoch: 10, Batch: 160, Loss: 0.0956\n",
            "root        : INFO     Epoch: 10, Batch: 180, Loss: 0.1282\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.1106\n",
            "root        : INFO     Epoch: 10, Batch: 220, Loss: 0.1013\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     61/177 = 0.344633\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 20, Loss: 0.1154\n",
            "root        : INFO     Epoch: 11, Batch: 40, Loss: 0.0947\n",
            "root        : INFO     Epoch: 11, Batch: 60, Loss: 0.0862\n",
            "root        : INFO     Epoch: 11, Batch: 80, Loss: 0.1186\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.1203\n",
            "root        : INFO     Epoch: 11, Batch: 120, Loss: 0.0988\n",
            "root        : INFO     Epoch: 11, Batch: 140, Loss: 0.1235\n",
            "root        : INFO     Epoch: 11, Batch: 160, Loss: 0.1520\n",
            "root        : INFO     Epoch: 11, Batch: 180, Loss: 0.1254\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0931\n",
            "root        : INFO     Epoch: 11, Batch: 220, Loss: 0.1203\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     37/177 = 0.209040\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 20, Loss: 0.1161\n",
            "root        : INFO     Epoch: 12, Batch: 40, Loss: 0.1042\n",
            "root        : INFO     Epoch: 12, Batch: 60, Loss: 0.0967\n",
            "root        : INFO     Epoch: 12, Batch: 80, Loss: 0.1284\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.1230\n",
            "root        : INFO     Epoch: 12, Batch: 120, Loss: 0.1405\n",
            "root        : INFO     Epoch: 12, Batch: 140, Loss: 0.1156\n",
            "root        : INFO     Epoch: 12, Batch: 160, Loss: 0.1080\n",
            "root        : INFO     Epoch: 12, Batch: 180, Loss: 0.1158\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.1199\n",
            "root        : INFO     Epoch: 12, Batch: 220, Loss: 0.1274\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     60/177 = 0.338983\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 20, Loss: 0.1071\n",
            "root        : INFO     Epoch: 13, Batch: 40, Loss: 0.1121\n",
            "root        : INFO     Epoch: 13, Batch: 60, Loss: 0.1131\n",
            "root        : INFO     Epoch: 13, Batch: 80, Loss: 0.1092\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.1211\n",
            "root        : INFO     Epoch: 13, Batch: 120, Loss: 0.1353\n",
            "root        : INFO     Epoch: 13, Batch: 140, Loss: 0.0825\n",
            "root        : INFO     Epoch: 13, Batch: 160, Loss: 0.0832\n",
            "root        : INFO     Epoch: 13, Batch: 180, Loss: 0.1114\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.1132\n",
            "root        : INFO     Epoch: 13, Batch: 220, Loss: 0.1033\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     87/177 = 0.491525\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 20, Loss: 0.1266\n",
            "root        : INFO     Epoch: 14, Batch: 40, Loss: 0.0968\n",
            "root        : INFO     Epoch: 14, Batch: 60, Loss: 0.0763\n",
            "root        : INFO     Epoch: 14, Batch: 80, Loss: 0.1030\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0937\n",
            "root        : INFO     Epoch: 14, Batch: 120, Loss: 0.0969\n",
            "root        : INFO     Epoch: 14, Batch: 140, Loss: 0.0917\n",
            "root        : INFO     Epoch: 14, Batch: 160, Loss: 0.1060\n",
            "root        : INFO     Epoch: 14, Batch: 180, Loss: 0.1136\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0940\n",
            "root        : INFO     Epoch: 14, Batch: 220, Loss: 0.0884\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     88/177 = 0.497175\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 20, Loss: 0.1020\n",
            "root        : INFO     Epoch: 15, Batch: 40, Loss: 0.1163\n",
            "root        : INFO     Epoch: 15, Batch: 60, Loss: 0.0826\n",
            "root        : INFO     Epoch: 15, Batch: 80, Loss: 0.1244\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.1007\n",
            "root        : INFO     Epoch: 15, Batch: 120, Loss: 0.1039\n",
            "root        : INFO     Epoch: 15, Batch: 140, Loss: 0.1188\n",
            "root        : INFO     Epoch: 15, Batch: 160, Loss: 0.0889\n",
            "root        : INFO     Epoch: 15, Batch: 180, Loss: 0.1223\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0963\n",
            "root        : INFO     Epoch: 15, Batch: 220, Loss: 0.0782\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     93/177 = 0.525424\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 20, Loss: 0.1063\n",
            "root        : INFO     Epoch: 16, Batch: 40, Loss: 0.1069\n",
            "root        : INFO     Epoch: 16, Batch: 60, Loss: 0.0829\n",
            "root        : INFO     Epoch: 16, Batch: 80, Loss: 0.0915\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0993\n",
            "root        : INFO     Epoch: 16, Batch: 120, Loss: 0.1274\n",
            "root        : INFO     Epoch: 16, Batch: 140, Loss: 0.1153\n",
            "root        : INFO     Epoch: 16, Batch: 160, Loss: 0.0677\n",
            "root        : INFO     Epoch: 16, Batch: 180, Loss: 0.0713\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0955\n",
            "root        : INFO     Epoch: 16, Batch: 220, Loss: 0.0666\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     106/177 = 0.598870\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 20, Loss: 0.0892\n",
            "root        : INFO     Epoch: 17, Batch: 40, Loss: 0.1002\n",
            "root        : INFO     Epoch: 17, Batch: 60, Loss: 0.0972\n",
            "root        : INFO     Epoch: 17, Batch: 80, Loss: 0.1180\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.1057\n",
            "root        : INFO     Epoch: 17, Batch: 120, Loss: 0.0824\n",
            "root        : INFO     Epoch: 17, Batch: 140, Loss: 0.0798\n",
            "root        : INFO     Epoch: 17, Batch: 160, Loss: 0.0911\n",
            "root        : INFO     Epoch: 17, Batch: 180, Loss: 0.1194\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0854\n",
            "root        : INFO     Epoch: 17, Batch: 220, Loss: 0.1030\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 20, Loss: 0.0974\n",
            "root        : INFO     Epoch: 18, Batch: 40, Loss: 0.1073\n",
            "root        : INFO     Epoch: 18, Batch: 60, Loss: 0.0859\n",
            "root        : INFO     Epoch: 18, Batch: 80, Loss: 0.1085\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0815\n",
            "root        : INFO     Epoch: 18, Batch: 120, Loss: 0.1005\n",
            "root        : INFO     Epoch: 18, Batch: 140, Loss: 0.0843\n",
            "root        : INFO     Epoch: 18, Batch: 160, Loss: 0.0874\n",
            "root        : INFO     Epoch: 18, Batch: 180, Loss: 0.0954\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0883\n",
            "root        : INFO     Epoch: 18, Batch: 220, Loss: 0.0762\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     119/177 = 0.672316\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 20, Loss: 0.1212\n",
            "root        : INFO     Epoch: 19, Batch: 40, Loss: 0.1150\n",
            "root        : INFO     Epoch: 19, Batch: 60, Loss: 0.0895\n",
            "root        : INFO     Epoch: 19, Batch: 80, Loss: 0.1126\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0789\n",
            "root        : INFO     Epoch: 19, Batch: 120, Loss: 0.0896\n",
            "root        : INFO     Epoch: 19, Batch: 140, Loss: 0.0917\n",
            "root        : INFO     Epoch: 19, Batch: 160, Loss: 0.1096\n",
            "root        : INFO     Epoch: 19, Batch: 180, Loss: 0.0997\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0771\n",
            "root        : INFO     Epoch: 19, Batch: 220, Loss: 0.0824\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     129/177 = 0.728814\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 20, Batch: 20, Loss: 0.1146\n",
            "root        : INFO     Epoch: 20, Batch: 40, Loss: 0.1123\n",
            "root        : INFO     Epoch: 20, Batch: 60, Loss: 0.0711\n",
            "root        : INFO     Epoch: 20, Batch: 80, Loss: 0.0770\n",
            "root        : INFO     Epoch: 20, Batch: 100, Loss: 0.0808\n",
            "root        : INFO     Epoch: 20, Batch: 120, Loss: 0.0892\n",
            "root        : INFO     Epoch: 20, Batch: 140, Loss: 0.0754\n",
            "root        : INFO     Epoch: 20, Batch: 160, Loss: 0.0916\n",
            "root        : INFO     Epoch: 20, Batch: 180, Loss: 0.1109\n",
            "root        : INFO     Epoch: 20, Batch: 200, Loss: 0.0557\n",
            "root        : INFO     Epoch: 20, Batch: 220, Loss: 0.0771\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     125/177 = 0.706215\n",
            "root        : INFO     Beginning Epoch 21\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 21, Batch: 20, Loss: 0.0649\n",
            "root        : INFO     Epoch: 21, Batch: 40, Loss: 0.0785\n",
            "root        : INFO     Epoch: 21, Batch: 60, Loss: 0.1009\n",
            "root        : INFO     Epoch: 21, Batch: 80, Loss: 0.1036\n",
            "root        : INFO     Epoch: 21, Batch: 100, Loss: 0.0693\n",
            "root        : INFO     Epoch: 21, Batch: 120, Loss: 0.0778\n",
            "root        : INFO     Epoch: 21, Batch: 140, Loss: 0.1209\n",
            "root        : INFO     Epoch: 21, Batch: 160, Loss: 0.1009\n",
            "root        : INFO     Epoch: 21, Batch: 180, Loss: 0.0782\n",
            "root        : INFO     Epoch: 21, Batch: 200, Loss: 0.1058\n",
            "root        : INFO     Epoch: 21, Batch: 220, Loss: 0.0761\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     122/177 = 0.689266\n",
            "root        : INFO     Beginning Epoch 22\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 22, Batch: 20, Loss: 0.0936\n",
            "root        : INFO     Epoch: 22, Batch: 40, Loss: 0.1085\n",
            "root        : INFO     Epoch: 22, Batch: 60, Loss: 0.0956\n",
            "root        : INFO     Epoch: 22, Batch: 80, Loss: 0.0885\n",
            "root        : INFO     Epoch: 22, Batch: 100, Loss: 0.1438\n",
            "root        : INFO     Epoch: 22, Batch: 120, Loss: 0.0818\n",
            "root        : INFO     Epoch: 22, Batch: 140, Loss: 0.1001\n",
            "root        : INFO     Epoch: 22, Batch: 160, Loss: 0.0768\n",
            "root        : INFO     Epoch: 22, Batch: 180, Loss: 0.0892\n",
            "root        : INFO     Epoch: 22, Batch: 200, Loss: 0.1051\n",
            "root        : INFO     Epoch: 22, Batch: 220, Loss: 0.0999\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     130/177 = 0.734463\n",
            "root        : INFO     Beginning Epoch 23\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 23, Batch: 20, Loss: 0.1007\n",
            "root        : INFO     Epoch: 23, Batch: 40, Loss: 0.0846\n",
            "root        : INFO     Epoch: 23, Batch: 60, Loss: 0.0779\n",
            "root        : INFO     Epoch: 23, Batch: 80, Loss: 0.0933\n",
            "root        : INFO     Epoch: 23, Batch: 100, Loss: 0.0902\n",
            "root        : INFO     Epoch: 23, Batch: 120, Loss: 0.1107\n",
            "root        : INFO     Epoch: 23, Batch: 140, Loss: 0.0858\n",
            "root        : INFO     Epoch: 23, Batch: 160, Loss: 0.0937\n",
            "root        : INFO     Epoch: 23, Batch: 180, Loss: 0.1037\n",
            "root        : INFO     Epoch: 23, Batch: 200, Loss: 0.0991\n",
            "root        : INFO     Epoch: 23, Batch: 220, Loss: 0.0764\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     136/177 = 0.768362\n",
            "root        : INFO     Beginning Epoch 24\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 24, Batch: 20, Loss: 0.0707\n",
            "root        : INFO     Epoch: 24, Batch: 40, Loss: 0.0912\n",
            "root        : INFO     Epoch: 24, Batch: 60, Loss: 0.0765\n",
            "root        : INFO     Epoch: 24, Batch: 80, Loss: 0.0693\n",
            "root        : INFO     Epoch: 24, Batch: 100, Loss: 0.0780\n",
            "root        : INFO     Epoch: 24, Batch: 120, Loss: 0.0732\n",
            "root        : INFO     Epoch: 24, Batch: 140, Loss: 0.1095\n",
            "root        : INFO     Epoch: 24, Batch: 160, Loss: 0.1065\n",
            "root        : INFO     Epoch: 24, Batch: 180, Loss: 0.0725\n",
            "root        : INFO     Epoch: 24, Batch: 200, Loss: 0.0802\n",
            "root        : INFO     Epoch: 24, Batch: 220, Loss: 0.0684\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     109/177 = 0.615819\n",
            "root        : INFO     Beginning Epoch 25\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 25, Batch: 20, Loss: 0.0684\n",
            "root        : INFO     Epoch: 25, Batch: 40, Loss: 0.0756\n",
            "root        : INFO     Epoch: 25, Batch: 60, Loss: 0.0933\n",
            "root        : INFO     Epoch: 25, Batch: 80, Loss: 0.0985\n",
            "root        : INFO     Epoch: 25, Batch: 100, Loss: 0.0804\n",
            "root        : INFO     Epoch: 25, Batch: 120, Loss: 0.0946\n",
            "root        : INFO     Epoch: 25, Batch: 140, Loss: 0.0805\n",
            "root        : INFO     Epoch: 25, Batch: 160, Loss: 0.1011\n",
            "root        : INFO     Epoch: 25, Batch: 180, Loss: 0.0781\n",
            "root        : INFO     Epoch: 25, Batch: 200, Loss: 0.0887\n",
            "root        : INFO     Epoch: 25, Batch: 220, Loss: 0.0876\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     115/177 = 0.649718\n",
            "root        : INFO     Beginning Epoch 26\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 26, Batch: 20, Loss: 0.0873\n",
            "root        : INFO     Epoch: 26, Batch: 40, Loss: 0.0825\n",
            "root        : INFO     Epoch: 26, Batch: 60, Loss: 0.1013\n",
            "root        : INFO     Epoch: 26, Batch: 80, Loss: 0.0858\n",
            "root        : INFO     Epoch: 26, Batch: 100, Loss: 0.0817\n",
            "root        : INFO     Epoch: 26, Batch: 120, Loss: 0.0865\n",
            "root        : INFO     Epoch: 26, Batch: 140, Loss: 0.0823\n",
            "root        : INFO     Epoch: 26, Batch: 160, Loss: 0.0682\n",
            "root        : INFO     Epoch: 26, Batch: 180, Loss: 0.0808\n",
            "root        : INFO     Epoch: 26, Batch: 200, Loss: 0.0838\n",
            "root        : INFO     Epoch: 26, Batch: 220, Loss: 0.0537\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     131/177 = 0.740113\n",
            "root        : INFO     Beginning Epoch 27\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 27, Batch: 20, Loss: 0.0825\n",
            "root        : INFO     Epoch: 27, Batch: 40, Loss: 0.1015\n",
            "root        : INFO     Epoch: 27, Batch: 60, Loss: 0.0919\n",
            "root        : INFO     Epoch: 27, Batch: 80, Loss: 0.0827\n",
            "root        : INFO     Epoch: 27, Batch: 100, Loss: 0.0815\n",
            "root        : INFO     Epoch: 27, Batch: 120, Loss: 0.0935\n",
            "root        : INFO     Epoch: 27, Batch: 140, Loss: 0.0707\n",
            "root        : INFO     Epoch: 27, Batch: 160, Loss: 0.1013\n",
            "root        : INFO     Epoch: 27, Batch: 180, Loss: 0.0737\n",
            "root        : INFO     Epoch: 27, Batch: 200, Loss: 0.0992\n",
            "root        : INFO     Epoch: 27, Batch: 220, Loss: 0.0798\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 28\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 28, Batch: 20, Loss: 0.0907\n",
            "root        : INFO     Epoch: 28, Batch: 40, Loss: 0.0685\n",
            "root        : INFO     Epoch: 28, Batch: 60, Loss: 0.0919\n",
            "root        : INFO     Epoch: 28, Batch: 80, Loss: 0.0727\n",
            "root        : INFO     Epoch: 28, Batch: 100, Loss: 0.0706\n",
            "root        : INFO     Epoch: 28, Batch: 120, Loss: 0.0893\n",
            "root        : INFO     Epoch: 28, Batch: 140, Loss: 0.0677\n",
            "root        : INFO     Epoch: 28, Batch: 160, Loss: 0.0776\n",
            "root        : INFO     Epoch: 28, Batch: 180, Loss: 0.0948\n",
            "root        : INFO     Epoch: 28, Batch: 200, Loss: 0.1073\n",
            "root        : INFO     Epoch: 28, Batch: 220, Loss: 0.0974\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     128/177 = 0.723164\n",
            "root        : INFO     Beginning Epoch 29\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 29, Batch: 20, Loss: 0.0979\n",
            "root        : INFO     Epoch: 29, Batch: 40, Loss: 0.1005\n",
            "root        : INFO     Epoch: 29, Batch: 60, Loss: 0.0715\n",
            "root        : INFO     Epoch: 29, Batch: 80, Loss: 0.0791\n",
            "root        : INFO     Epoch: 29, Batch: 100, Loss: 0.0743\n",
            "root        : INFO     Epoch: 29, Batch: 120, Loss: 0.0729\n",
            "root        : INFO     Epoch: 29, Batch: 140, Loss: 0.0883\n",
            "root        : INFO     Epoch: 29, Batch: 160, Loss: 0.0630\n",
            "root        : INFO     Epoch: 29, Batch: 180, Loss: 0.1018\n",
            "root        : INFO     Epoch: 29, Batch: 200, Loss: 0.0951\n",
            "root        : INFO     Epoch: 29, Batch: 220, Loss: 0.0835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6RmO1NfbbeV"
      },
      "source": [
        "**Poor Performance - Learning rate is assigned to 0.005 (when Batch size =8), which is larger than the optimal value.**    \n",
        "saved at /content/drive/MyDrive/GR_ConvNet_Code/logs/210403_0307_training_cornell  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIGAjO8NwUy",
        "outputId": "40c0b7fa-484a-4df8-ab2c-b48491278f0e"
      },
      "source": [
        "!python train_network3.py --dataset cornell --dataset-path /content/drive/MyDrive/cornell_grasp_dataset --description training_cornell --logdir /content/drive/MyDrive/GR_ConvNet_Code/logs  --channel-size 32 --num-workers 8 --batch-size 8 --batches-per-epoch 896 --split 0.8  --ds-shuffle --ds-rotate 0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.80, ds-rotate = 0.20, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 8, bacthes per epoch = 896, optimizer = adam\n",
            "root        : INFO     Loading Cornell Dataset...\n",
            "root        : INFO     Dataset size is 885\n",
            "root        : INFO     Training size: 708\n",
            "root        : INFO     Validation size: 177\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.2020\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.1256\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.1290\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.1012\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0778\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.1014\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.1749\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.1293\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.1094\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0886\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0852\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.0779\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.1332\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.1601\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.0787\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.1220\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0687\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     46/177 = 0.259887\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0798\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.1359\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.1430\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.1116\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0957\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.1754\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.1507\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0986\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.1370\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.1061\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.1129\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0851\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0926\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0940\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.1065\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.1393\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.1097\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     106/177 = 0.598870\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0649\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.1293\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.1426\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.1001\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.1051\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0753\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0861\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0586\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0664\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0857\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.1081\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.1122\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.1005\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0961\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.0830\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.1220\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.1022\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     109/177 = 0.615819\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0606\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0695\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0740\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0923\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0442\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0963\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0869\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.1189\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0855\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0444\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.1813\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.1121\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0830\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.1289\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.1132\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0490\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0985\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     114/177 = 0.644068\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.1079\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0914\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.1102\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0538\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0660\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.1027\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0678\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0905\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.0996\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.1245\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0914\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0800\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.1093\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0631\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0685\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.1040\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0495\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     120/177 = 0.677966\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.1141\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0657\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.1308\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0748\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0574\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0912\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0696\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.1393\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0861\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0700\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.1118\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0841\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.1560\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0717\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0936\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0548\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0905\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.1140\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.1152\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.1258\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.1374\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0531\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.1205\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.1118\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0544\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.1120\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.1089\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0699\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0566\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0629\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0851\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.1328\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0843\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0823\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     130/177 = 0.734463\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0646\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.1051\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0689\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.1186\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0910\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0635\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.1132\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.1629\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.1195\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0934\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.1071\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0531\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0689\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0645\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0724\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.1394\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0694\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     141/177 = 0.796610\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0708\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0664\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0801\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0687\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.1091\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0629\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.1227\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0940\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0791\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.1063\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.1019\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0806\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0844\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0960\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0666\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0729\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0704\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     135/177 = 0.762712\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0590\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.1310\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0687\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0676\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0765\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0764\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.1146\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0510\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0615\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.1005\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.1278\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0505\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0612\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.1002\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.1400\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0556\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0781\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     127/177 = 0.717514\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.1356\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.1140\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0529\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.1299\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0861\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0774\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0927\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.1082\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.0988\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0475\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0936\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0768\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.1206\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0524\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0750\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.1351\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0721\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     100/177 = 0.564972\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0876\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.1356\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.1286\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.1620\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0812\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0821\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0832\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0653\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0723\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0873\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0891\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.1101\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0841\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0936\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0769\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0920\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0680\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     151/177 = 0.853107\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0786\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.1163\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0698\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.1448\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0619\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0957\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.1005\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0956\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.1162\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0955\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.1206\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0694\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0816\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0618\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0451\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0883\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0821\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     144/177 = 0.813559\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0780\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0853\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0449\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0781\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0744\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.1186\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.1144\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0747\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.0946\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.1108\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.1137\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0705\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0649\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0833\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.0782\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0819\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.1266\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     140/177 = 0.790960\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0751\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0719\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0861\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.1484\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0562\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0695\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0948\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0798\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0323\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0661\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.1149\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0727\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0671\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0547\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0709\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0647\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0702\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     138/177 = 0.779661\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0573\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.1124\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.1029\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.1046\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0671\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hinIYK3MND5u"
      },
      "source": [
        "!unzip -n /content/drive/MyDrive/cornell-grasp.zip -d /content/cornell_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDN8mutbANEN"
      },
      "source": [
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_0.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_1.zip -d /content/jacquard_dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGC5kaqwhItK"
      },
      "source": [
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_2.zip -d /content/jacquard_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edqxxh8nezBd"
      },
      "source": [
        "**Training Jacquard**  \n",
        "**use train_network3.py to train Jacquard dataset, RGB-D,batchsize=8, Adam, learning rate =0.001, channel size 32, small dataset=jacquard 0,1, shuffling only at every epoch. augment = 0 (random_rotate=False, random_zoom=False)**  \n",
        "\n",
        "**Achieved**  \n",
        "saved at /content/drive/MyDrive/jacquard_logs/210409_1221_training_jacquard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JhfYjs5gRuB",
        "outputId": "8d78e7b9-aef9-4b92-e1b7-534390311dc1"
      },
      "source": [
        "!python train_network3.py --dataset jacquard --dataset-path /content/jacquard_dataset --description training_jacquard --logdir /content/drive/MyDrive/jacquard_logs/ --num-workers 8 --batch-size 8 --batches-per-epoch 1052 --epochs 50 --lr=0.001 --ds-shuffle --augment 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla V100-SXM2-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.90, ds-rotate = 0.00, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 50, batch size = 8, bacthes per epoch = 1052, optimizer = adam, learning rate = 0.001000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/jacquard_logs/210409_1221_training_jacquard\n",
            "root        : INFO     Loading Jacquard Dataset...\n",
            "root        : INFO     Dataset size is 9352\n",
            "root        : INFO     Training size: 8416\n",
            "root        : INFO     Validation size: 936\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0800\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0672\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.0558\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0352\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0387\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0421\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0661\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0386\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0350\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0323\n",
            "root        : INFO     Epoch: 0, Batch: 550, Loss: 0.0383\n",
            "root        : INFO     Epoch: 0, Batch: 600, Loss: 0.0386\n",
            "root        : INFO     Epoch: 0, Batch: 650, Loss: 0.0321\n",
            "root        : INFO     Epoch: 0, Batch: 700, Loss: 0.0307\n",
            "root        : INFO     Epoch: 0, Batch: 750, Loss: 0.0292\n",
            "root        : INFO     Epoch: 0, Batch: 800, Loss: 0.0401\n",
            "root        : INFO     Epoch: 0, Batch: 850, Loss: 0.0420\n",
            "root        : INFO     Epoch: 0, Batch: 900, Loss: 0.0275\n",
            "root        : INFO     Epoch: 0, Batch: 950, Loss: 0.0172\n",
            "root        : INFO     Epoch: 0, Batch: 1000, Loss: 0.0283\n",
            "root        : INFO     Epoch: 0, Batch: 1050, Loss: 0.0181\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     634/936 = 0.677350\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 50, Loss: 0.0188\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0367\n",
            "root        : INFO     Epoch: 1, Batch: 150, Loss: 0.0300\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0471\n",
            "root        : INFO     Epoch: 1, Batch: 250, Loss: 0.0355\n",
            "root        : INFO     Epoch: 1, Batch: 300, Loss: 0.0243\n",
            "root        : INFO     Epoch: 1, Batch: 350, Loss: 0.0368\n",
            "root        : INFO     Epoch: 1, Batch: 400, Loss: 0.0406\n",
            "root        : INFO     Epoch: 1, Batch: 450, Loss: 0.0320\n",
            "root        : INFO     Epoch: 1, Batch: 500, Loss: 0.0254\n",
            "root        : INFO     Epoch: 1, Batch: 550, Loss: 0.0359\n",
            "root        : INFO     Epoch: 1, Batch: 600, Loss: 0.0256\n",
            "root        : INFO     Epoch: 1, Batch: 650, Loss: 0.0185\n",
            "root        : INFO     Epoch: 1, Batch: 700, Loss: 0.0322\n",
            "root        : INFO     Epoch: 1, Batch: 750, Loss: 0.0244\n",
            "root        : INFO     Epoch: 1, Batch: 800, Loss: 0.0383\n",
            "root        : INFO     Epoch: 1, Batch: 850, Loss: 0.0182\n",
            "root        : INFO     Epoch: 1, Batch: 900, Loss: 0.0258\n",
            "root        : INFO     Epoch: 1, Batch: 950, Loss: 0.0319\n",
            "root        : INFO     Epoch: 1, Batch: 1000, Loss: 0.0222\n",
            "root        : INFO     Epoch: 1, Batch: 1050, Loss: 0.0263\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     638/936 = 0.681624\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 50, Loss: 0.0429\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0262\n",
            "root        : INFO     Epoch: 2, Batch: 150, Loss: 0.0249\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0317\n",
            "root        : INFO     Epoch: 2, Batch: 250, Loss: 0.0170\n",
            "root        : INFO     Epoch: 2, Batch: 300, Loss: 0.0262\n",
            "root        : INFO     Epoch: 2, Batch: 350, Loss: 0.0258\n",
            "root        : INFO     Epoch: 2, Batch: 400, Loss: 0.0240\n",
            "root        : INFO     Epoch: 2, Batch: 450, Loss: 0.0234\n",
            "root        : INFO     Epoch: 2, Batch: 500, Loss: 0.0286\n",
            "root        : INFO     Epoch: 2, Batch: 550, Loss: 0.0340\n",
            "root        : INFO     Epoch: 2, Batch: 600, Loss: 0.0147\n",
            "root        : INFO     Epoch: 2, Batch: 650, Loss: 0.0210\n",
            "root        : INFO     Epoch: 2, Batch: 700, Loss: 0.0332\n",
            "root        : INFO     Epoch: 2, Batch: 750, Loss: 0.0368\n",
            "root        : INFO     Epoch: 2, Batch: 800, Loss: 0.0244\n",
            "root        : INFO     Epoch: 2, Batch: 850, Loss: 0.0174\n",
            "root        : INFO     Epoch: 2, Batch: 900, Loss: 0.0116\n",
            "root        : INFO     Epoch: 2, Batch: 950, Loss: 0.0338\n",
            "root        : INFO     Epoch: 2, Batch: 1000, Loss: 0.0245\n",
            "root        : INFO     Epoch: 2, Batch: 1050, Loss: 0.0201\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     623/936 = 0.665598\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 50, Loss: 0.0163\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0282\n",
            "root        : INFO     Epoch: 3, Batch: 150, Loss: 0.0236\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0201\n",
            "root        : INFO     Epoch: 3, Batch: 250, Loss: 0.0303\n",
            "root        : INFO     Epoch: 3, Batch: 300, Loss: 0.0238\n",
            "root        : INFO     Epoch: 3, Batch: 350, Loss: 0.0360\n",
            "root        : INFO     Epoch: 3, Batch: 400, Loss: 0.0151\n",
            "root        : INFO     Epoch: 3, Batch: 450, Loss: 0.0334\n",
            "root        : INFO     Epoch: 3, Batch: 500, Loss: 0.0297\n",
            "root        : INFO     Epoch: 3, Batch: 550, Loss: 0.0213\n",
            "root        : INFO     Epoch: 3, Batch: 600, Loss: 0.0182\n",
            "root        : INFO     Epoch: 3, Batch: 650, Loss: 0.0120\n",
            "root        : INFO     Epoch: 3, Batch: 700, Loss: 0.0312\n",
            "root        : INFO     Epoch: 3, Batch: 750, Loss: 0.0320\n",
            "root        : INFO     Epoch: 3, Batch: 800, Loss: 0.0241\n",
            "root        : INFO     Epoch: 3, Batch: 850, Loss: 0.0305\n",
            "root        : INFO     Epoch: 3, Batch: 900, Loss: 0.0129\n",
            "root        : INFO     Epoch: 3, Batch: 950, Loss: 0.0156\n",
            "root        : INFO     Epoch: 3, Batch: 1000, Loss: 0.0215\n",
            "root        : INFO     Epoch: 3, Batch: 1050, Loss: 0.0218\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     574/936 = 0.613248\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 50, Loss: 0.0226\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0275\n",
            "root        : INFO     Epoch: 4, Batch: 150, Loss: 0.0210\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0107\n",
            "root        : INFO     Epoch: 4, Batch: 250, Loss: 0.0122\n",
            "root        : INFO     Epoch: 4, Batch: 300, Loss: 0.0175\n",
            "root        : INFO     Epoch: 4, Batch: 350, Loss: 0.0168\n",
            "root        : INFO     Epoch: 4, Batch: 400, Loss: 0.0354\n",
            "root        : INFO     Epoch: 4, Batch: 450, Loss: 0.0288\n",
            "root        : INFO     Epoch: 4, Batch: 500, Loss: 0.0211\n",
            "root        : INFO     Epoch: 4, Batch: 550, Loss: 0.0180\n",
            "root        : INFO     Epoch: 4, Batch: 600, Loss: 0.0177\n",
            "root        : INFO     Epoch: 4, Batch: 650, Loss: 0.0201\n",
            "root        : INFO     Epoch: 4, Batch: 700, Loss: 0.0164\n",
            "root        : INFO     Epoch: 4, Batch: 750, Loss: 0.0109\n",
            "root        : INFO     Epoch: 4, Batch: 800, Loss: 0.0261\n",
            "root        : INFO     Epoch: 4, Batch: 850, Loss: 0.0264\n",
            "root        : INFO     Epoch: 4, Batch: 900, Loss: 0.0201\n",
            "root        : INFO     Epoch: 4, Batch: 950, Loss: 0.0408\n",
            "root        : INFO     Epoch: 4, Batch: 1000, Loss: 0.0177\n",
            "root        : INFO     Epoch: 4, Batch: 1050, Loss: 0.0182\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     637/936 = 0.680556\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 50, Loss: 0.0221\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0217\n",
            "root        : INFO     Epoch: 5, Batch: 150, Loss: 0.0243\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0140\n",
            "root        : INFO     Epoch: 5, Batch: 250, Loss: 0.0216\n",
            "root        : INFO     Epoch: 5, Batch: 300, Loss: 0.0134\n",
            "root        : INFO     Epoch: 5, Batch: 350, Loss: 0.0316\n",
            "root        : INFO     Epoch: 5, Batch: 400, Loss: 0.0403\n",
            "root        : INFO     Epoch: 5, Batch: 450, Loss: 0.0235\n",
            "root        : INFO     Epoch: 5, Batch: 500, Loss: 0.0189\n",
            "root        : INFO     Epoch: 5, Batch: 550, Loss: 0.0254\n",
            "root        : INFO     Epoch: 5, Batch: 600, Loss: 0.0112\n",
            "root        : INFO     Epoch: 5, Batch: 650, Loss: 0.0177\n",
            "root        : INFO     Epoch: 5, Batch: 700, Loss: 0.0155\n",
            "root        : INFO     Epoch: 5, Batch: 750, Loss: 0.0199\n",
            "root        : INFO     Epoch: 5, Batch: 800, Loss: 0.0322\n",
            "root        : INFO     Epoch: 5, Batch: 850, Loss: 0.0126\n",
            "root        : INFO     Epoch: 5, Batch: 900, Loss: 0.0159\n",
            "root        : INFO     Epoch: 5, Batch: 950, Loss: 0.0162\n",
            "root        : INFO     Epoch: 5, Batch: 1000, Loss: 0.0292\n",
            "root        : INFO     Epoch: 5, Batch: 1050, Loss: 0.0325\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     611/936 = 0.652778\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 50, Loss: 0.0155\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0210\n",
            "root        : INFO     Epoch: 6, Batch: 150, Loss: 0.0309\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0202\n",
            "root        : INFO     Epoch: 6, Batch: 250, Loss: 0.0211\n",
            "root        : INFO     Epoch: 6, Batch: 300, Loss: 0.0117\n",
            "root        : INFO     Epoch: 6, Batch: 350, Loss: 0.0230\n",
            "root        : INFO     Epoch: 6, Batch: 400, Loss: 0.0128\n",
            "root        : INFO     Epoch: 6, Batch: 450, Loss: 0.0135\n",
            "root        : INFO     Epoch: 6, Batch: 500, Loss: 0.0158\n",
            "root        : INFO     Epoch: 6, Batch: 550, Loss: 0.0134\n",
            "root        : INFO     Epoch: 6, Batch: 600, Loss: 0.0197\n",
            "root        : INFO     Epoch: 6, Batch: 650, Loss: 0.0124\n",
            "root        : INFO     Epoch: 6, Batch: 700, Loss: 0.0227\n",
            "root        : INFO     Epoch: 6, Batch: 750, Loss: 0.0117\n",
            "root        : INFO     Epoch: 6, Batch: 800, Loss: 0.0105\n",
            "root        : INFO     Epoch: 6, Batch: 850, Loss: 0.0207\n",
            "root        : INFO     Epoch: 6, Batch: 900, Loss: 0.0204\n",
            "root        : INFO     Epoch: 6, Batch: 950, Loss: 0.0239\n",
            "root        : INFO     Epoch: 6, Batch: 1000, Loss: 0.0185\n",
            "root        : INFO     Epoch: 6, Batch: 1050, Loss: 0.0175\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     630/936 = 0.673077\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 7, Batch: 50, Loss: 0.0193\n",
            "root        : INFO     Epoch: 7, Batch: 100, Loss: 0.0128\n",
            "root        : INFO     Epoch: 7, Batch: 150, Loss: 0.0205\n",
            "root        : INFO     Epoch: 7, Batch: 200, Loss: 0.0188\n",
            "root        : INFO     Epoch: 7, Batch: 250, Loss: 0.0267\n",
            "root        : INFO     Epoch: 7, Batch: 300, Loss: 0.0143\n",
            "root        : INFO     Epoch: 7, Batch: 350, Loss: 0.0254\n",
            "root        : INFO     Epoch: 7, Batch: 400, Loss: 0.0226\n",
            "root        : INFO     Epoch: 7, Batch: 450, Loss: 0.0175\n",
            "root        : INFO     Epoch: 7, Batch: 500, Loss: 0.0232\n",
            "root        : INFO     Epoch: 7, Batch: 550, Loss: 0.0335\n",
            "root        : INFO     Epoch: 7, Batch: 600, Loss: 0.0327\n",
            "root        : INFO     Epoch: 7, Batch: 650, Loss: 0.0309\n",
            "root        : INFO     Epoch: 7, Batch: 700, Loss: 0.0177\n",
            "root        : INFO     Epoch: 7, Batch: 750, Loss: 0.0149\n",
            "root        : INFO     Epoch: 7, Batch: 800, Loss: 0.0271\n",
            "root        : INFO     Epoch: 7, Batch: 850, Loss: 0.0202\n",
            "root        : INFO     Epoch: 7, Batch: 900, Loss: 0.0416\n",
            "root        : INFO     Epoch: 7, Batch: 950, Loss: 0.0109\n",
            "root        : INFO     Epoch: 7, Batch: 1000, Loss: 0.0211\n",
            "root        : INFO     Epoch: 7, Batch: 1050, Loss: 0.0292\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     614/936 = 0.655983\n",
            "root        : INFO     Beginning Epoch 08\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 8, Batch: 50, Loss: 0.0120\n",
            "root        : INFO     Epoch: 8, Batch: 100, Loss: 0.0096\n",
            "root        : INFO     Epoch: 8, Batch: 150, Loss: 0.0226\n",
            "root        : INFO     Epoch: 8, Batch: 200, Loss: 0.0154\n",
            "root        : INFO     Epoch: 8, Batch: 250, Loss: 0.0217\n",
            "root        : INFO     Epoch: 8, Batch: 300, Loss: 0.0249\n",
            "root        : INFO     Epoch: 8, Batch: 350, Loss: 0.0175\n",
            "root        : INFO     Epoch: 8, Batch: 400, Loss: 0.0131\n",
            "root        : INFO     Epoch: 8, Batch: 450, Loss: 0.0174\n",
            "root        : INFO     Epoch: 8, Batch: 500, Loss: 0.0222\n",
            "root        : INFO     Epoch: 8, Batch: 550, Loss: 0.0280\n",
            "root        : INFO     Epoch: 8, Batch: 600, Loss: 0.0235\n",
            "root        : INFO     Epoch: 8, Batch: 650, Loss: 0.0129\n",
            "root        : INFO     Epoch: 8, Batch: 700, Loss: 0.0276\n",
            "root        : INFO     Epoch: 8, Batch: 750, Loss: 0.0239\n",
            "root        : INFO     Epoch: 8, Batch: 800, Loss: 0.0123\n",
            "root        : INFO     Epoch: 8, Batch: 850, Loss: 0.0197\n",
            "root        : INFO     Epoch: 8, Batch: 900, Loss: 0.0286\n",
            "root        : INFO     Epoch: 8, Batch: 950, Loss: 0.0225\n",
            "root        : INFO     Epoch: 8, Batch: 1000, Loss: 0.0254\n",
            "root        : INFO     Epoch: 8, Batch: 1050, Loss: 0.0249\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     609/936 = 0.650641\n",
            "root        : INFO     Beginning Epoch 09\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 9, Batch: 50, Loss: 0.0167\n",
            "root        : INFO     Epoch: 9, Batch: 100, Loss: 0.0343\n",
            "root        : INFO     Epoch: 9, Batch: 150, Loss: 0.0149\n",
            "root        : INFO     Epoch: 9, Batch: 200, Loss: 0.0100\n",
            "root        : INFO     Epoch: 9, Batch: 250, Loss: 0.0160\n",
            "root        : INFO     Epoch: 9, Batch: 300, Loss: 0.0135\n",
            "root        : INFO     Epoch: 9, Batch: 350, Loss: 0.0171\n",
            "root        : INFO     Epoch: 9, Batch: 400, Loss: 0.0256\n",
            "root        : INFO     Epoch: 9, Batch: 450, Loss: 0.0137\n",
            "root        : INFO     Epoch: 9, Batch: 500, Loss: 0.0289\n",
            "root        : INFO     Epoch: 9, Batch: 550, Loss: 0.0113\n",
            "root        : INFO     Epoch: 9, Batch: 600, Loss: 0.0200\n",
            "root        : INFO     Epoch: 9, Batch: 650, Loss: 0.0207\n",
            "root        : INFO     Epoch: 9, Batch: 700, Loss: 0.0362\n",
            "root        : INFO     Epoch: 9, Batch: 750, Loss: 0.0168\n",
            "root        : INFO     Epoch: 9, Batch: 800, Loss: 0.0193\n",
            "root        : INFO     Epoch: 9, Batch: 850, Loss: 0.0188\n",
            "root        : INFO     Epoch: 9, Batch: 900, Loss: 0.0174\n",
            "root        : INFO     Epoch: 9, Batch: 950, Loss: 0.0187\n",
            "root        : INFO     Epoch: 9, Batch: 1000, Loss: 0.0173\n",
            "root        : INFO     Epoch: 9, Batch: 1050, Loss: 0.0210\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     532/936 = 0.568376\n",
            "root        : INFO     Beginning Epoch 10\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 10, Batch: 50, Loss: 0.0210\n",
            "root        : INFO     Epoch: 10, Batch: 100, Loss: 0.0298\n",
            "root        : INFO     Epoch: 10, Batch: 150, Loss: 0.0085\n",
            "root        : INFO     Epoch: 10, Batch: 200, Loss: 0.0170\n",
            "root        : INFO     Epoch: 10, Batch: 250, Loss: 0.0258\n",
            "root        : INFO     Epoch: 10, Batch: 300, Loss: 0.0201\n",
            "root        : INFO     Epoch: 10, Batch: 350, Loss: 0.0133\n",
            "root        : INFO     Epoch: 10, Batch: 400, Loss: 0.0217\n",
            "root        : INFO     Epoch: 10, Batch: 450, Loss: 0.0239\n",
            "root        : INFO     Epoch: 10, Batch: 500, Loss: 0.0186\n",
            "root        : INFO     Epoch: 10, Batch: 550, Loss: 0.0121\n",
            "root        : INFO     Epoch: 10, Batch: 600, Loss: 0.0301\n",
            "root        : INFO     Epoch: 10, Batch: 650, Loss: 0.0134\n",
            "root        : INFO     Epoch: 10, Batch: 700, Loss: 0.0171\n",
            "root        : INFO     Epoch: 10, Batch: 750, Loss: 0.0204\n",
            "root        : INFO     Epoch: 10, Batch: 800, Loss: 0.0139\n",
            "root        : INFO     Epoch: 10, Batch: 850, Loss: 0.0159\n",
            "root        : INFO     Epoch: 10, Batch: 900, Loss: 0.0269\n",
            "root        : INFO     Epoch: 10, Batch: 950, Loss: 0.0143\n",
            "root        : INFO     Epoch: 10, Batch: 1000, Loss: 0.0294\n",
            "root        : INFO     Epoch: 10, Batch: 1050, Loss: 0.0335\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     463/936 = 0.494658\n",
            "root        : INFO     Beginning Epoch 11\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 11, Batch: 50, Loss: 0.0148\n",
            "root        : INFO     Epoch: 11, Batch: 100, Loss: 0.0231\n",
            "root        : INFO     Epoch: 11, Batch: 150, Loss: 0.0229\n",
            "root        : INFO     Epoch: 11, Batch: 200, Loss: 0.0184\n",
            "root        : INFO     Epoch: 11, Batch: 250, Loss: 0.0300\n",
            "root        : INFO     Epoch: 11, Batch: 300, Loss: 0.0193\n",
            "root        : INFO     Epoch: 11, Batch: 350, Loss: 0.0278\n",
            "root        : INFO     Epoch: 11, Batch: 400, Loss: 0.0080\n",
            "root        : INFO     Epoch: 11, Batch: 450, Loss: 0.0172\n",
            "root        : INFO     Epoch: 11, Batch: 500, Loss: 0.0194\n",
            "root        : INFO     Epoch: 11, Batch: 550, Loss: 0.0128\n",
            "root        : INFO     Epoch: 11, Batch: 600, Loss: 0.0151\n",
            "root        : INFO     Epoch: 11, Batch: 650, Loss: 0.0159\n",
            "root        : INFO     Epoch: 11, Batch: 700, Loss: 0.0131\n",
            "root        : INFO     Epoch: 11, Batch: 750, Loss: 0.0227\n",
            "root        : INFO     Epoch: 11, Batch: 800, Loss: 0.0139\n",
            "root        : INFO     Epoch: 11, Batch: 850, Loss: 0.0158\n",
            "root        : INFO     Epoch: 11, Batch: 900, Loss: 0.0154\n",
            "root        : INFO     Epoch: 11, Batch: 950, Loss: 0.0196\n",
            "root        : INFO     Epoch: 11, Batch: 1000, Loss: 0.0162\n",
            "root        : INFO     Epoch: 11, Batch: 1050, Loss: 0.0171\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     631/936 = 0.674145\n",
            "root        : INFO     Beginning Epoch 12\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 12, Batch: 50, Loss: 0.0123\n",
            "root        : INFO     Epoch: 12, Batch: 100, Loss: 0.0151\n",
            "root        : INFO     Epoch: 12, Batch: 150, Loss: 0.0178\n",
            "root        : INFO     Epoch: 12, Batch: 200, Loss: 0.0336\n",
            "root        : INFO     Epoch: 12, Batch: 250, Loss: 0.0215\n",
            "root        : INFO     Epoch: 12, Batch: 300, Loss: 0.0201\n",
            "root        : INFO     Epoch: 12, Batch: 350, Loss: 0.0190\n",
            "root        : INFO     Epoch: 12, Batch: 400, Loss: 0.0261\n",
            "root        : INFO     Epoch: 12, Batch: 450, Loss: 0.0219\n",
            "root        : INFO     Epoch: 12, Batch: 500, Loss: 0.0199\n",
            "root        : INFO     Epoch: 12, Batch: 550, Loss: 0.0176\n",
            "root        : INFO     Epoch: 12, Batch: 600, Loss: 0.0145\n",
            "root        : INFO     Epoch: 12, Batch: 650, Loss: 0.0129\n",
            "root        : INFO     Epoch: 12, Batch: 700, Loss: 0.0154\n",
            "root        : INFO     Epoch: 12, Batch: 750, Loss: 0.0241\n",
            "root        : INFO     Epoch: 12, Batch: 800, Loss: 0.0164\n",
            "root        : INFO     Epoch: 12, Batch: 850, Loss: 0.0113\n",
            "root        : INFO     Epoch: 12, Batch: 900, Loss: 0.0293\n",
            "root        : INFO     Epoch: 12, Batch: 950, Loss: 0.0144\n",
            "root        : INFO     Epoch: 12, Batch: 1000, Loss: 0.0271\n",
            "root        : INFO     Epoch: 12, Batch: 1050, Loss: 0.0123\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     602/936 = 0.643162\n",
            "root        : INFO     Beginning Epoch 13\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 13, Batch: 50, Loss: 0.0259\n",
            "root        : INFO     Epoch: 13, Batch: 100, Loss: 0.0193\n",
            "root        : INFO     Epoch: 13, Batch: 150, Loss: 0.0296\n",
            "root        : INFO     Epoch: 13, Batch: 200, Loss: 0.0198\n",
            "root        : INFO     Epoch: 13, Batch: 250, Loss: 0.0172\n",
            "root        : INFO     Epoch: 13, Batch: 300, Loss: 0.0159\n",
            "root        : INFO     Epoch: 13, Batch: 350, Loss: 0.0100\n",
            "root        : INFO     Epoch: 13, Batch: 400, Loss: 0.0267\n",
            "root        : INFO     Epoch: 13, Batch: 450, Loss: 0.0233\n",
            "root        : INFO     Epoch: 13, Batch: 500, Loss: 0.0157\n",
            "root        : INFO     Epoch: 13, Batch: 550, Loss: 0.0245\n",
            "root        : INFO     Epoch: 13, Batch: 600, Loss: 0.0169\n",
            "root        : INFO     Epoch: 13, Batch: 650, Loss: 0.0153\n",
            "root        : INFO     Epoch: 13, Batch: 700, Loss: 0.0201\n",
            "root        : INFO     Epoch: 13, Batch: 750, Loss: 0.0236\n",
            "root        : INFO     Epoch: 13, Batch: 800, Loss: 0.0097\n",
            "root        : INFO     Epoch: 13, Batch: 850, Loss: 0.0108\n",
            "root        : INFO     Epoch: 13, Batch: 900, Loss: 0.0092\n",
            "root        : INFO     Epoch: 13, Batch: 950, Loss: 0.0202\n",
            "root        : INFO     Epoch: 13, Batch: 1000, Loss: 0.0213\n",
            "root        : INFO     Epoch: 13, Batch: 1050, Loss: 0.0181\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     570/936 = 0.608974\n",
            "root        : INFO     Beginning Epoch 14\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 14, Batch: 50, Loss: 0.0071\n",
            "root        : INFO     Epoch: 14, Batch: 100, Loss: 0.0124\n",
            "root        : INFO     Epoch: 14, Batch: 150, Loss: 0.0147\n",
            "root        : INFO     Epoch: 14, Batch: 200, Loss: 0.0226\n",
            "root        : INFO     Epoch: 14, Batch: 250, Loss: 0.0112\n",
            "root        : INFO     Epoch: 14, Batch: 300, Loss: 0.0146\n",
            "root        : INFO     Epoch: 14, Batch: 350, Loss: 0.0286\n",
            "root        : INFO     Epoch: 14, Batch: 400, Loss: 0.0249\n",
            "root        : INFO     Epoch: 14, Batch: 450, Loss: 0.0158\n",
            "root        : INFO     Epoch: 14, Batch: 500, Loss: 0.0140\n",
            "root        : INFO     Epoch: 14, Batch: 550, Loss: 0.0086\n",
            "root        : INFO     Epoch: 14, Batch: 600, Loss: 0.0128\n",
            "root        : INFO     Epoch: 14, Batch: 650, Loss: 0.0294\n",
            "root        : INFO     Epoch: 14, Batch: 700, Loss: 0.0223\n",
            "root        : INFO     Epoch: 14, Batch: 750, Loss: 0.0140\n",
            "root        : INFO     Epoch: 14, Batch: 800, Loss: 0.0256\n",
            "root        : INFO     Epoch: 14, Batch: 850, Loss: 0.0139\n",
            "root        : INFO     Epoch: 14, Batch: 900, Loss: 0.0221\n",
            "root        : INFO     Epoch: 14, Batch: 950, Loss: 0.0229\n",
            "root        : INFO     Epoch: 14, Batch: 1000, Loss: 0.0208\n",
            "root        : INFO     Epoch: 14, Batch: 1050, Loss: 0.0181\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     593/936 = 0.633547\n",
            "root        : INFO     Beginning Epoch 15\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 15, Batch: 50, Loss: 0.0141\n",
            "root        : INFO     Epoch: 15, Batch: 100, Loss: 0.0136\n",
            "root        : INFO     Epoch: 15, Batch: 150, Loss: 0.0179\n",
            "root        : INFO     Epoch: 15, Batch: 200, Loss: 0.0123\n",
            "root        : INFO     Epoch: 15, Batch: 250, Loss: 0.0304\n",
            "root        : INFO     Epoch: 15, Batch: 300, Loss: 0.0185\n",
            "root        : INFO     Epoch: 15, Batch: 350, Loss: 0.0233\n",
            "root        : INFO     Epoch: 15, Batch: 400, Loss: 0.0150\n",
            "root        : INFO     Epoch: 15, Batch: 450, Loss: 0.0123\n",
            "root        : INFO     Epoch: 15, Batch: 500, Loss: 0.0148\n",
            "root        : INFO     Epoch: 15, Batch: 550, Loss: 0.0126\n",
            "root        : INFO     Epoch: 15, Batch: 600, Loss: 0.0158\n",
            "root        : INFO     Epoch: 15, Batch: 650, Loss: 0.0296\n",
            "root        : INFO     Epoch: 15, Batch: 700, Loss: 0.0214\n",
            "root        : INFO     Epoch: 15, Batch: 750, Loss: 0.0101\n",
            "root        : INFO     Epoch: 15, Batch: 800, Loss: 0.0131\n",
            "root        : INFO     Epoch: 15, Batch: 850, Loss: 0.0197\n",
            "root        : INFO     Epoch: 15, Batch: 900, Loss: 0.0101\n",
            "root        : INFO     Epoch: 15, Batch: 950, Loss: 0.0211\n",
            "root        : INFO     Epoch: 15, Batch: 1000, Loss: 0.0237\n",
            "root        : INFO     Epoch: 15, Batch: 1050, Loss: 0.0174\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     438/936 = 0.467949\n",
            "root        : INFO     Beginning Epoch 16\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 16, Batch: 50, Loss: 0.0239\n",
            "root        : INFO     Epoch: 16, Batch: 100, Loss: 0.0256\n",
            "root        : INFO     Epoch: 16, Batch: 150, Loss: 0.0174\n",
            "root        : INFO     Epoch: 16, Batch: 200, Loss: 0.0286\n",
            "root        : INFO     Epoch: 16, Batch: 250, Loss: 0.0132\n",
            "root        : INFO     Epoch: 16, Batch: 300, Loss: 0.0206\n",
            "root        : INFO     Epoch: 16, Batch: 350, Loss: 0.0094\n",
            "root        : INFO     Epoch: 16, Batch: 400, Loss: 0.0084\n",
            "root        : INFO     Epoch: 16, Batch: 450, Loss: 0.0095\n",
            "root        : INFO     Epoch: 16, Batch: 500, Loss: 0.0173\n",
            "root        : INFO     Epoch: 16, Batch: 550, Loss: 0.0185\n",
            "root        : INFO     Epoch: 16, Batch: 600, Loss: 0.0110\n",
            "root        : INFO     Epoch: 16, Batch: 650, Loss: 0.0198\n",
            "root        : INFO     Epoch: 16, Batch: 700, Loss: 0.0164\n",
            "root        : INFO     Epoch: 16, Batch: 750, Loss: 0.0221\n",
            "root        : INFO     Epoch: 16, Batch: 800, Loss: 0.0189\n",
            "root        : INFO     Epoch: 16, Batch: 850, Loss: 0.0197\n",
            "root        : INFO     Epoch: 16, Batch: 900, Loss: 0.0215\n",
            "root        : INFO     Epoch: 16, Batch: 950, Loss: 0.0136\n",
            "root        : INFO     Epoch: 16, Batch: 1000, Loss: 0.0131\n",
            "root        : INFO     Epoch: 16, Batch: 1050, Loss: 0.0112\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     615/936 = 0.657051\n",
            "root        : INFO     Beginning Epoch 17\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 17, Batch: 50, Loss: 0.0091\n",
            "root        : INFO     Epoch: 17, Batch: 100, Loss: 0.0244\n",
            "root        : INFO     Epoch: 17, Batch: 150, Loss: 0.0110\n",
            "root        : INFO     Epoch: 17, Batch: 200, Loss: 0.0167\n",
            "root        : INFO     Epoch: 17, Batch: 250, Loss: 0.0107\n",
            "root        : INFO     Epoch: 17, Batch: 300, Loss: 0.0243\n",
            "root        : INFO     Epoch: 17, Batch: 350, Loss: 0.0187\n",
            "root        : INFO     Epoch: 17, Batch: 400, Loss: 0.0139\n",
            "root        : INFO     Epoch: 17, Batch: 450, Loss: 0.0143\n",
            "root        : INFO     Epoch: 17, Batch: 500, Loss: 0.0370\n",
            "root        : INFO     Epoch: 17, Batch: 550, Loss: 0.0119\n",
            "root        : INFO     Epoch: 17, Batch: 600, Loss: 0.0176\n",
            "root        : INFO     Epoch: 17, Batch: 650, Loss: 0.0147\n",
            "root        : INFO     Epoch: 17, Batch: 700, Loss: 0.0150\n",
            "root        : INFO     Epoch: 17, Batch: 750, Loss: 0.0244\n",
            "root        : INFO     Epoch: 17, Batch: 800, Loss: 0.0164\n",
            "root        : INFO     Epoch: 17, Batch: 850, Loss: 0.0201\n",
            "root        : INFO     Epoch: 17, Batch: 900, Loss: 0.0157\n",
            "root        : INFO     Epoch: 17, Batch: 950, Loss: 0.0088\n",
            "root        : INFO     Epoch: 17, Batch: 1000, Loss: 0.0151\n",
            "root        : INFO     Epoch: 17, Batch: 1050, Loss: 0.0198\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     519/936 = 0.554487\n",
            "root        : INFO     Beginning Epoch 18\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 18, Batch: 50, Loss: 0.0141\n",
            "root        : INFO     Epoch: 18, Batch: 100, Loss: 0.0121\n",
            "root        : INFO     Epoch: 18, Batch: 150, Loss: 0.0169\n",
            "root        : INFO     Epoch: 18, Batch: 200, Loss: 0.0213\n",
            "root        : INFO     Epoch: 18, Batch: 250, Loss: 0.0151\n",
            "root        : INFO     Epoch: 18, Batch: 300, Loss: 0.0259\n",
            "root        : INFO     Epoch: 18, Batch: 350, Loss: 0.0158\n",
            "root        : INFO     Epoch: 18, Batch: 400, Loss: 0.0166\n",
            "root        : INFO     Epoch: 18, Batch: 450, Loss: 0.0203\n",
            "root        : INFO     Epoch: 18, Batch: 500, Loss: 0.0145\n",
            "root        : INFO     Epoch: 18, Batch: 550, Loss: 0.0151\n",
            "root        : INFO     Epoch: 18, Batch: 600, Loss: 0.0253\n",
            "root        : INFO     Epoch: 18, Batch: 650, Loss: 0.0249\n",
            "root        : INFO     Epoch: 18, Batch: 700, Loss: 0.0208\n",
            "root        : INFO     Epoch: 18, Batch: 750, Loss: 0.0133\n",
            "root        : INFO     Epoch: 18, Batch: 800, Loss: 0.0269\n",
            "root        : INFO     Epoch: 18, Batch: 850, Loss: 0.0131\n",
            "root        : INFO     Epoch: 18, Batch: 900, Loss: 0.0155\n",
            "root        : INFO     Epoch: 18, Batch: 950, Loss: 0.0250\n",
            "root        : INFO     Epoch: 18, Batch: 1000, Loss: 0.0173\n",
            "root        : INFO     Epoch: 18, Batch: 1050, Loss: 0.0199\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     557/936 = 0.595085\n",
            "root        : INFO     Beginning Epoch 19\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 19, Batch: 50, Loss: 0.0091\n",
            "root        : INFO     Epoch: 19, Batch: 100, Loss: 0.0117\n",
            "root        : INFO     Epoch: 19, Batch: 150, Loss: 0.0198\n",
            "root        : INFO     Epoch: 19, Batch: 200, Loss: 0.0237\n",
            "root        : INFO     Epoch: 19, Batch: 250, Loss: 0.0117\n",
            "root        : INFO     Epoch: 19, Batch: 300, Loss: 0.0165\n",
            "root        : INFO     Epoch: 19, Batch: 350, Loss: 0.0222\n",
            "root        : INFO     Epoch: 19, Batch: 400, Loss: 0.0158\n",
            "root        : INFO     Epoch: 19, Batch: 450, Loss: 0.0171\n",
            "root        : INFO     Epoch: 19, Batch: 500, Loss: 0.0078\n",
            "root        : INFO     Epoch: 19, Batch: 550, Loss: 0.0112\n",
            "root        : INFO     Epoch: 19, Batch: 600, Loss: 0.0128\n",
            "root        : INFO     Epoch: 19, Batch: 650, Loss: 0.0165\n",
            "root        : INFO     Epoch: 19, Batch: 700, Loss: 0.0274\n",
            "root        : INFO     Epoch: 19, Batch: 750, Loss: 0.0293\n",
            "root        : INFO     Epoch: 19, Batch: 800, Loss: 0.0159\n",
            "root        : INFO     Epoch: 19, Batch: 850, Loss: 0.0170\n",
            "root        : INFO     Epoch: 19, Batch: 900, Loss: 0.0078\n",
            "root        : INFO     Epoch: 19, Batch: 950, Loss: 0.0200\n",
            "root        : INFO     Epoch: 19, Batch: 1000, Loss: 0.0387\n",
            "root        : INFO     Epoch: 19, Batch: 1050, Loss: 0.0180\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     365/936 = 0.389957\n",
            "root        : INFO     Beginning Epoch 20\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "Traceback (most recent call last):\n",
            "  File \"train_network3.py\", line 367, in <module>\n",
            "  File \"train_network3.py\", line 339, in run\n",
            "    train_results = train(epoch, net, device, train_data, optimizer, args.batches_per_epoch, vis=args.vis)\n",
            "  File \"train_network3.py\", line 161, in train\n",
            "    for x, y, _, _, _ in train_data:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1138, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJwqE1RbziCw"
      },
      "source": [
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_0.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_1.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_2.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_3.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_4.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_5.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_6.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_7.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_8.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_9.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_10.zip -d /content/jacquard_dataset\n",
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_11.zip -d /content/jacquard_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOd_H4SeYzMc"
      },
      "source": [
        "!unzip -n /content/drive/MyDrive/Grasp_Detection_Workplace/Jacquard_Dataset_0.zip -d /content/jacquard_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB2L-tKhaiOj"
      },
      "source": [
        "**Training the Jacquard dataset 0 but augment it  - Object-Wise (train_network3.py)**  \n",
        "use-depth = 1, use-rgb = 1, channel size =32, batchsize =64, Adam (lr=0.01) --augment 0  \n",
        "logs and results are saved at /content/drive/MyDrive/jacquard_logs/210410_1542_training_jacquard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-_ri8GDY7Kx",
        "outputId": "057d8941-36d5-43f3-8bc7-c394bbce1ae5"
      },
      "source": [
        "!python train_network3.py --dataset jacquard --dataset-path /content/jacquard_dataset/ --description training_jacquard --logdir /content/drive/MyDrive/jacquard_logs/ --ds-shuffle --num-workers 8 --batch-size 64 --batches-per-epoch 264 --lr 0.01 --augment 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=1\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.90, ds-rotate = 0.00, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 64, bacthes per epoch = 264, optimizer = adam, learning rate = 0.010000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/jacquard_logs/210410_1542_training_jacquard\n",
            "root        : INFO     Loading Jacquard Dataset...\n",
            "root        : INFO     Dataset size is 4646\n",
            "root        : INFO     Training size: 4181\n",
            "root        : INFO     Validation size: 465\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 20, Loss: 0.3022\n",
            "root        : INFO     Epoch: 0, Batch: 40, Loss: 0.0789\n",
            "root        : INFO     Epoch: 0, Batch: 60, Loss: 0.0740\n",
            "root        : INFO     Epoch: 0, Batch: 80, Loss: 0.0709\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0749\n",
            "root        : INFO     Epoch: 0, Batch: 120, Loss: 0.0728\n",
            "root        : INFO     Epoch: 0, Batch: 140, Loss: 0.0726\n",
            "root        : INFO     Epoch: 0, Batch: 160, Loss: 0.0679\n",
            "root        : INFO     Epoch: 0, Batch: 180, Loss: 0.0709\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0604\n",
            "root        : INFO     Epoch: 0, Batch: 220, Loss: 0.0579\n",
            "root        : INFO     Epoch: 0, Batch: 240, Loss: 0.0697\n",
            "root        : INFO     Epoch: 0, Batch: 260, Loss: 0.0669\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     104/465 = 0.223656\n",
            "root        : INFO     Beginning Epoch 01\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 1, Batch: 20, Loss: 0.0673\n",
            "root        : INFO     Epoch: 1, Batch: 40, Loss: 0.0852\n",
            "root        : INFO     Epoch: 1, Batch: 60, Loss: 0.0726\n",
            "root        : INFO     Epoch: 1, Batch: 80, Loss: 0.0635\n",
            "root        : INFO     Epoch: 1, Batch: 100, Loss: 0.0708\n",
            "root        : INFO     Epoch: 1, Batch: 120, Loss: 0.0525\n",
            "root        : INFO     Epoch: 1, Batch: 140, Loss: 0.0647\n",
            "root        : INFO     Epoch: 1, Batch: 160, Loss: 0.0563\n",
            "root        : INFO     Epoch: 1, Batch: 180, Loss: 0.0514\n",
            "root        : INFO     Epoch: 1, Batch: 200, Loss: 0.0587\n",
            "root        : INFO     Epoch: 1, Batch: 220, Loss: 0.0577\n",
            "root        : INFO     Epoch: 1, Batch: 240, Loss: 0.0563\n",
            "root        : INFO     Epoch: 1, Batch: 260, Loss: 0.0627\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     38/465 = 0.081720\n",
            "root        : INFO     Beginning Epoch 02\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 2, Batch: 20, Loss: 0.0615\n",
            "root        : INFO     Epoch: 2, Batch: 40, Loss: 0.0680\n",
            "root        : INFO     Epoch: 2, Batch: 60, Loss: 0.0681\n",
            "root        : INFO     Epoch: 2, Batch: 80, Loss: 0.0570\n",
            "root        : INFO     Epoch: 2, Batch: 100, Loss: 0.0552\n",
            "root        : INFO     Epoch: 2, Batch: 120, Loss: 0.0553\n",
            "root        : INFO     Epoch: 2, Batch: 140, Loss: 0.0577\n",
            "root        : INFO     Epoch: 2, Batch: 160, Loss: 0.0540\n",
            "root        : INFO     Epoch: 2, Batch: 180, Loss: 0.0508\n",
            "root        : INFO     Epoch: 2, Batch: 200, Loss: 0.0631\n",
            "root        : INFO     Epoch: 2, Batch: 220, Loss: 0.0571\n",
            "root        : INFO     Epoch: 2, Batch: 240, Loss: 0.0653\n",
            "root        : INFO     Epoch: 2, Batch: 260, Loss: 0.0518\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     145/465 = 0.311828\n",
            "root        : INFO     Beginning Epoch 03\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 3, Batch: 20, Loss: 0.0530\n",
            "root        : INFO     Epoch: 3, Batch: 40, Loss: 0.0481\n",
            "root        : INFO     Epoch: 3, Batch: 60, Loss: 0.0541\n",
            "root        : INFO     Epoch: 3, Batch: 80, Loss: 0.0446\n",
            "root        : INFO     Epoch: 3, Batch: 100, Loss: 0.0605\n",
            "root        : INFO     Epoch: 3, Batch: 120, Loss: 0.0499\n",
            "root        : INFO     Epoch: 3, Batch: 140, Loss: 0.0569\n",
            "root        : INFO     Epoch: 3, Batch: 160, Loss: 0.0543\n",
            "root        : INFO     Epoch: 3, Batch: 180, Loss: 0.0476\n",
            "root        : INFO     Epoch: 3, Batch: 200, Loss: 0.0649\n",
            "root        : INFO     Epoch: 3, Batch: 220, Loss: 0.0512\n",
            "root        : INFO     Epoch: 3, Batch: 240, Loss: 0.0506\n",
            "root        : INFO     Epoch: 3, Batch: 260, Loss: 0.0478\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     137/465 = 0.294624\n",
            "root        : INFO     Beginning Epoch 04\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 4, Batch: 20, Loss: 0.0545\n",
            "root        : INFO     Epoch: 4, Batch: 40, Loss: 0.0516\n",
            "root        : INFO     Epoch: 4, Batch: 60, Loss: 0.0567\n",
            "root        : INFO     Epoch: 4, Batch: 80, Loss: 0.0574\n",
            "root        : INFO     Epoch: 4, Batch: 100, Loss: 0.0506\n",
            "root        : INFO     Epoch: 4, Batch: 120, Loss: 0.0548\n",
            "root        : INFO     Epoch: 4, Batch: 140, Loss: 0.0459\n",
            "root        : INFO     Epoch: 4, Batch: 160, Loss: 0.0559\n",
            "root        : INFO     Epoch: 4, Batch: 180, Loss: 0.0508\n",
            "root        : INFO     Epoch: 4, Batch: 200, Loss: 0.0421\n",
            "root        : INFO     Epoch: 4, Batch: 220, Loss: 0.0525\n",
            "root        : INFO     Epoch: 4, Batch: 240, Loss: 0.0551\n",
            "root        : INFO     Epoch: 4, Batch: 260, Loss: 0.0500\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     166/465 = 0.356989\n",
            "root        : INFO     Beginning Epoch 05\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 5, Batch: 20, Loss: 0.0455\n",
            "root        : INFO     Epoch: 5, Batch: 40, Loss: 0.0420\n",
            "root        : INFO     Epoch: 5, Batch: 60, Loss: 0.0473\n",
            "root        : INFO     Epoch: 5, Batch: 80, Loss: 0.0502\n",
            "root        : INFO     Epoch: 5, Batch: 100, Loss: 0.0483\n",
            "root        : INFO     Epoch: 5, Batch: 120, Loss: 0.0432\n",
            "root        : INFO     Epoch: 5, Batch: 140, Loss: 0.0426\n",
            "root        : INFO     Epoch: 5, Batch: 160, Loss: 0.0419\n",
            "root        : INFO     Epoch: 5, Batch: 180, Loss: 0.0586\n",
            "root        : INFO     Epoch: 5, Batch: 200, Loss: 0.0382\n",
            "root        : INFO     Epoch: 5, Batch: 220, Loss: 0.0483\n",
            "root        : INFO     Epoch: 5, Batch: 240, Loss: 0.0558\n",
            "root        : INFO     Epoch: 5, Batch: 260, Loss: 0.0508\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     233/465 = 0.501075\n",
            "root        : INFO     Beginning Epoch 06\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 6, Batch: 20, Loss: 0.0388\n",
            "root        : INFO     Epoch: 6, Batch: 40, Loss: 0.0479\n",
            "root        : INFO     Epoch: 6, Batch: 60, Loss: 0.0508\n",
            "root        : INFO     Epoch: 6, Batch: 80, Loss: 0.0451\n",
            "root        : INFO     Epoch: 6, Batch: 100, Loss: 0.0527\n",
            "root        : INFO     Epoch: 6, Batch: 120, Loss: 0.0453\n",
            "root        : INFO     Epoch: 6, Batch: 140, Loss: 0.0453\n",
            "root        : INFO     Epoch: 6, Batch: 160, Loss: 0.0394\n",
            "root        : INFO     Epoch: 6, Batch: 180, Loss: 0.0408\n",
            "root        : INFO     Epoch: 6, Batch: 200, Loss: 0.0454\n",
            "root        : INFO     Epoch: 6, Batch: 220, Loss: 0.0429\n",
            "root        : INFO     Epoch: 6, Batch: 240, Loss: 0.0422\n",
            "root        : INFO     Epoch: 6, Batch: 260, Loss: 0.0499\n",
            "root        : INFO     Validating...\n",
            "root        : INFO     258/465 = 0.554839\n",
            "root        : INFO     Beginning Epoch 07\n",
            "root        : INFO     Training set is shuffled and prepared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCafc2WjpTRj"
      },
      "source": [
        "**Training the whole Jacquard dataset  - Object-Wise (train_network3.py)**  \n",
        "use-depth = 1, use-rgb = 1, channel size =32, batchsize =64, Adam (lr=0.01) --augment 1  \n",
        "saved at /content/drive/MyDrive/jacquard_logs/210410_0519_training_jacquard\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij_l1ROApUAa",
        "outputId": "8f8d1ede-15c3-44e0-903e-479d962105be"
      },
      "source": [
        "!python train_network3.py --dataset jacquard --dataset-path /content/jacquard_dataset/ --description training_jacquard --logdir /content/drive/MyDrive/jacquard_logs/ --ds-shuffle --num-workers 8 --batch-size 64 --batches-per-epoch 767 --lr 0.01 --augment 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        : INFO     CUDA detected. Running with GPU acceleration.\n",
            "root        : INFO     GPU: Tesla P100-PCIE-16GB, number of GPUs: 1\n",
            "root        : INFO     network = grconvnet3, use-depth = 1, use-rgb = 1, augment=0\n",
            "root        : INFO     dropout prob = 0.10, channel size = 32\n",
            "root        : INFO     split = 0.90, ds-rotate = 0.00, number of workers = 8, random seed = 123.00\n",
            "root        : INFO     epochs = 30, batch size = 64, bacthes per epoch = 767, optimizer = adam, learning rate = 0.010000\n",
            "root        : INFO     logs and results are saved at /content/drive/MyDrive/jacquard_logs/210410_0519_training_jacquard\n",
            "root        : INFO     Loading Jacquard Dataset...\n",
            "root        : INFO     Dataset size is 54485\n",
            "root        : INFO     Training size: 49036\n",
            "root        : INFO     Validation size: 5449\n",
            "root        : INFO     Validation set is prepared\n",
            "root        : INFO     Loading Network...\n",
            "root        : INFO     Done\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]          10,400\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "            Conv2d-3         [-1, 64, 112, 112]          32,832\n",
            "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
            "            Conv2d-5          [-1, 128, 56, 56]         131,200\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "            Conv2d-7          [-1, 128, 56, 56]         147,584\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "            Conv2d-9          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-11          [-1, 128, 56, 56]               0\n",
            "           Conv2d-12          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 56, 56]             256\n",
            "           Conv2d-14          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
            "           Conv2d-19          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-21          [-1, 128, 56, 56]               0\n",
            "           Conv2d-22          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
            "           Conv2d-24          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
            "    ResidualBlock-31          [-1, 128, 56, 56]               0\n",
            "  ConvTranspose2d-32         [-1, 64, 113, 113]         131,136\n",
            "      BatchNorm2d-33         [-1, 64, 113, 113]             128\n",
            "  ConvTranspose2d-34         [-1, 32, 225, 225]          32,800\n",
            "      BatchNorm2d-35         [-1, 32, 225, 225]              64\n",
            "  ConvTranspose2d-36         [-1, 32, 225, 225]          82,976\n",
            "          Dropout-37         [-1, 32, 225, 225]               0\n",
            "           Conv2d-38          [-1, 1, 224, 224]             129\n",
            "          Dropout-39         [-1, 32, 225, 225]               0\n",
            "           Conv2d-40          [-1, 1, 224, 224]             129\n",
            "          Dropout-41         [-1, 32, 225, 225]               0\n",
            "           Conv2d-42          [-1, 1, 224, 224]             129\n",
            "          Dropout-43         [-1, 32, 225, 225]               0\n",
            "           Conv2d-44          [-1, 1, 224, 224]             129\n",
            "================================================================\n",
            "Total params: 1,900,900\n",
            "Trainable params: 1,900,900\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 219.96\n",
            "Params size (MB): 7.25\n",
            "Estimated Total Size (MB): 227.97\n",
            "----------------------------------------------------------------\n",
            "root        : INFO     Beginning Epoch 00\n",
            "root        : INFO     Training set is shuffled and prepared\n",
            "root        : INFO     Epoch: 0, Batch: 50, Loss: 0.0510\n",
            "root        : INFO     Epoch: 0, Batch: 100, Loss: 0.0445\n",
            "root        : INFO     Epoch: 0, Batch: 150, Loss: 0.0603\n",
            "root        : INFO     Epoch: 0, Batch: 200, Loss: 0.0468\n",
            "root        : INFO     Epoch: 0, Batch: 250, Loss: 0.0513\n",
            "root        : INFO     Epoch: 0, Batch: 300, Loss: 0.0446\n",
            "root        : INFO     Epoch: 0, Batch: 350, Loss: 0.0479\n",
            "root        : INFO     Epoch: 0, Batch: 400, Loss: 0.0404\n",
            "root        : INFO     Epoch: 0, Batch: 450, Loss: 0.0371\n",
            "root        : INFO     Epoch: 0, Batch: 500, Loss: 0.0482\n"
          ]
        }
      ]
    }
  ]
}